{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chapter 4 - Web Mining Techniques\n",
    "웹 마이닝 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 웹 구조 마이닝\n",
    "Web structure mining\n",
    "\n",
    "### 01 웹 크롤러 - Spyder\n",
    "### 02 인덱서- DB\n",
    "### 03 페이지 랭킹 알고리즘 - Ranking (명성)\n",
    "page I's in-link : 외부 페이지에서 I page 연결 수\n",
    "\n",
    "page I's out-link : 페이지 I 가 연결하는 외부페이지 수\n",
    "1. P(i) : i 페이지 방문확률\n",
    "2. P(j) : j 페이지 방문확률\n",
    "3. Aji: 노트 j에서 노드 i로 전이될 확률 \n",
    "$$ P(i) = \\sum_j A_{ji} P(j) $$\n",
    "\n",
    "### 04 rank sing (랭크싱크) \n",
    "서로 링크한 경우에는 Loop에 빠져서, 랜덤한 점프 전이행렬을 추가\n",
    "1. (1-d) 페이지를 임의로 방문할 확률\n",
    "2. A는 확룰로써 총 합은 1이다\n",
    "$$ P = (\\frac{(1-d)E}{N}+dA^T)P $$\n",
    "3. 아래의 식의 P벡터를 $e^T P=N $으로 정규화를 하면 식이 간단해진다\n",
    "$$ P = (1-d)e + dA^TP \\to P(i) = (1-d)+d\\sum_{j=1}A_{ji}P(j) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 웹 콘텐츠 마이닝\n",
    "### 01 Parsing\n",
    "파싱\n",
    "### 02 자연어 처리\n",
    "NLTK\n",
    "\n",
    "Stemming : 단어를 어간으로 축소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = \"\"\"On 1 January 2007, Irish became a full EU official language, \n",
    "with a temporary derogation for a renewable period of five years (see Council \n",
    "Regulation (EC) No 920/2005 of 13 June 2005 (OJ L 156, 18.6.2005, p. 3)) stating \n",
    "that 'the institutions of the European Union shall not be bound by the obligation\n",
    "to draft all acts in Irish and to publish them in that language in the Official \n",
    "Journal of the European Union \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words length :  91 \n",
      "\n",
      " ['On', '1', 'January', '2007', ',', 'Irish', 'became', 'a', 'full', 'EU', 'official', 'language', ',', 'with', 'a', 'temporary', 'derogation', 'for', 'a', 'renewable']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tknzr = WordPunctTokenizer()\n",
    "\n",
    "words = tknzr.tokenize(text)\n",
    "print('Words length : ', len(words), '\\n\\n', words[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean words length :  64 \n",
      "\n",
      " ['on', '1', 'january', '2007', ',', 'irish', 'became', 'full', 'eu', 'official', 'language', ',', 'temporary', 'derogation', 'renewable']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "words_clean = [ w.lower()   for w in words   if w not in stopwords]\n",
    "print('Clean words length : ', len(words_clean), '\\n\\n', words_clean[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean words stem length :  64 \n",
      "\n",
      " ['on', '1', 'januari', '2007', ',', 'irish', 'becam', 'full', 'eu', 'offici', 'languag', ',', 'temporari', 'derog', 'renew']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "words_clean_stem = [stemmer.stem(w)  for w in words_clean]\n",
    "print('Clean words stem length : ', len(words_clean_stem), '\\n\\n', words_clean_stem[:15])\n",
    "# token 의 갯수는 동일, 접사를 제거한 나머지를 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03 정보 검색 모델\n",
    "Information retrieval models\n",
    "\n",
    "모델목록 : Boolean Model(불리언), Vector space model(벡터), Probabilistic model(확률)\n",
    "\n",
    "Vector 모델 목록\n",
    "1. TF-IDF(Term Frequency-Inverse Document Frequency) 단어빈도 - 역문서 빈도\n",
    "2. LSA(Latent Semantic Analysis) 잠재의미분석\n",
    "3. Doc2Vec (Word2Vec)\n",
    "\n",
    "쿼리 단어간의 벡터로 표현하고, <strong>쿼리 벡터</strong>와 <strong>각 문서</strong>간의 <strong>$\\cos \\theta$ 유사도</strong> 를 측정, 비교한다 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04 TF-IDF\n",
    "아주 <strong>많은 문서에 빈번</strong>하게 등장하는 단어는 <strong>중요도가 낮고</strong>, \n",
    "<strong>일부문서에 빈번</strong>한 단어의 <strong>중요도가 높다</strong>\n",
    "$$ W_{ij} = tf_{ij}*idf_j $$\n",
    "$ tf_{ij} = \\frac {f_{ij}}{max f_{i1}...f_{iV}}$  문서 i에서 <strong>단어 j의 정규화 빈도</strong>\n",
    "\n",
    "$ idf_j = log\\frac{N}{df} $ <strong>역문서 빈도</strong>로 $idf_j$는 단어 j를 포함하는 웹페이지 갯수 (N은 전체 웹페이지 갯수)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05 잠재 의미 분석(LSA)\n",
    "단어와 문서를 효과적으로 설명할 수 있는 정형적인 잠재공간이 존재하고, 비슷한 의미의 단어는 비슷한 위치에 나타난다\n",
    "\n",
    "문서의 잠재공간 투영은 <strong>절단SVD</strong>를 이용한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
