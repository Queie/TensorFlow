{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chapter 5 - Recommendation Systems\n",
    "추천 시스템\n",
    "1. 협업 필터링 (CF) Collaborative Filtering \n",
    "2. 콘텐츠 기반 필터링 (CBF) Content-based Filtering\n",
    "\n",
    "기타 접근방법\n",
    "1. 연관 룰 association rules\n",
    "2. $Log$ 우도 the log-likelihood method\n",
    "3. 하이브리드 hybrid methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## 1 유틸리티 행렬\n",
    "Utility matrix 추천시스템에 사용되는 계량척도 시스템\n",
    "\n",
    "평점 사용자 $i$가 아이템 $j$를 평가한 사용자 평가목록 : $ r_{ij}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01 데이터 수집 및 전처리\n",
    "import Csv files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1  2          3\n",
       "0  196  242  3  881250949\n",
       "1  186  302  3  891717742"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from scipy import linalg\n",
    "from collections import defaultdict\n",
    "import copy, collections, math\n",
    "\n",
    "# 사용자 평점 데이터 불러오기\n",
    "df = pd.read_csv('./data/ml-100k/u.data', sep='\\t', header=None)\n",
    "\n",
    "num_users  = len(df[0].drop_duplicates().tolist())  \n",
    "movies_rated  = list(df[1]) \n",
    "counts = collections.Counter(movies_rated)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                 1            2   3   \\\n",
       "0   1  Toy Story (1995)  01-Jan-1995 NaN   \n",
       "1   2  GoldenEye (1995)  01-Jan-1995 NaN   \n",
       "\n",
       "                                                  4   5   6   7   8   9  ...  \\\n",
       "0  http://us.imdb.com/M/title-exact?Toy%20Story%2...   0   0   0   1   1 ...   \n",
       "1  http://us.imdb.com/M/title-exact?GoldenEye%20(...   0   1   1   0   0 ...   \n",
       "\n",
       "   14  15  16  17  18  19  20  21  22  23  \n",
       "0   0   0   0   0   0   0   0   0   0   0  \n",
       "1   0   0   0   0   0   0   0   1   0   0  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/18171739/unicodedecodeerror-when-reading-csv-file-in-pandas-with-python\n",
    "# 데이터 영화목록 불러오기\n",
    "df_info = pd.read_csv('./data/ml-100k/u.item', sep='|', header=None, encoding = \"ISO-8859-1\")\n",
    "\n",
    "# 영화목록 추출\n",
    "movie_list = [df_info[1].tolist()[ indx ] + ';' + str(indx+1) \n",
    "              for indx in range(len(df_info[1].tolist())) ]\n",
    "num_movies = len(movie_list)\n",
    "df_info.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [user, Toy Story (1995);1, GoldenEye (1995);2, Four Rooms (1995);3, Get Shorty (1995);4, Copycat (1995);5, Shanghai Triad (Yao a yao yao dao waipo qiao) (1995);6, Twelve Monkeys (1995);7, Babe (1995);8, Dead Man Walking (1995);9, Richard III (1995);10, Seven (Se7en) (1995);11, Usual Suspects, The (1995);12, Mighty Aphrodite (1995);13, Postino, Il (1994);14, Mr. Holland's Opus (1995);15, French Twist (Gazon maudit) (1995);16, From Dusk Till Dawn (1996);17, White Balloon, The (1995);18, Antonia's Line (1995);19, Angels and Insects (1995);20, Muppet Treasure Island (1996);21, Braveheart (1995);22, Taxi Driver (1976);23, Rumble in the Bronx (1995);24, Birdcage, The (1996);25, Brothers McMullen, The (1995);26, Bad Boys (1995);27, Apollo 13 (1995);28, Batman Forever (1995);29, Belle de jour (1967);30, Crimson Tide (1995);31, Crumb (1994);32, Desperado (1995);33, Doom Generation, The (1995);34, Free Willy 2: The Adventure Home (1995);35, Mad Love (1995);36, Nadja (1994);37, Net, The (1995);38, Strange Days (1995);39, To Wong Foo, Thanks for Everything! Julie Newmar (1995);40, Billy Madison (1995);41, Clerks (1994);42, Disclosure (1994);43, Dolores Claiborne (1994);44, Eat Drink Man Woman (1994);45, Exotica (1994);46, Ed Wood (1994);47, Hoop Dreams (1994);48, I.Q. (1994);49, Star Wars (1977);50, Legends of the Fall (1994);51, Madness of King George, The (1994);52, Natural Born Killers (1994);53, Outbreak (1995);54, Professional, The (1994);55, Pulp Fiction (1994);56, Priest (1994);57, Quiz Show (1994);58, Three Colors: Red (1994);59, Three Colors: Blue (1993);60, Three Colors: White (1994);61, Stargate (1994);62, Santa Clause, The (1994);63, Shawshank Redemption, The (1994);64, What's Eating Gilbert Grape (1993);65, While You Were Sleeping (1995);66, Ace Ventura: Pet Detective (1994);67, Crow, The (1994);68, Forrest Gump (1994);69, Four Weddings and a Funeral (1994);70, Lion King, The (1994);71, Mask, The (1994);72, Maverick (1994);73, Faster Pussycat! Kill! Kill! (1965);74, Brother Minister: The Assassination of Malcolm X (1994);75, Carlito's Way (1993);76, Firm, The (1993);77, Free Willy (1993);78, Fugitive, The (1993);79, Hot Shots! Part Deux (1993);80, Hudsucker Proxy, The (1994);81, Jurassic Park (1993);82, Much Ado About Nothing (1993);83, Robert A. Heinlein's The Puppet Masters (1994);84, Ref, The (1994);85, Remains of the Day, The (1993);86, Searching for Bobby Fischer (1993);87, Sleepless in Seattle (1993);88, Blade Runner (1982);89, So I Married an Axe Murderer (1993);90, Nightmare Before Christmas, The (1993);91, True Romance (1993);92, Welcome to the Dollhouse (1995);93, Home Alone (1990);94, Aladdin (1992);95, Terminator 2: Judgment Day (1991);96, Dances with Wolves (1990);97, Silence of the Lambs, The (1991);98, Snow White and the Seven Dwarfs (1937);99, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 1683 columns]\n"
     ]
    }
   ],
   "source": [
    "df_out = pd.DataFrame(columns=['user']+movie_list)\n",
    "df_out  # 영화의 목록을 컬럼으로 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.6869 sec\n"
     ]
    }
   ],
   "source": [
    "# 사용자 리뷰중 50개 이하의 영화 리뷰를 작성한 사람들의 데이터는 제거한다\n",
    "min_ratings = 50  \n",
    "to_removelist = []; t0 = time()\n",
    "\n",
    "for i in range(1,num_users):\n",
    "    tmp_movielist = [0 for j in range(num_movies)]\n",
    "    df_tmp = df[df[0] == i]\n",
    "    for k in df_tmp.index:\n",
    "        if counts[ df_tmp.ix[k][1] ] >= min_ratings:\n",
    "            tmp_movielist[ df_tmp.ix[k][1] -1 ] = df_tmp.ix[k][2]\n",
    "        else: to_removelist.append(df_tmp.ix[k][1])\n",
    "    df_out.loc[i] = [i] + tmp_movielist   # df의 사용자 리뷰 데이터를 df_out 에 첨부\n",
    "\n",
    "to_remove_list = list(set(to_removelist))\n",
    "df_out.drop(df_out.columns[ to_removelist ], axis = 1, inplace = True)\n",
    "df_out.to_csv('data/utilitymatrix.csv', index = None)\n",
    "print(round(time()-t0,4),'sec'); df_out.iloc[:4,:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_out.shape\n",
    "# 총 1683개의 영화에 대한 개별 사용자의 평점을 첨부한다\n",
    "# 사용자가 모든 영화에 대한 리뷰를 작성하지는 않으므로, 50개 이하의 평점이 기록된 영화는 제거한다\n",
    "# NaN 결측치에 대하여, 정상적인 작동을 위해 '대체'(imputation) 의 방법으로 결측치 초기화를 한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02 결측치 처리\n",
    "대체 (imputation) : <strong>사용자의 평균 평점</strong>과 <strong>영화별 평균 평점</strong>을 대체에 사용한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputation(inp,Ri):\n",
    "    Ri = Ri.astype(float)\n",
    "    def userav():\n",
    "        for i in range(len(Ri)):\n",
    "            Ri[i][Ri[i] == 0] = sum( Ri[i] ) / float(len(Ri[i][Ri[i] > 0]))\n",
    "        return Ri\n",
    "    def itemav():\n",
    "        for i in range(len(Ri[0])):\n",
    "            Ri[:, i][Ri[:, i] == 0] = sum(Ri[:,i])/float(len(Ri[:, i][Ri[:, i] > 0]))\n",
    "        return Ri            \n",
    "    switch = {'useraverage' : userav() ,'itemaverage' : itemav() }\n",
    "    return switch[inp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## 2 유사도 척도\n",
    "벡터 $X$와 $Y$의 유사도를 계산하기 위한 척도\n",
    "1. 코사인 유사도 Cosine similarity\n",
    "2. 피어슨 상관관계 Pearson correlation\n",
    "두 척도의 평균이 0인경우, 일치하게 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "from scipy.spatial.distance import cosine \n",
    "def similarity(x,y,metric='cos'):\n",
    "    if metric == 'cos':\n",
    "        return 1.-cosine(x,y)   # 코사인 유사도를 출력\n",
    "    else:\n",
    "        return pearsonr(x,y)[0] # 피어슨 상관계수를 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## 3 협업 필터링 방법\n",
    "<h4><strong>Collaborative Filtering methods</strong></h4>\n",
    "\"자신과 비슷한 사람들은, 좋아하는 아이템을 공유한다\"를 기반으로 한다\n",
    "\n",
    "이는 사용자의 수많은 데이터를 필요로 하므로 <strong>Cold Start</strong>\n",
    "\n",
    "(<strong>가용 데이터 부족</strong>상태로, 반대로 <strong>Warm Start</strong>가 있다)가 문제가 되고 있다\n",
    "\n",
    "이를 극복하기 위하여, <strong>CF</strong>와 <strong>CBF의 하이브리드</strong> 방식이 제안되곤 한다\n",
    "\n",
    "(콘텐츠의 내부적 분류로써, 사용자의 데이터를 더 세분화 한 데이터로 분석을 한다)\n",
    "<h4><strong>콘텐츠 기반 알고리즘의 이슈</strong></h4>\n",
    "공통이슈로 <strong>'확장성(Scalability)'</strong>이 언급되는데\n",
    "\n",
    "이는 사용자와 아이템 갯수에 비례하여 연산량이 급증하는 문제를 말한다(<strong>병렬처리</strong>가 필요)\n",
    "\n",
    "반면 아이템 갯수가 작은경우에는 <strong>희소성(Sparsity)</strong> 문제가 생긴다(<strong>대체</strong>의 방법으로 해결\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><strong>1 메모리 기반의 협업 필터링</strong></h4>\n",
    "Memory-based Collaborative Filtering 은 <strong>유틸리티 행렬</strong>을 사용하여 아이템의 유사도를 계산한다\n",
    "<h4><strong>2 사용자 기반 협업 필터링</strong></h4>\n",
    "User-based Collaborative Filtering 은 <strong> K-NN 알고리즘</strong>을 사용한다, \n",
    "\n",
    "유사 사용자들의 평점을 찾은 뒤 <strong>가중 평균</strong>하여, 현재 사용자의 누락 평점 대신에 사용된다\n",
    "1. 사용자 $i$와 평가되지 않은 아이템 $j$를 특정한다\n",
    "2. 유사도 척도 $s$를 사용하여 $j$아이템에 유사평점을 준 사용자 $K$를 찾는다 ($K$ 이웃의 수는 20~50 사이값을 사용한다)\n",
    "3. $K$들의 평점을 가중평균하여, 사용자 $i$의 평점을 예측한다\n",
    "4. 균질적인 평점을 비교하기 위하여, 평점분포를 정규화 한다\n",
    "5. 예측평균이 1보다 작거나, 5보다 큰경우, 1과 5로 조정된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CF_userbased(u_vec, K, data, indxs = False):\n",
    "    def FindKNeighbours(r, data, K):\n",
    "        neighs, cnt = [], 0\n",
    "        for u in range(len(data)):\n",
    "            if data[u,r] > 0  and  cnt < K:\n",
    "                neighs.append(data[u])\n",
    "                cnt += 1 \n",
    "            elif cnt == K: break\n",
    "        return np.array(neighs)\n",
    "\n",
    "    def CalcRating(u_vec, r, neighs):\n",
    "        rating, den = 0., 0.\n",
    "        for j in range(len(neighs)):\n",
    "            rating += neighs[j][-1] * float(neighs[j][r] - neighs[j][neighs[j] > 0][:-1].mean())\n",
    "            den += abs(neighs[j][-1])\n",
    "        if den > 0:    rating = np.round(u_vec[u_vec>0].mean()+(rating/den),0)\n",
    "        else:          rating = np.round(u_vec[u_vec>0].mean(),0)\n",
    "        if rating > 5: return 5.\n",
    "        elif rating<1: return 1.\n",
    "        return rating \n",
    "\n",
    "    data = data.astype(float)\n",
    "    nrows, ncols = len(data), len(data[0])\n",
    "    data_sim = np.zeros((nrows,ncols+1))\n",
    "    data_sim[:,:-1] = data\n",
    "\n",
    "    # calc similarities:\n",
    "    for u in range(nrows):\n",
    "        if np.array_equal(data_sim[u, :-1], u_vec) == False: \n",
    "            data_sim[u,ncols] = sim(data_sim[u,:-1],u_vec,'pearson')\n",
    "        else:\n",
    "            data_sim[u,ncols] = 0.\n",
    "\n",
    "    #order by similarity:\n",
    "    data_sim =data_sim[data_sim[:,ncols].argsort()][::-1]\n",
    "    #find the K users for each item not rated:\n",
    "    u_rec = np.zeros(len(u_vec))\n",
    "    for r in xrange(ncols):\n",
    "        if u_vec[r]==0:\n",
    "            neighs = FindKNeighbours(r,data_sim,K)\n",
    "            # calc the predicted ratin\n",
    "            u_rec[r] = CalcRating(u_vec,r,neighs)\n",
    "\n",
    "    #take out the rated movies\n",
    "    if indxs:\n",
    "        seenindxs = [indx for indx in xrange(len(u_vec)) if u_vec[indx]>0]\n",
    "        u_rec[seenindxs] = -1\n",
    "        recsvec = np.argsort(u_rec)[::-1][np.argsort(u_rec)>0]\n",
    "        return recsvec    \n",
    "    return u_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
