{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ch 12. MNIST 에 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SoftMAX 를 활용한 MNIST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random\n",
    "tf.set_random_seed(777)  # reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# weights & bias for nn layers\n",
    "W = tf.Variable(tf.random_normal([784, 10]))\n",
    "b = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(X, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Inputing Tensor -------------------------------------------------------\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./data/MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 5.916487252\n",
      "Epoch: 0002 cost = 1.866405768\n",
      "Epoch: 0003 cost = 1.162832679\n",
      "Epoch: 0004 cost = 0.895143161\n",
      "Epoch: 0005 cost = 0.753446946\n",
      "Epoch: 0006 cost = 0.665053124\n",
      "Epoch: 0007 cost = 0.603639526\n",
      "Epoch: 0008 cost = 0.557631131\n",
      "Epoch: 0009 cost = 0.523071646\n",
      "Epoch: 0010 cost = 0.494843250\n",
      "Epoch: 0011 cost = 0.471451207\n",
      "Epoch: 0012 cost = 0.451943489\n",
      "Epoch: 0013 cost = 0.435195638\n",
      "Epoch: 0014 cost = 0.420587433\n",
      "Epoch: 0015 cost = 0.408088194\n"
     ]
    }
   ],
   "source": [
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.4f}'.format(avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9023\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [4]\n"
     ]
    }
   ],
   "source": [
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [4]\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJAoX64VgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5d4c698518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "          reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. NN를 활용한 MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "tf.set_random_seed(777)\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# weights & bias for nn layers\n",
    "W1 = tf.Variable(tf.random_normal([784, 256]))  \n",
    "b1 = tf.Variable(tf.random_normal([256]))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([256, 256]))\n",
    "b2 = tf.Variable(tf.random_normal([256])) \n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([256, 10]))\n",
    "b3 = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L2, W3) + b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "# tf.nn.softmax_cross_entropy_with_logits() : Cost 함수에 Softmax 를 바로 적용\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "                      logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize --------------------------------------------------------------\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Inputing Tensor ----------------------------------------------------------\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./data/MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 162.538095855\n",
      "Epoch: 0002 cost = 40.856378926\n",
      "Epoch: 0003 cost = 25.951241435\n",
      "Epoch: 0004 cost = 18.033336604\n",
      "Epoch: 0005 cost = 13.208470125\n",
      "Epoch: 0006 cost = 9.655478320\n",
      "Epoch: 0007 cost = 7.271904661\n",
      "Epoch: 0008 cost = 5.540651633\n",
      "Epoch: 0009 cost = 4.074460392\n",
      "Epoch: 0010 cost = 3.097866127\n",
      "Epoch: 0011 cost = 2.360980675\n",
      "Epoch: 0012 cost = 1.800317868\n",
      "Epoch: 0013 cost = 1.347157450\n",
      "Epoch: 0014 cost = 1.064786895\n",
      "Epoch: 0015 cost = 0.840181309\n"
     ]
    }
   ],
   "source": [
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9448\n"
     ]
    }
   ],
   "source": [
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [4]\n",
      "Prediction:  [4]\n"
     ]
    }
   ],
   "source": [
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJAoX64VgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5d4c698518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "          reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. weights & bias for NN를 활용한 MNIST (Xavier)\n",
    "- 초기값을 잘 주어짐으로써 성능을 향상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# weights & bias for nn layers (http://stackoverflow.com/questions/33640581/how-to-do-xavier-initialization-on-tensorflow)\n",
    "W1 = tf.get_variable(\"W1\", shape=[784, 256],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([256]))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.get_variable(\"W2\", shape=[256, 256],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([256]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "\n",
    "W3 = tf.get_variable(\"W3\", shape=[256, 10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L2, W3) + b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize ----------------------------------------------------------\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Inputing Tensor -------------------------------------------------------\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "mnist = input_data.read_data_sets(\"./data/MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.342817177\n",
      "Epoch: 0002 cost = 0.123277053\n",
      "Epoch: 0003 cost = 0.080149401\n",
      "Epoch: 0004 cost = 0.058212431\n",
      "Epoch: 0005 cost = 0.043214157\n",
      "Epoch: 0006 cost = 0.034394976\n",
      "Epoch: 0007 cost = 0.024810856\n",
      "Epoch: 0008 cost = 0.020439993\n",
      "Epoch: 0009 cost = 0.017374469\n",
      "Epoch: 0010 cost = 0.015349797\n",
      "Epoch: 0011 cost = 0.012645072\n",
      "Epoch: 0012 cost = 0.010901182\n",
      "Epoch: 0013 cost = 0.010076454\n",
      "Epoch: 0014 cost = 0.010257031\n",
      "Epoch: 0015 cost = 0.006876825\n"
     ]
    }
   ],
   "source": [
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.977\n"
     ]
    }
   ],
   "source": [
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [6]\n",
      "Prediction:  [6]\n"
     ]
    }
   ],
   "source": [
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5d443c9f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "          reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. More Deep & Drop Out\n",
    "- 8,9단의 뉴런을 갖는경우, 효율성을 높이기 위해 부분 부분의 실행을 제어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "tf.set_random_seed(777)  # reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dropout (keep_prob) rate  0.7 on training, but should be 1 for testing\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W1 = tf.get_variable(\"W1\", shape=[784, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([512]))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "L1 = tf.nn.dropout(L1, keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W2 = tf.get_variable(\"W2\", shape=[512, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([512]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "L2 = tf.nn.dropout(L2, keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W3 = tf.get_variable(\"W3\", shape=[512, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([512]))\n",
    "L3 = tf.nn.relu(tf.matmul(L2, W3) + b3)\n",
    "L3 = tf.nn.dropout(L3, keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W4 = tf.get_variable(\"W4\", shape=[512, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([512]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3, W4) + b4)\n",
    "L4 = tf.nn.dropout(L4, keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W5 = tf.get_variable(\"W5\", shape=[512, 10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 가설의 설립\n",
    "hypothesis = tf.matmul(L4, W5) + b5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize -----------------------------------------------------------------\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inputing Tensor ------------------------------------------------------------\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1], keep_prob: 1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "          reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Adam Optimizer\n",
    "- Optimize 할 때 추가적인 옵션으로도 성능이 향샹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# AdamOptimizer() 를 활용 (Gradient Descent 대신 코드를 삽입)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(hypothesis, Y))   # softmax loss\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Optimizer\n",
    "- http://www.denizyuret.com/2015/03/alec-radfords-animations-for.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/s25RsOr - Imgur.gif\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/Beal- Imgur.gif\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
