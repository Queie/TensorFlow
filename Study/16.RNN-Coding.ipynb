{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ch 15 RNN-coding\n",
    "- http://pythonkim.tistory.com/57\n",
    "- LSTM (Long Short Term Memory) 가장 대중적인 모델\n",
    "- GRU (Gated recurrent unit) 우리나라 교수님의 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. RNN in TensorFlow\n",
    "- TensorFlow 0.9 이상에서는 코드가 아래와 같이 변경\n",
    "- LSTM 공통 01 : Cell 생성\n",
    "    1. rnn_cell = tf.nn.rnn_cell.<strong>BasicRNNCell</strong>(num_units = rnn_size, input_size = None, )\n",
    "    1. rnn_cell = tf.nn.rnn_cell.<strong>BasicLSTMCell</strong>(num_units = rnn_size, input_size = None, )\n",
    "    2. initial_state = rnn_cell.zero_state(batch_size, tf.float32)\n",
    "    3. initial_state_1 = tf.zeros([batch_size, rnn_cell.state_size])\n",
    "    4. x_split = tf.split(0, len(char_dic), x_data) \n",
    "- LSTM 공통 02 : Cell 구동\n",
    "    5. outputs, state = tf.nn.rnn(cell = rnn_cell, inputs = x_split, initial_state = initial_state)    \n",
    "\n",
    "<img src=\"./img/RNNt-013.png\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#출력 사이즈를 정의\n",
    "# hidden_size = 2     \n",
    "# cell = tf.contrib.rnn.BasicLSTMCell(num_units = hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#입력 Dim을 정의\n",
    "# x_data = np.array([[[1,0,0,0]]], dtype=np.float32)\n",
    "# outputs, _states = tf.nn.dynamic_rnn(cell, x_data, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#출력모듈 실행\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "# pp.print(outputs.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cell을 생성\n",
    "- rnn_size : Output 의 크기값(4)을 입력 <p></p></br>\n",
    "<img src=\"./img/RNNt-004.png\" align=\"left\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- input : One-Hot Encoding ->  [[[1,0,0,0]]] shape=(1,1,4)\n",
    "- Output : Hidden-size = 임의의 값 ->  [[[x,x]]] shape=(1,1,2)\n",
    "- Input 데이터 형식과 , Hidden-size 만 '매개변수'로 입력하면 작동<p></p>\n",
    "<img src =\"./img/Lab12-RNN01.png\" align=\"left\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/Lab12-RNNout.png\" align=\"left\" width = 700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/Lab12-RNNout2.png\" align=\"left\" width = 700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01. One cell RNN input_dim (4) -> output_dim (2)\n",
    "- input = 5 ([1,0,0,0,0])  입력형태\n",
    "- Sequence = 6 (연산모듈이 6개)\n",
    "- hidden = 5 ([0,1,0,0,0]) 출력형태\n",
    "- batch = 1 (현재는 1개로만 작동) <p></p></br>\n",
    "<img src = \"./img/lab12-Rnnpa.png\" align=\"left\" width = 700>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.contrib import rnn\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One hot encoding for each char in 'hello'\n",
    "h = [1, 0, 0, 0]\n",
    "e = [0, 1, 0, 0]\n",
    "l = [0, 0, 1, 0]\n",
    "o = [0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output 2 state 2\n",
      "array([[[ 1.,  0.,  0.,  0.]]], dtype=float32)\n",
      "array([[[ 0.62225187, -0.40305367]]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# One cell RNN input_dim (4) -> output_dim (2)\n",
    "with tf.variable_scope('one_cell') as scope:\n",
    "    hidden_size = 2                                            # output_dim (2) \n",
    "    cell = tf.contrib.rnn.BasicRNNCell(num_units=hidden_size)\n",
    "    print('Output',cell.output_size, 'state',cell.state_size)  # 입력 데이터 형식을 출력\n",
    "    x_data = np.array([[h]],  dtype=np.float32)                # x_data ( h = [[[1,0,0,0]]] )\n",
    "    pp.pprint(x_data)                                          # 입력 데이터 출력\n",
    "    outputs, _states = tf.nn.dynamic_rnn( cell, x_data, dtype=tf.float32 )\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    pp.pprint(outputs.eval())                                  # 최종 데이터 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5, 4)\n",
      "array([[[ 1.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.]]], dtype=float32)\n",
      "array([[[-0.32641998,  0.41991842],\n",
      "        [-0.13929564, -0.48992422],\n",
      "        [ 0.20226188, -0.24535619],\n",
      "        [ 0.0399439 , -0.16477039],\n",
      "        [-0.40884489,  0.5929662 ]]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# One cell RNN input_dim (4) -> output_dim (2). sequence: 5\n",
    "with tf.variable_scope('two_sequances') as scope:\n",
    "    hidden_size = 2                                            # output_dim (2)\n",
    "    cell = tf.contrib.rnn.BasicRNNCell( num_units = hidden_size )\n",
    "    x_data = np.array( [[h,e,l,l,o]], dtype=np.float32 )       # sequence: 5  cf) input_dim (4)\n",
    "    print(x_data.shape)                                        # 입력 데이터 형식을 출력\n",
    "    pp.pprint(x_data)                                          # 입력 데이터 출력\n",
    "    outputs, states = tf.nn.dynamic_rnn( cell , x_data , dtype=tf.float32 )\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    pp.pprint(outputs.eval())                                  # 최종 데이터 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[[ 1.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.]],\n",
      "\n",
      "       [[ 0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.],\n",
      "        [ 0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.]]], dtype=float32)\n",
      "array([[[ 0.01180693,  0.07072996],\n",
      "        [ 0.02780049, -0.01082219],\n",
      "        [-0.06957481, -0.17919052],\n",
      "        [-0.12637572, -0.25342694],\n",
      "        [-0.00897235, -0.14294407]],\n",
      "\n",
      "       [[ 0.0266323 , -0.06549848],\n",
      "        [ 0.08703664, -0.00559421],\n",
      "        [-0.03538973, -0.18263945],\n",
      "        [-0.10124918, -0.25898033],\n",
      "        [-0.13777752, -0.29646835]],\n",
      "\n",
      "       [[-0.09290437, -0.16737527],\n",
      "        [-0.14468664, -0.24425863],\n",
      "        [-0.04393194, -0.18008718],\n",
      "        [ 0.01278433, -0.19284461],\n",
      "        [-0.06409218, -0.31255662]]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# One cell RNN input_dim (4) -> output_dim (2). sequence: 5, batch 3\n",
    "with tf.variable_scope('3_batches') as scope:\n",
    "    # 3 batches 'hello', 'eolll', 'lleel'\n",
    "    x_data = np.array([[h,e,l,l,o], [e,o,l,l,l], [l,l,e,e,l]], dtype=np.float32)  \n",
    "    pp.pprint(x_data)                                       # 입력 데이터 input_dim (4)\n",
    "    hidden_size = 2                                         # 출력 데이터 output_dim (2)\n",
    "    cell = rnn.BasicLSTMCell( num_units=hidden_size , state_is_tuple = True )\n",
    "    outputs, _states = tf.nn.dynamic_rnn( cell , x_data , dtype=tf.float32 )\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    pp.pprint(outputs.eval())                               # 최종 데이터 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[[ 1.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.]],\n",
      "\n",
      "       [[ 0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.],\n",
      "        [ 0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.]]], dtype=float32)\n",
      "array([[[-0.10441136, -0.09090777],\n",
      "        [ 0.07102746, -0.05561611],\n",
      "        [-0.04449596, -0.18288326],\n",
      "        [-0.13725717, -0.24952796],\n",
      "        [-0.05420873, -0.13149051]],\n",
      "\n",
      "       [[ 0.12674828, -0.0071988 ],\n",
      "        [ 0.14043358,  0.03840204],\n",
      "        [ 0.00520404, -0.11380652],\n",
      "        [ 0.        ,  0.        ],\n",
      "        [ 0.        ,  0.        ]],\n",
      "\n",
      "       [[-0.10302107, -0.12369861],\n",
      "        [-0.1797438 , -0.20011409],\n",
      "        [ 0.00667668, -0.10969392],\n",
      "        [ 0.13671795, -0.08314592],\n",
      "        [ 0.        ,  0.        ]]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# One cell RNN input_dim (4) -> output_dim (5). sequence: 5, batch 3\n",
    "with tf.variable_scope('3_batches_dynamic_length') as scope:\n",
    "    x_data = np.array([[h,e,l,l,o],[e,o,l,l,l],[l,l,e,e,l]], dtype=np.float32) # 3 batches 'hello', 'eolll', 'lleel'\n",
    "    pp.pprint(x_data)    \n",
    "    hidden_size = 2\n",
    "    cell = rnn.BasicLSTMCell( num_units = hidden_size , state_is_tuple = True )\n",
    "    # sequence_length=[5,3,4] : sequence: 5, batch 3, input_dim (4)\n",
    "    outputs, _states = tf.nn.dynamic_rnn(cell, x_data, sequence_length=[5,3,4], dtype=tf.float32)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    pp.pprint(outputs.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[[ 1.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.]],\n",
      "\n",
      "       [[ 0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.],\n",
      "        [ 0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.]]], dtype=float32)\n",
      "array([[[-0.07840708,  0.14941281],\n",
      "        [-0.25659773,  0.09724767],\n",
      "        [-0.25391352,  0.05390799],\n",
      "        [-0.26038998,  0.05199654],\n",
      "        [-0.14665331,  0.08220701]],\n",
      "\n",
      "       [[-0.19065872, -0.00270398],\n",
      "        [-0.07985987,  0.05199519],\n",
      "        [-0.15294963,  0.0657903 ],\n",
      "        [-0.19532792,  0.0701785 ],\n",
      "        [-0.22303128,  0.07032412]],\n",
      "\n",
      "       [[-0.08467411,  0.02964721],\n",
      "        [-0.14667179,  0.04683939],\n",
      "        [-0.28777272,  0.0343443 ],\n",
      "        [-0.35641044, -0.00953914],\n",
      "        [-0.30878997, -0.00367071]]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# One cell RNN input_dim (4) -> output_dim (5). sequence: 5, batch: 3\n",
    "with tf.variable_scope('initial_state') as scope:\n",
    "    batch_size = 3\n",
    "    x_data = np.array([[h,e,l,l,o], [e,o,l,l,l], [l,l,e,e,l]], dtype=np.float32)\n",
    "    pp.pprint(x_data)\n",
    "    hidden_size=2\n",
    "    cell = rnn.BasicLSTMCell(num_units=hidden_size, state_is_tuple=True)\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "    outputs, _states = tf.nn.dynamic_rnn(cell, x_data,\n",
    "                                         initial_state=initial_state, dtype=tf.float32)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    pp.pprint(outputs.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02. One cell RNN input_dim (3) -> output_dim (5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[[  0.,   1.,   2.],\n",
      "        [  3.,   4.,   5.],\n",
      "        [  6.,   7.,   8.],\n",
      "        [  9.,  10.,  11.],\n",
      "        [ 12.,  13.,  14.]],\n",
      "\n",
      "       [[ 15.,  16.,  17.],\n",
      "        [ 18.,  19.,  20.],\n",
      "        [ 21.,  22.,  23.],\n",
      "        [ 24.,  25.,  26.],\n",
      "        [ 27.,  28.,  29.]],\n",
      "\n",
      "       [[ 30.,  31.,  32.],\n",
      "        [ 33.,  34.,  35.],\n",
      "        [ 36.,  37.,  38.],\n",
      "        [ 39.,  40.,  41.],\n",
      "        [ 42.,  43.,  44.]]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Create input data\n",
    "batch_size=3\n",
    "sequence_length=5\n",
    "input_dim=3\n",
    "x_data = np.arange(45, dtype=np.float32).reshape(batch_size, sequence_length, input_dim)\n",
    "pp.pprint(x_data)  # batch, sequence_length, input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[[  1.48951430e-02,   1.36933044e-01,  -9.37520489e-02,\n",
      "           1.44709498e-01,  -2.74909697e-02],\n",
      "        [  1.23557728e-02,   2.21116468e-01,  -1.34138335e-02,\n",
      "           5.41603625e-01,  -1.07498476e-02],\n",
      "        [  6.71007764e-03,   1.97831646e-01,  -7.63019721e-04,\n",
      "           7.18563378e-01,  -7.55928515e-04],\n",
      "        [  3.40350647e-03,   1.25264287e-01,  -3.68362671e-05,\n",
      "           7.66722083e-01,  -4.64893201e-05],\n",
      "        [  1.64988311e-03,   6.80105537e-02,  -1.61077560e-06,\n",
      "           7.73712277e-01,  -2.80107679e-06]],\n",
      "\n",
      "       [[  2.59785721e-10,   1.48467673e-02,  -4.33666401e-08,\n",
      "           7.49117076e-01,  -1.80648357e-07],\n",
      "        [  1.30050137e-10,   1.42297512e-02,  -2.85983814e-09,\n",
      "           7.67691970e-01,  -9.73030101e-09],\n",
      "        [  6.04955738e-11,   7.86872301e-03,  -1.23809143e-10,\n",
      "           7.65618324e-01,  -5.61959479e-10],\n",
      "        [  2.80317471e-11,   3.90626397e-03,  -5.28892468e-12,\n",
      "           7.63988674e-01,  -3.23283726e-11],\n",
      "        [  1.29769841e-11,   1.88655651e-03,  -2.26123807e-13,\n",
      "           7.62994468e-01,  -1.85214647e-12]],\n",
      "\n",
      "       [[  1.67371389e-19,   4.46416961e-04,  -6.25878870e-15,\n",
      "           7.61117637e-01,  -1.16659625e-13],\n",
      "        [  8.32528464e-20,   3.84091167e-04,  -4.13887350e-16,\n",
      "           7.62059867e-01,  -6.03891886e-15],\n",
      "        [  3.85685788e-20,   2.01840390e-04,  -1.77386847e-17,\n",
      "           7.61862636e-01,  -3.44112296e-16],\n",
      "        [  1.78464880e-20,   9.84140788e-05,  -7.59739233e-19,\n",
      "           7.61747897e-01,  -1.95999205e-17],\n",
      "        [  8.25772063e-21,   4.72326501e-05,  -3.25416149e-20,\n",
      "           7.61682093e-01,  -1.11595536e-18]]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# One cell RNN input_dim (3) -> output_dim (5). sequence: 5, batch: 3\n",
    "with tf.variable_scope('generated_data') as scope:\n",
    "    cell = rnn.BasicLSTMCell(num_units=5, state_is_tuple=True)\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "    outputs, _states = tf.nn.dynamic_rnn(cell, x_data,\n",
    "                                         initial_state=initial_state, dtype=tf.float32)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    pp.pprint(outputs.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dynamic rnn:  Tensor(\"MultiRNNCell/rnn/transpose:0\", shape=(3, 5, 5), dtype=float32)\n",
      "array([[[  3.85906035e-03,  -3.46304500e-03,   6.51773298e-04,\n",
      "           3.47830844e-03,   3.02806986e-03],\n",
      "        [  6.34685718e-03,  -9.81214643e-03,   1.92663574e-03,\n",
      "           8.94505158e-03,   7.11261295e-03],\n",
      "        [  4.56437608e-03,  -1.64472442e-02,   3.58432997e-03,\n",
      "           1.46009829e-02,   1.04552554e-02],\n",
      "        [ -9.86767700e-04,  -2.17805002e-02,   5.45538729e-03,\n",
      "           1.94177721e-02,   1.27179381e-02],\n",
      "        [ -8.88167135e-03,  -2.54344810e-02,   7.34295044e-03,\n",
      "           2.30296962e-02,   1.40163219e-02]],\n",
      "\n",
      "       [[ -1.22465356e-03,  -3.63395968e-03,  -2.73378973e-04,\n",
      "           1.56903476e-03,   5.00238908e-04],\n",
      "        [ -4.25911136e-03,  -8.40106979e-03,  -2.70955206e-04,\n",
      "           3.64604429e-03,   1.32056267e-03],\n",
      "        [ -8.89113080e-03,  -1.27781667e-02,   1.82134943e-04,\n",
      "           5.33036236e-03,   2.27817846e-03],\n",
      "        [ -1.44636370e-02,  -1.62092969e-02,   9.82616679e-04,\n",
      "           6.25422923e-03,   3.21292691e-03],\n",
      "        [ -2.02899277e-02,  -1.86205767e-02,   1.94057508e-03,\n",
      "           6.32256269e-03,   4.00966266e-03]],\n",
      "\n",
      "       [[ -1.18864933e-03,  -3.08630662e-03,  -3.92712711e-04,\n",
      "           5.75649668e-04,   4.11963469e-04],\n",
      "        [ -3.91070498e-03,  -7.04600848e-03,  -6.56342192e-04,\n",
      "           9.42680577e-04,   1.04895700e-03],\n",
      "        [ -7.84373563e-03,  -1.06046563e-02,  -6.31826173e-04,\n",
      "           5.21183654e-04,   1.73260563e-03],\n",
      "        [ -1.23565355e-02,  -1.33512504e-02,  -3.93374095e-04,\n",
      "          -8.20143905e-04,   2.32896605e-03],\n",
      "        [ -1.68572068e-02,  -1.52799021e-02,  -8.06254538e-05,\n",
      "          -3.00619216e-03,   2.75557837e-03]]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('MultiRNNCell') as scope:\n",
    "    # Make rnn\n",
    "    cell = rnn.BasicLSTMCell(num_units=5, state_is_tuple=True)\n",
    "    cell = rnn.MultiRNNCell([cell] * 3, state_is_tuple=True) # 3 layers\n",
    "    # rnn in/out\n",
    "    outputs, _states = tf.nn.dynamic_rnn(cell, x_data, dtype=tf.float32)\n",
    "    print(\"dynamic rnn: \", outputs)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    pp.pprint(outputs.eval())  # batch size, unrolling (time), hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dynamic rnn:  Tensor(\"dynamic_rnn/rnn/transpose:0\", shape=(3, 5, 5), dtype=float32)\n",
      "array([[[  1.19335636e-01,   1.17564842e-01,  -5.99743389e-02,\n",
      "           1.61135346e-01,  -1.34429395e-01],\n",
      "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "           0.00000000e+00,   0.00000000e+00],\n",
      "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "           0.00000000e+00,   0.00000000e+00],\n",
      "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "           0.00000000e+00,   0.00000000e+00],\n",
      "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "           0.00000000e+00,   0.00000000e+00]],\n",
      "\n",
      "       [[  3.36048943e-05,   2.53466794e-08,  -7.94968859e-04,\n",
      "           1.59909114e-01,   4.94458480e-04],\n",
      "        [  5.27783868e-06,   2.29055108e-09,  -2.49875098e-04,\n",
      "           1.21128455e-01,   6.38624886e-04],\n",
      "        [  7.92449896e-07,   1.72006756e-10,  -7.68404643e-05,\n",
      "           8.67925659e-02,   6.87622756e-04],\n",
      "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "           0.00000000e+00,   0.00000000e+00],\n",
      "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "           0.00000000e+00,   0.00000000e+00]],\n",
      "\n",
      "       [[  2.56029975e-09,   9.65032154e-16,  -2.20794936e-06,\n",
      "           3.17120664e-02,   5.15245006e-07],\n",
      "        [  3.78685444e-10,   9.11450928e-17,  -6.77821049e-07,\n",
      "           2.23823041e-02,   6.47679713e-07],\n",
      "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "           0.00000000e+00,   0.00000000e+00],\n",
      "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "           0.00000000e+00,   0.00000000e+00],\n",
      "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "           0.00000000e+00,   0.00000000e+00]]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# lentgh 1 for batch 1, lentgh 2 for batch 2\n",
    "with tf.variable_scope('dynamic_rnn') as scope:\n",
    "    cell = rnn.BasicLSTMCell(num_units=5, state_is_tuple=True)\n",
    "    outputs, _states = tf.nn.dynamic_rnn(cell, x_data, dtype=tf.float32,\n",
    "                                         sequence_length=[1, 3, 2])    \n",
    "    print(\"dynamic rnn: \", outputs)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    pp.pprint(outputs.eval())  # batch size, unrolling (time), hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(   array([[[ -1.30502075e-01,  -2.37174630e-02,  -9.64497998e-02,\n",
      "           1.37160525e-01,  -1.54298857e-01],\n",
      "        [ -3.71729225e-01,  -6.80332482e-02,  -1.48819208e-01,\n",
      "           3.24346483e-01,  -3.21275324e-01],\n",
      "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "           0.00000000e+00,   0.00000000e+00],\n",
      "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "           0.00000000e+00,   0.00000000e+00],\n",
      "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "           0.00000000e+00,   0.00000000e+00]],\n",
      "\n",
      "       [[ -5.32830894e-01,  -6.86394982e-04,  -7.80673327e-06,\n",
      "           3.99099708e-01,  -3.77700984e-01],\n",
      "        [ -8.35911155e-01,  -1.94387132e-04,  -8.87755778e-06,\n",
      "           5.16412914e-01,  -5.56405425e-01],\n",
      "        [ -9.43687737e-01,  -5.49392789e-05,  -9.01896692e-06,\n",
      "           5.53423047e-01,  -6.12843633e-01],\n",
      "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "           0.00000000e+00,   0.00000000e+00],\n",
      "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "           0.00000000e+00,   0.00000000e+00]],\n",
      "\n",
      "       [[ -6.31069481e-01,  -1.21423136e-06,  -1.68010703e-10,\n",
      "           4.90644455e-01,  -4.96637374e-01],\n",
      "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "           0.00000000e+00,   0.00000000e+00],\n",
      "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "           0.00000000e+00,   0.00000000e+00],\n",
      "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "           0.00000000e+00,   0.00000000e+00],\n",
      "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "           0.00000000e+00,   0.00000000e+00]]], dtype=float32),\n",
      "    array([[[  1.24267489e-01,   1.78541094e-01,  -1.71508417e-01,\n",
      "           2.81051099e-01,  -7.26445988e-02],\n",
      "        [ -1.67596457e-03,   4.45160456e-02,  -1.97791427e-01,\n",
      "           2.57634968e-01,   2.10252609e-02],\n",
      "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "           0.00000000e+00,   0.00000000e+00],\n",
      "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "           0.00000000e+00,   0.00000000e+00],\n",
      "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "           0.00000000e+00,   0.00000000e+00]],\n",
      "\n",
      "       [[ -5.03277220e-02,   1.75272362e-05,  -2.79875118e-02,\n",
      "           4.72047091e-01,   2.46716524e-03],\n",
      "        [ -2.35967580e-02,   2.00210638e-06,  -1.52870780e-02,\n",
      "           3.07371467e-01,   7.56622292e-04],\n",
      "        [ -8.53256602e-03,   1.91143272e-07,  -8.27305298e-03,\n",
      "           1.45868599e-01,   1.89574115e-04],\n",
      "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "           0.00000000e+00,   0.00000000e+00],\n",
      "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "           0.00000000e+00,   0.00000000e+00]],\n",
      "\n",
      "       [[ -1.21261505e-03,   2.49434751e-10,  -1.27349584e-03,\n",
      "           9.54264849e-02,   7.59069826e-06],\n",
      "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "           0.00000000e+00,   0.00000000e+00],\n",
      "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "           0.00000000e+00,   0.00000000e+00],\n",
      "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "           0.00000000e+00,   0.00000000e+00],\n",
      "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "           0.00000000e+00,   0.00000000e+00]]], dtype=float32))\n",
      "(   LSTMStateTuple(c=array([[ -5.65295994e-01,  -5.72388887e-01,  -1.90474868e-01,\n",
      "          9.01396155e-01,  -8.22192430e-01],\n",
      "       [ -1.91230536e+00,  -1.03175068e+00,  -9.03367709e-06,\n",
      "          2.80104661e+00,  -2.54744005e+00],\n",
      "       [ -7.46379375e-01,  -9.99879003e-01,  -1.68053418e-10,\n",
      "          9.95626688e-01,  -9.59527314e-01]], dtype=float32), h=array([[ -3.71729225e-01,  -6.80332482e-02,  -1.48819208e-01,\n",
      "          3.24346483e-01,  -3.21275324e-01],\n",
      "       [ -9.43687737e-01,  -5.49392789e-05,  -9.01896692e-06,\n",
      "          5.53423047e-01,  -6.12843633e-01],\n",
      "       [ -6.31069481e-01,  -1.21423136e-06,  -1.68010703e-10,\n",
      "          4.90644455e-01,  -4.96637374e-01]], dtype=float32)),\n",
      "    LSTMStateTuple(c=array([[  1.89273372e-01,   3.36794853e-01,  -3.30470562e-01,\n",
      "          4.17684495e-01,  -1.58476487e-01],\n",
      "       [ -1.66650224e+00,   4.43851517e-04,  -2.81311292e-02,\n",
      "          5.12701213e-01,   4.01403848e-03],\n",
      "       [ -8.94758701e-01,   1.86224440e-07,  -1.27353042e-03,\n",
      "          9.57177430e-02,   1.01993073e-05]], dtype=float32), h=array([[  1.24267489e-01,   1.78541094e-01,  -1.71508417e-01,\n",
      "          2.81051099e-01,  -7.26445988e-02],\n",
      "       [ -5.03277220e-02,   1.75272362e-05,  -2.79875118e-02,\n",
      "          4.72047091e-01,   2.46716524e-03],\n",
      "       [ -1.21261505e-03,   2.49434751e-10,  -1.27349584e-03,\n",
      "          9.54264849e-02,   7.59069826e-06]], dtype=float32)))\n"
     ]
    }
   ],
   "source": [
    "# bi-directional rnn\n",
    "with tf.variable_scope('bi-directional') as scope:\n",
    "    cell_fw = rnn.BasicLSTMCell(num_units=5, state_is_tuple=True)\n",
    "    cell_bw = rnn.BasicLSTMCell(num_units=5, state_is_tuple=True)\n",
    "    outputs, states = tf.nn.bidirectional_dynamic_rnn(cell_fw, cell_bw, x_data,\n",
    "                                                      sequence_length=[2, 3, 1],\n",
    "                                                      dtype=tf.float32)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    pp.pprint(sess.run(outputs))\n",
    "    pp.pprint(sess.run(states))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03. hidden_size=3 , sequence_length=5 , batch_size=3 , num_classes=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flattern based softmax\n",
    "hidden_size=3\n",
    "sequence_length=5\n",
    "batch_size=3\n",
    "num_classes=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[[  0.,   1.,   2.],\n",
      "        [  3.,   4.,   5.],\n",
      "        [  6.,   7.,   8.],\n",
      "        [  9.,  10.,  11.],\n",
      "        [ 12.,  13.,  14.]],\n",
      "\n",
      "       [[ 15.,  16.,  17.],\n",
      "        [ 18.,  19.,  20.],\n",
      "        [ 21.,  22.,  23.],\n",
      "        [ 24.,  25.,  26.],\n",
      "        [ 27.,  28.,  29.]],\n",
      "\n",
      "       [[ 30.,  31.,  32.],\n",
      "        [ 33.,  34.,  35.],\n",
      "        [ 36.,  37.,  38.],\n",
      "        [ 39.,  40.,  41.],\n",
      "        [ 42.,  43.,  44.]]], dtype=float32)\n",
      "array([[  0.,   1.,   2.],\n",
      "       [  3.,   4.,   5.],\n",
      "       [  6.,   7.,   8.],\n",
      "       [  9.,  10.,  11.],\n",
      "       [ 12.,  13.,  14.],\n",
      "       [ 15.,  16.,  17.],\n",
      "       [ 18.,  19.,  20.],\n",
      "       [ 21.,  22.,  23.],\n",
      "       [ 24.,  25.,  26.],\n",
      "       [ 27.,  28.,  29.],\n",
      "       [ 30.,  31.,  32.],\n",
      "       [ 33.,  34.,  35.],\n",
      "       [ 36.,  37.,  38.],\n",
      "       [ 39.,  40.,  41.],\n",
      "       [ 42.,  43.,  44.]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(x_data) # hidden_size=3, sequence_length=4, batch_size=2\n",
    "x_data = x_data.reshape(-1, hidden_size)\n",
    "pp.pprint(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[[   25.,    28.,    31.,    34.,    37.],\n",
      "        [   70.,    82.,    94.,   106.,   118.],\n",
      "        [  115.,   136.,   157.,   178.,   199.],\n",
      "        [  160.,   190.,   220.,   250.,   280.],\n",
      "        [  205.,   244.,   283.,   322.,   361.]],\n",
      "\n",
      "       [[  250.,   298.,   346.,   394.,   442.],\n",
      "        [  295.,   352.,   409.,   466.,   523.],\n",
      "        [  340.,   406.,   472.,   538.,   604.],\n",
      "        [  385.,   460.,   535.,   610.,   685.],\n",
      "        [  430.,   514.,   598.,   682.,   766.]],\n",
      "\n",
      "       [[  475.,   568.,   661.,   754.,   847.],\n",
      "        [  520.,   622.,   724.,   826.,   928.],\n",
      "        [  565.,   676.,   787.,   898.,  1009.],\n",
      "        [  610.,   730.,   850.,   970.,  1090.],\n",
      "        [  655.,   784.,   913.,  1042.,  1171.]]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "softmax_w = np.arange(15, dtype=np.float32).reshape(hidden_size, num_classes)\n",
    "outputs = np.matmul(x_data, softmax_w)\n",
    "outputs = outputs.reshape(-1, sequence_length, num_classes) # batch, seq, class\n",
    "pp.pprint(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [batch_size, sequence_length]\n",
    "y_data = tf.constant([[1, 1, 1]])\n",
    "# [batch_size, sequence_length, emb_dim ]\n",
    "prediction = tf.constant([[[0.2, 0.7], [0.6, 0.2], [0.2, 0.9]]], dtype=tf.float32)\n",
    "# [batch_size * sequence_length]\n",
    "weights = tf.constant([[1, 1, 1]], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.596759\n"
     ]
    }
   ],
   "source": [
    "# sequence 데이터를 연산한다\n",
    "# .sequence_loss( logits=예측값 , targets=목표값(seq) , weights= [,,,] 형태로 입력 )\n",
    "sequence_loss = tf.contrib.seq2seq.sequence_loss(logits=prediction, targets=y_data, weights=weights)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(\"Loss: \", sequence_loss.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [batch_size, sequence_length]\n",
    "y_data = tf.constant([[1, 1, 1]])\n",
    "# [batch_size, sequence_length, emb_dim ]\n",
    "prediction1 = tf.constant([[[0.3, 0.7], [0.3, 0.7], [0.3, 0.7]]], dtype=tf.float32)\n",
    "prediction2 = tf.constant([[[0.1, 0.9], [0.1, 0.9], [0.1, 0.9]]], dtype=tf.float32)\n",
    "prediction3 = tf.constant([[[1, 0], [1, 0], [1, 0]]], dtype=tf.float32)\n",
    "prediction4 = tf.constant([[[0, 1], [1, 0], [0, 1]]], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [batch_size * sequence_length]\n",
    "weights = tf.constant([[1, 1, 1]], dtype=tf.float32)\n",
    "sequence_loss1 = tf.contrib.seq2seq.sequence_loss(prediction1, y_data, weights)\n",
    "sequence_loss2 = tf.contrib.seq2seq.sequence_loss(prediction2, y_data, weights)\n",
    "sequence_loss3 = tf.contrib.seq2seq.sequence_loss(prediction3, y_data, weights)\n",
    "sequence_loss4 = tf.contrib.seq2seq.sequence_loss(prediction3, y_data, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss1:  0.513015 Loss2:  0.371101 Loss3:  1.31326 Loss4:  1.31326\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "print(\"Loss1: \", sequence_loss1.eval(),\n",
    "      \"Loss2: \", sequence_loss2.eval(),\n",
    "      \"Loss3: \", sequence_loss3.eval(),\n",
    "      \"Loss4: \", sequence_loss4.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cell을 구동\n",
    "- rnn_size : Output 의 크기값(4)을 입력 <p></p></br>\n",
    "<img src=\"./img/RNNt-004.png\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    outputs, state = tf.nn.rnn(cell = rnn_cell, inputs = x_split, initial_state = initial_state)\n",
    "- 세부 작동내용 확인 \n",
    "- time Step size :  모델의 갯수 (여기선 rnn_size와 동일) </br></br><p>\n",
    "<img src = \"./img/RNNt-009.png\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    x_split = tf.split(0, len(char_dic), x_data) # 가로축으로 4개로 split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cost Functions\n",
    "### 01. Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- logits, targets, weights 별로 사이즈를 맞춰야만 작동이 된다\n",
    "\n",
    "\n",
    "    logits = tf.reshape(tf.concat(1, outputs), # shape = 1 x 16\n",
    "                        [-1, rnn_size])        # shape = 4 x 4 (2D [batcha_size * num_decoder_symbols])\n",
    "    targets = tf.reshape(ground_truth[1:], [-1]) # a shape of [-1] flattens into 1-D\n",
    "    weights = tf.ones([len(char_dic) * batch_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- loss 함수 (개별적 모듈에 적용)\n",
    "- cost 함수 (batch size 별로 적용)\n",
    "\n",
    "\n",
    "    loss = tf.nn.seq2seq.sequence_loss_by_example([logits], [targets], [weights])\n",
    "    cost = tf.reduce_sum(loss) / batch_size\n",
    "    train_op = tf.train.RMSPropOptimizer(0.01, 0.9).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Launch the graph in a session\n",
    "\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        tf.initialize_all_variables().run()\n",
    "        for i in range(100):\n",
    "            sess.run(train_op)\n",
    "            result = sess.run(tf.argmax(logits, 1))\n",
    "            print(result, [char_rdic[t] for t in result])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02. Hi Hello Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lab 12 RNN\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.set_random_seed(777)  # reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 파라미터를 정의\n",
    "num_classes = 5\n",
    "input_dim = 5  # one-hot size\n",
    "hidden_size = 5  # output from the LSTM. 5 to directly predict one-hot\n",
    "batch_size = 1   # one sentence\n",
    "sequence_length = 6  # |ihello| == 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx2char = ['h', 'i', 'e', 'l', 'o']\n",
    "# Teach hello: hihell -> ihello\n",
    "x_data = [[0, 1, 0, 2, 3, 3]]   # hihell\n",
    "# x_data를 onehot으로 치환\n",
    "x_one_hot = [[[1, 0, 0, 0, 0],   # h 0\n",
    "              [0, 1, 0, 0, 0],   # i 1\n",
    "              [1, 0, 0, 0, 0],   # h 0\n",
    "              [0, 0, 1, 0, 0],   # e 2\n",
    "              [0, 0, 0, 1, 0],   # l 3\n",
    "              [0, 0, 0, 1, 0]]]  # l 3\n",
    "y_data = [[1, 0, 2, 3, 3, 4]]    # ihello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, sequence_length, input_dim])  # X one-hot\n",
    "Y = tf.placeholder(tf.int32, [None, sequence_length])  # Y label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cell = tf.contrib.rnn.BasicLSTMCell(num_units=hidden_size, state_is_tuple=True)\n",
    "initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "outputs, _states = tf.nn.dynamic_rnn(cell, X, initial_state=initial_state, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FC layer\n",
    "X_for_fc = tf.reshape(outputs, [-1, hidden_size])\n",
    "# fc_w = tf.get_variable(\"fc_w\", [hidden_size, num_classes])\n",
    "# fc_b = tf.get_variable(\"fc_b\", [num_classes])\n",
    "# outputs = tf.matmul(X_for_fc, fc_w) + fc_b\n",
    "outputs = tf.contrib.layers.fully_connected( inputs=X_for_fc, num_outputs=num_classes, activation_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape out for sequence_loss\n",
    "outputs = tf.reshape(outputs, [batch_size, sequence_length, num_classes])\n",
    "weights = tf.ones([batch_size, sequence_length])\n",
    "sequence_loss = tf.contrib.seq2seq.sequence_loss(logits=outputs, targets=Y, weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(sequence_loss)\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.1).minimize(loss)\n",
    "prediction = tf.argmax(outputs, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss: 1.65056 prediction:  [[3 3 3 3 3 3]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  llllll\n",
      "1 loss: 1.52608 prediction:  [[3 3 3 3 3 3]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  llllll\n",
      "2 loss: 1.45652 prediction:  [[3 3 3 3 3 3]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  llllll\n",
      "3 loss: 1.39797 prediction:  [[3 3 3 3 3 3]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  llllll\n",
      "4 loss: 1.31818 prediction:  [[3 3 3 3 3 3]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  llllll\n",
      "5 loss: 1.20625 prediction:  [[3 0 3 3 3 3]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  lhllll\n",
      "6 loss: 1.08421 prediction:  [[1 0 0 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihhllo\n",
      "7 loss: 0.973617 prediction:  [[1 0 0 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihhllo\n",
      "8 loss: 0.872481 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "9 loss: 0.781866 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "10 loss: 0.696431 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "11 loss: 0.601939 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "12 loss: 0.5185 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "13 loss: 0.437557 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "14 loss: 0.368346 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "15 loss: 0.30549 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "16 loss: 0.241391 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "17 loss: 0.186702 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "18 loss: 0.144434 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "19 loss: 0.110295 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "20 loss: 0.0845748 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "21 loss: 0.065407 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "22 loss: 0.0501638 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "23 loss: 0.0387273 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "24 loss: 0.0304702 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "25 loss: 0.0243975 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "26 loss: 0.0198245 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "27 loss: 0.0163305 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "28 loss: 0.0136335 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "29 loss: 0.0115294 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "30 loss: 0.00986656 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "31 loss: 0.00853353 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "32 loss: 0.00744955 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "33 loss: 0.00655667 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "34 loss: 0.00581313 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "35 loss: 0.00518885 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "36 loss: 0.00466143 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "37 loss: 0.00421356 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "38 loss: 0.00383184 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "39 loss: 0.00350527 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "40 loss: 0.00322512 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "41 loss: 0.00298414 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "42 loss: 0.0027761 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "43 loss: 0.00259598 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "44 loss: 0.00243948 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "45 loss: 0.0023028 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "46 loss: 0.00218285 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "47 loss: 0.00207697 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "48 loss: 0.00198299 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "49 loss: 0.00189902 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(50):\n",
    "        l, _ = sess.run([loss, train], feed_dict={X: x_one_hot, Y: y_data})\n",
    "        result = sess.run(prediction, feed_dict={X: x_one_hot})\n",
    "        print(i, \"loss:\", l, \"prediction: \", result, \"true Y: \", y_data)\n",
    "\n",
    "        # print char using dic\n",
    "        result_str = [idx2char[c] for c in np.squeeze(result)]\n",
    "        print(\"\\tPrediction str: \", ''.join(result_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 22.  28.]\n",
      " [ 49.  64.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# Creates a graph.\n",
    "a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "c = tf.matmul(a, b)\n",
    "# Creates a session with log_device_placement set to True.\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# Runs the op.\n",
    "print(sess.run(c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 22.  28.]\n",
      " [ 49.  64.]]\n"
     ]
    }
   ],
   "source": [
    "# Creates a graph.\n",
    "with tf.device('/gpu:0'):\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "    c = tf.matmul(a, b)\n",
    "# Creates a session with log_device_placement set to True.\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# Runs the op.\n",
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (10) : invalid device ordinal at torch/csrc/cuda/Module.cpp:84",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e1dd4680ed5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# y.get_device() == 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m# allocates a tensor on GPU 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/markbaum/Python/python36/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev_idx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_setDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (10) : invalid device ordinal at torch/csrc/cuda/Module.cpp:84"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.cuda.FloatTensor(1)\n",
    "# x.get_device() == 0\n",
    "y = torch.FloatTensor(1).cuda()\n",
    "# y.get_device() == 0\n",
    "\n",
    "with torch.cuda.device(1):\n",
    "    # allocates a tensor on GPU 1\n",
    "    a = torch.cuda.FloatTensor(1)\n",
    "    # transfers a tensor from CPU to GPU 1\n",
    "    b = torch.FloatTensor(1).cuda()\n",
    "    # a.get_device() == b.get_device() == 1\n",
    "    c = a + b\n",
    "    # c.get_device() == 1\n",
    "    z = x + y\n",
    "    # z.get_device() == 0\n",
    "    # even within a context, you can give a GPU id to the .cuda call\n",
    "    d = torch.randn(2).cuda(2)\n",
    "    # d.get_device() == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from data_parallel import DataParallel\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=256, shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "model = DataParallel(Net())\n",
    "model.cuda()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = nn.NLLLoss().cuda()\n",
    "\n",
    "model.train()\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    input_var = Variable(data.cuda())\n",
    "    target_var = Variable(target.cuda())\n",
    "\n",
    "    print('Getting model output')\n",
    "    output = model(input_var)\n",
    "    print('Got model output')\n",
    "\n",
    "    loss = criterion(output, target_var)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print('Finished')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
