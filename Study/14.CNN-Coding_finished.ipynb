{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ch14 CNN with TensorFlow\n",
    "- http://pythonkim.tistory.com/56\n",
    "- http://sanghyukchun.github.io/75/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "<!-- <img src=\"./img/cnn-016.png\" align=\"left\"> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "CNN Model\n",
    "   1. 직선적 Filter 모델\n",
    "   2. 불연속적인 Image 데이터를 필터링/ 학습/ 테스트에 용이\n",
    "   3. CNN 은 이미지 핵심 정보를 효과적으로 추출 (기울기, 회전, 노이즈에도 인식 가능)\n",
    "      1. Convolution layer : 이미지 벡터에 filter적용 (by stride) \n",
    "      2. Pooling Layer (Subsamplig) : by 평균값/ 최댓값 </br><p></p>\n",
    "<img src=\"./img/K-003.png\" align=\"left\" width = 700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"./img/cnn-75-11.png\" align=\"left\"><img src = \"./img/cnn-75-13.png\" align=\"left\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Simple Convolution Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01. 원본 이미지 만들기\n",
    "- (3 x 3 x 1 ) 이미지크기 3 x 3 \n",
    "- (2 x 2 x 1 ) 필터 2 x 2\n",
    "- (1 x 1) 스트라이드 이동<p></p>\n",
    "<img src = \"./img/Lab11-CNN01.png\" align = \"left\" width = 450>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 원본 이미지 만들기\n",
    "image = np.array([[[[1],[2],[3]],\n",
    "                   [[4],[5],[6]],\n",
    "                   [[7],[8],[9]]]], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (이미지 갯수, 3 x 3 (array) , 칼러) \n",
    "# 이미지 shape를 출력\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2cb90857b8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ8AAAD8CAYAAABpXiE9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhoekJoaHpCaGh6QmhoekJv8PCCQPV9d2xkgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2cdcb45fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image.reshape(3,3), cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02. padding = \"VALID\"\n",
    "- Data (Image)   : [ 이미지 갯수 , x , y , 칼러]\n",
    "- Weight (Fiter) : [ x , y , 칼러 , 필터]\n",
    "- 원본 이미지에, 2x2 filter 를 , 1 stride 간격으로 적용<p></p>\n",
    "<img src = \"./img/cnncode_2017-05-13.png\" align= \"left\" width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imag:\n",
      " [[[[ 1.]\n",
      "   [ 2.]\n",
      "   [ 3.]]\n",
      "\n",
      "  [[ 4.]\n",
      "   [ 5.]\n",
      "   [ 6.]]\n",
      "\n",
      "  [[ 7.]\n",
      "   [ 8.]\n",
      "   [ 9.]]]]\n"
     ]
    }
   ],
   "source": [
    "# Matrix 로 Image를 출력\n",
    "print(\"imag:\\n\", image)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w(filter).shape (2, 2, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "weight = tf.constant([[[[1.]],[[1.0]]],\n",
    "                     [[[1.]],[[1.]]]])\n",
    "print(\"w(filter).shape\", weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "# tf.nn.conv2d( 원본 이미지, Weight(filter), strides = [필터적용 stirde map 값], padding = 내용)\n",
    "# strides [ 이미지갯수 , x , y , layer수]\n",
    "conv2d = tf.nn.conv2d(image, weight, strides=[1, 1, 1, 1], padding='VALID')  # 원소스는 padding='SAME')\n",
    "conv2d_img = conv2d.eval()\n",
    "print(conv2d_img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.nn.conv2d(input, filter, strides, padding, use_cudnn_on_gpu=None, data_format=None, name=None)\n",
    "\n",
    "- input : [batch, in_height, in_width, in_channels] 형식. 28x28x1 형식의 손글씨 이미지.\n",
    "- filter : [filter_height, filter_width, in_channels, out_channels] 형식. 3, 3, 1, 32의 w.\n",
    "- strides : 크기 4인 1차원 리스트. [0], [3]은 반드시 1. 일반적으로 [1], [2]는 같은 값 사용.\n",
    "- padding : 'SAME' 또는 'VALID'. 패딩을 추가하는 공식의 차이. SAME은 출력 크기를 입력과 같게 유지.\n",
    "\n",
    "3x3x1 필터를 32개 만드는 것을 코드로 표현하면 [3, 3, 1, 32]가 된다. 순서대로 너비(3), 높이(3), 입력 채널(1), 출력 채널(32)을 뜻한다. 32개의 출력이 만들어진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 12.  16.]\n",
      " [ 24.  28.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAM0AAAC7CAYAAADGxxq1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2cb4a50ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reshape( Filter 적용가능한 Matrix 크기값 입력)\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(2,2))\n",
    "    plt.subplot(1,2,i+1), plt.imshow(one_img.reshape(2,2), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03. padding = \"SAME\"\n",
    "- Data (Image)   : [ 이미지 갯수 , x , y , 칼러]\n",
    "- Weight (Fiter) : [ x , y , 칼러 , 필터]\n",
    "    1. 원본 이미지에, 2x2 filter 를 , 1 stride 간격으로 적용\n",
    "    2. Zero Padding 을 이용해서 크기를 맞춘다.<p></p>\n",
    "<img src = \"./img/cnncode-111.png\" align= \"left\" width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image.shape (1, 3, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "# Matrix 로 Image를 출력\n",
    "print(\"image.shape\", image.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w(filter).shape (2, 2, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "weight = tf.constant([[[[1.]],[[1.]]],\n",
    "                     [[[1.]],[[1.]]]])\n",
    "print(\"w(filter).shape\", weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "# strides [ 이미지갯수 , x , y , layer수]\n",
    "conv2d = tf.nn.conv2d(image, weight, strides=[1, 1, 1, 1], padding='SAME')  # 원소스는 padding='SAME')\n",
    "conv2d_img = conv2d.eval()\n",
    "print(conv2d_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 12.  16.   9.]\n",
      " [ 24.  28.  15.]\n",
      " [ 15.  17.   9.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMkAAAC7CAYAAADPLLrPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAACVlJREFUeJzt3X+IZXUZx/H3J1enRavdWnGX1VyjRbIfkI6jIsiSCbqI\nK2Sw/pE/UAZE6QcFaYFBkFh/FMmGsajYRKhhMW2ysRhaGqXsKOuPXVmdJHBtwxxzt0VbmXr6457q\nepuZZ93z3e+9M/N5wWXPufe79/kehg/nnnPPfY4iAjOb3bv6PQGzQeeQmCUcErOEQ2KWcEjMEg6J\nWaJVSCS9X9KDkl5o/l0+y7h/StrRPLa0qWlWm9p8TyLpO8BrEXGrpBuB5RHx1RnGHYiI41rM06xv\n2oZkN7AuIvZKWgX8JiJOnWGcQ2LzVttjkhMiYm+z/BfghFnGvVvShKTHJF3asqZZVUuyAZJ+Dayc\n4aWvd69EREiabbd0ckS8LOlDwEOSnomIP85QaxQYbZbPGBoaSjdgPjj22GP7PYVipqam+j2Fkl6N\niOOzQVU+bvX8n7uBByLi/rnGLV26NNasWXPYcxskIyMj/Z5CMWNjY/2eQklPRMRwNqjtx60twJXN\n8pXAL3oHSFouaahZXgGcC+xqWdesmrYhuRW4QNILwKebdSQNS7qjGfMRYELSU8DDwK0R4ZDYvJEe\nk8wlIqaA82d4fgK4tln+PfDxNnXM+snfuJslHBKzhENilnBIzBIOiVnCITFLOCRmCYfELOGQmCUc\nErOEQ2KWcEjMEg6JWcIhMUs4JGYJh8Qs4ZCYJYqERNKFknZLmmya1PW+PiTpvub1xyWtKVHXrIbW\nIZF0FPAD4CLgNOBySaf1DLsG+FtEfBj4HvDttnXNaimxJxkBJiPixYh4C7gX2NAzZgPwo2b5fuB8\nSSpQ2+yIKxGS1cBLXet7mudmHBMR08A+4AO9byRptOn0ODE9PV1gambtDdSBe0RsjojhiBhesqRV\nIxezYkqE5GXgpK71E5vnZhwjaQnwPmBB9cu0hatESLYDayWdIukYYCOdzo7dujs9XgY8FL43ts0T\nrT/TRMS0pBuAbcBRwF0RsVPSN4GJiNgC3An8WNIk8BqdIJnNC0U++EfEVmBrz3M3dy3/A/hsiVpm\ntQ3UgbvZIHJIzBIOiVnCITFLOCRmCYfELOGQmCUcErOEQ2KWcEjMEg6JWcIhMUs4JGYJh8Qs4ZCY\nJRwSs0St5nRXSfqrpB3N49oSdc1qaP3LxK7mdBfQaSe0XdKWiNjVM/S+iLihbT2z2mo1pzObt0r8\nxn2m5nRnzTDuM5LOA54HvhQRL/UOkDQKjAKsXLmSsbGxAtPrvzPPPLPfUyhm//79/Z5CMePj44c0\nrtaB+y+BNRHxCeBB/tfy9G26m9MtW7as0tTM5lalOV1ETEXEwWb1DuCMAnXNqqjSnE7Sqq7VS4Dn\nCtQ1q6JWc7rPS7oEmKbTnO6qtnXNaqnVnO4m4KYStcxq8zfuZgmHxCzhkJglHBKzhENilnBIzBIO\niVnCITFLOCRmCYfELOGQmCUcErOEQ2KWcEjMEg6JWcIhMUuUak53l6RXJD07y+uSdFvTvO5pSaeX\nqGtWQ6k9yd3AhXO8fhGwtnmMArcXqmt2xBUJSUQ8Que367PZAIxFx2PAsp7mEGYDq9YxyUwN7FZX\nqm3WykAduEsalTQhaeL111/v93TMgHohSRvYgTs42mCqFZItwBXNWa6zgX0RsbdSbbNWivTdknQP\nsA5YIWkP8A3gaICI+CGdnlzrgUngDeDqEnXNaijVnO7y5PUAri9Ry6y2gTpwNxtEDolZwiExSzgk\nZgmHxCzhkJglHBKzhENilnBIzBIOiVnCITFLOCRmCYfELOGQmCUcErOEQ2KWcEjMErU6OK6TtE/S\njuZxc4m6ZjUU+fkunQ6Om4CxOcY8GhEXF6pnVk2tDo5m81apPcmhOEfSU8Cfga9ExM7eAZJG6fQK\nZunSpdxyyy0Vp3fkrF69cJpVjo+P93sK1dUKyZPAyRFxQNJ6YJxO8+y3iYjNwGaA5cuXR6W5mc2p\nytmtiNgfEQea5a3A0ZJW1Kht1laVkEhaKUnN8khTd6pGbbO2anVwvAy4TtI08CawsWlYZzbwanVw\n3ETnFLHZvONv3M0SDolZwiExSzgkZgmHxCzhkJglHBKzhENilnBIzBIOiVnCITFLOCRmCYfELOGQ\nmCUcErOEQ2KWaB0SSSdJeljSLkk7JX1hhjGSdJukSUlPSzq9bV2zWkr8MnEa+HJEPCnpPcATkh6M\niF1dYy6i0x1lLXAWcHvzr9nAa70niYi9EfFks/x34Dmgt9HUBmAsOh4Dlkla1ba2WQ1Fj0kkrQE+\nCTze89Jq4KWu9T38f5CQNCppQtLEwYMHS07N7LAVC4mk44CfAV+MiP2H8x4RsTkihiNieGhoqNTU\nzFop1VX+aDoB+UlE/HyGIS8DJ3Wtn9g8ZzbwSpzdEnAn8FxEfHeWYVuAK5qzXGcD+yJib9vaZjWU\nOLt1LvA54BlJO5rnvgZ8EP7bnG4rsB6YBN4Ari5Q16yK1iGJiN8BSsYEcH3bWmb94G/czRIOiVnC\nITFLOCRmCYfELOGQmCUcErOEQ2KWcEjMEg6JWcIhMUs4JGYJh8Qs4ZCYJRwSs4RDYpao1ZxunaR9\nknY0j5vb1jWrpVZzOoBHI+LiAvXMqqrVnM5s3qrVnA7gHElPSfqVpI+WrGt2JKnTo6HAG3Wa0/0W\n+FZv7y1J7wX+FREHJK0Hvh8Ra2d4j1FgtFk9FdhdZHJzWwG8WqFODQtlW2ptx8kRcXw2qEhImuZ0\nDwDb5ui91T3+T8BwRPT9DyppIiKG+z2PEhbKtgzadlRpTidpZTMOSSNN3am2tc1qqNWc7jLgOknT\nwJvAxij1Oc/sCKvVnG4TsKltrSNkc78nUNBC2ZaB2o5iB+5mC5UvSzFLLNqQSLpQ0u7mPo439ns+\nh0vSXZJekfRsv+fS1qFc4tQPi/LjlqSjgOeBC+jcdWs7cPkMl9IMPEnnAQfo3G7vY/2eTxvNLQJX\ndV/iBFza77/LYt2TjACTEfFiRLwF3Evnvo7zTkQ8ArzW73mUMKiXOC3WkBzSPRytf5JLnKparCGx\nAVbi/pslLdaQ+B6OA+oQ7r9Z3WINyXZgraRTJB0DbKRzX0fro0O8/2Z1izIkETEN3ABso3Nw+NOI\n2NnfWR0eSfcAfwBOlbRH0jX9nlML/7nE6VNdv2Jd3+9JLcpTwGbvxKLck5i9Ew6JWcIhMUs4JGYJ\nh8Qs4ZCYJRwSs4RDYpb4N4b3ASxEXpwlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2cb90dbdd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reshape( 원본 이미지 크기 Matrix )\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(3,3))\n",
    "    plt.subplot(1,2,i+1), plt.imshow(one_img.reshape(3,3), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04. Simple Convolution Layer 03\n",
    "- Weight (Fiter) : [ x , y , 칼러 , 필터 3개 적용]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w(filter).shape (2, 2, 1, 3)\n"
     ]
    }
   ],
   "source": [
    "weight = tf.constant([[[[1.,10,-1.]],[[1.,10,-1.]]],\n",
    "                     [[[1.,10,-1.]],[[1.,10,-1.]]]])\n",
    "print(\"w(filter).shape\", weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "# strides [ 이미지갯수 , x , y , layer수]\n",
    "conv2d = tf.nn.conv2d(image, weight, strides=[1, 1, 1, 1], padding='SAME')  # 원소스는 padding='SAME')\n",
    "conv2d_img = conv2d.eval()\n",
    "print(conv2d_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 12.  16.   9.]\n",
      " [ 24.  28.  15.]\n",
      " [ 15.  17.   9.]]\n",
      "[[ 120.  160.   90.]\n",
      " [ 240.  280.  150.]\n",
      " [ 150.  170.   90.]]\n",
      "[[-12. -16.  -9.]\n",
      " [-24. -28. -15.]\n",
      " [-15. -17.  -9.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAACFCAYAAAB7VhJ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNwAkQ3EDQDIUNwAkQ3EDQDIUNwAk828FNQf8XgjbqwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2cb3979860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reshape( 원본 이미지 크기 Matrix )\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(3,3))\n",
    "    plt.subplot(1,3,i+1), plt.imshow(one_img.reshape(3,3), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Max Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    CNN model은 여러 convolution layer가 결합되므로  \n",
    "    공식적으로는 layer, filter를 ==> kernel이라 하고. \n",
    "    kernel들이 모임을 ==> 한 layer로 부른다.\n",
    "   http://masters.donntu.org/2012/fknt/umiarov/diss/indexe.htm#p4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 4.],\n",
       "         [ 3.]],\n",
       "\n",
       "        [[ 2.],\n",
       "         [ 1.]]]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = np.array([[[[4],[3]],\n",
    "                    [[2],[1]]]], dtype=np.float32)\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01. padding = 'VALID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 1, 1)\n",
      "[[[[ 4.]]]]\n"
     ]
    }
   ],
   "source": [
    "pool = tf.nn.max_pool(image, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 1, 1, 1], padding='VALID')\n",
    "print(pool.shape)\n",
    "print(pool.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02. padding = 'SAME'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 2, 1)\n",
      "[[[[ 4.]\n",
      "   [ 3.]]\n",
      "\n",
      "  [[ 2.]\n",
      "   [ 1.]]]]\n"
     ]
    }
   ],
   "source": [
    "# padding = 'SAME'\n",
    "pool = tf.nn.max_pool(image, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 1, 1, 1], padding='SAME')\n",
    "print(pool.shape)\n",
    "print(pool.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. MNIST 에 CNN 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# MNIST 데이터 불러오기\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2c99b4a5c0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nV4sVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2c99bb5be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mnist.train.images[0]\n",
    "img = mnist.train.images[54999].reshape(28,28)\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01. MNIST Convolution Layer (by TensorFlow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using TensorFlow\n",
    "# Image index  : (-1번쨰 이미지, 28 x 28, 1 (color))\n",
    "sess = tf.InteractiveSession()\n",
    "img = img.reshape(-1,28,28,1)                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Conv2D_7:0\", shape=(1, 10, 10, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Kernel(filter) index : ( 3 x 3 , 1(color), 5(필터갯수))\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 5], stddev=0.01))        \n",
    "# Stride index : ( 이미지, 2 x 2 ,1(필터갯수))\n",
    "conv2d = tf.nn.conv2d(img, W1, strides=[1, 3, 3, 1], padding='SAME')  \n",
    "print(conv2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAABcCAYAAABOZ1+dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJVI1NeMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2c9921bbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "conv2d_img = conv2d.eval()    # eval(파이썬명령) : 문자열로 된 파이썬 명령을 실행\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    # 5개 filter를 적용한 5개 이미지를 출력\n",
    "    plt.subplot(1,5,i+1), plt.imshow(one_img.reshape(10,10), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02. MNIST Max Pooling (by TensorFlow)\n",
    "- SubSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MaxPool_2:0\", shape=(1, 7, 7, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "pool = tf.nn.max_pool(conv2d,                # 14 x 14원본 이미지\n",
    "                      ksize=[1, 2, 2, 1],    # Kernal size\n",
    "                      strides=[1, 2, 2, 1],  # 2 x 2 stride 간격 ==> Image는 7 x 7 로 출력\n",
    "                      padding='SAME')\n",
    "print(pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAABcCAYAAABOZ1+dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nx3BwExE55v9LRn0GMQBBVAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2c995999b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pool_img = pool.eval()\n",
    "pool_img = np.swapaxes(pool_img, 0, 3)\n",
    "for i, one_img in enumerate(pool_img):\n",
    "    plt.subplot(1,5,i+1), plt.imshow(one_img.reshape(7, 7), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03. Simple CNN \n",
    " - MNIST (99% 인식률에 도전!!)\n",
    " - Conv : 2개를 생성 \n",
    " - FC 로 마무리 <p></p>\n",
    "<img src = \"./img/Lab11-CNN-33.png\" align = \"left\" width = 700 >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using TensorBoard : http://222.110.23.116:6060/\n",
    "- http://stackoverflow.com/questions/38189119/simple-way-to-visualize-a-tensorflow-graph-in-jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "tf.set_random_seed(777)  # reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "#training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784]) \n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# img 28x28x1 (black/white)\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-1) Conv 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# L1 ImgIn shape = (?, 28, 28, 1)\n",
    "#  Conv & ReLU   -> (?, 28, 28, 32)\n",
    "#  Pool(2x2 stride) -> (?, 14, 14, 32)\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))  # [ 3 x 3 , 1color, 32개 필터를 활용] : shape의 크기 값\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 2, 2, 1], padding='SAME')\n",
    "# Tensor(\"Conv2D:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "# Tensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "# Tensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-2) Conv 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# L2 ImgIn shape = (?, 14, 14, 32)\n",
    "#    Conv & ReLU -> (?, 14, 14, 64)\n",
    "#    Pool        -> (?, 7, 7, 64)\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "#Tensor(\"Conv2D_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "#Tensor(\"Relu_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "#Tensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Fully Connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Final Fully Connected\n",
    "# 최종 연결갯수가 3,136개 \n",
    "L2_flat = tf.reshape(L2, [-1, 7 * 7 * 64])          \n",
    "#Tensor(\"Reshape_1:0\", shape=(?, 3136), dtype=float32)\n",
    "W3 = tf.get_variable(\"W3\", shape=[7 * 7 * 64, 10],  # 3,136개 , 0~ 9의 숫자샘플 \n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b = tf.Variable(tf.random_normal([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# logits = Hypothesis\n",
    "logits = tf.matmul(L2_flat, W3) + b\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Loading MNIST Tensor  ---------------------------------------------\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime.\n",
      "Epoch: 0001 cost = 0.358514333\n",
      "Epoch: 0002 cost = 0.098211916\n",
      "Epoch: 0003 cost = 0.070238326\n",
      "Epoch: 0004 cost = 0.055822760\n",
      "Epoch: 0005 cost = 0.047655358\n",
      "Epoch: 0006 cost = 0.041374029\n",
      "Epoch: 0007 cost = 0.035603068\n",
      "Epoch: 0008 cost = 0.031854277\n",
      "Epoch: 0009 cost = 0.027453821\n",
      "Epoch: 0010 cost = 0.024067590\n",
      "Epoch: 0011 cost = 0.021877891\n",
      "Epoch: 0012 cost = 0.019538247\n",
      "Epoch: 0013 cost = 0.016187267\n",
      "Epoch: 0014 cost = 0.014127988\n",
      "Epoch: 0015 cost = 0.013200664\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9888\n"
     ]
    }
   ],
   "source": [
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "                                        X: mnist.test.images, \n",
    "                                        Y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [0]\n",
      "Prediction:  [0]\n"
     ]
    }
   ],
   "source": [
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(tf.argmax(logits, 1), feed_dict={\n",
    "                                                        X: mnist.test.images[r:r + 1]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwg8ERfiBoAg/EBThB4Ii/EBQhB8I6v8B9ulHEXnRNcwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25eedf54e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "          reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04. Deep CNN  \n",
    " - Conv : 3개를 생성 \n",
    " - FC   : 2개로 마무리 <p></p>\n",
    "<img src = \"./img/Lab11-CNN-333.png\" align = \"left\" width = 700 >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "tf.set_random_seed(777)  # reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 조절변수 설정\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "# dropout (keep_prob) rate  0.7~0.5 on training, but should be 1 for testing\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])   # img 28x28x1 (black/white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# L1 ImgIn shape=(?, 28, 28, 1)\n",
    "#    Conv     -> (?, 28, 28, 32)\n",
    "#    Pool     -> (?, 14, 14, 32)\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1],strides=[1, 2, 2, 1], padding='SAME')\n",
    "L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "# Tensor(\"Conv2D:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "# Tensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "# Tensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
    "# Tensor(\"dropout/mul:0\", shape=(?, 14, 14, 32), dtype=float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# L2 ImgIn shape=(?, 14, 14, 32)\n",
    "#    Conv      ->(?, 14, 14, 64)\n",
    "#    Pool      ->(?, 7, 7, 64)\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1],strides=[1, 2, 2, 1], padding='SAME')\n",
    "L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "# Tensor(\"Conv2D_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "# Tensor(\"Relu_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "# Tensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
    "# Tensor(\"dropout_1/mul:0\", shape=(?, 7, 7, 64), dtype=float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# L3 ImgIn shape=(?, 7, 7, 64)\n",
    "#    Conv      ->(?, 7, 7, 128)\n",
    "#    Pool      ->(?, 4, 4, 128)\n",
    "#    Reshape   ->(?, 4 * 4 * 128) # Flatten them for FC\n",
    "W3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))\n",
    "L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L3 = tf.nn.relu(L3)\n",
    "L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "L3_flat = tf.reshape(L3, [-1, 128 * 4 * 4])\n",
    "# Tensor(\"Conv2D_2:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
    "# Tensor(\"Relu_2:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
    "# Tensor(\"MaxPool_2:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
    "# Tensor(\"dropout_2/mul:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
    "# Tensor(\"Reshape_1:0\", shape=(?, 2048), dtype=float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# L4 FC 4x4x128 inputs -> 625 outputs\n",
    "W4 = tf.get_variable(\"W4\", shape=[128 * 4 * 4, 625],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([625]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3_flat, W4) + b4)\n",
    "L4 = tf.nn.dropout(L4, keep_prob=keep_prob)\n",
    "# Tensor(\"Relu_3:0\", shape=(?, 625), dtype=float32)\n",
    "# Tensor(\"dropout_3/mul:0\", shape=(?, 625), dtype=float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# L5 Final FC 625 inputs -> 10 outputs\n",
    "W5 = tf.get_variable(\"W5\", shape=[625, 10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "logits = tf.matmul(L4, W5) + b5\n",
    "# Tensor(\"add_1:0\", shape=(?, 10), dtype=float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Loading MNIST Tensor  ---------------------------------------------\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime.\n",
      "Epoch: 0001 cost = 0.446621409\n",
      "Epoch: 0002 cost = 0.095134634\n",
      "Epoch: 0003 cost = 0.071754983\n",
      "Epoch: 0004 cost = 0.058670053\n",
      "Epoch: 0005 cost = 0.049495068\n",
      "Epoch: 0006 cost = 0.043176698\n",
      "Epoch: 0007 cost = 0.041006172\n",
      "Epoch: 0008 cost = 0.037053994\n",
      "Epoch: 0009 cost = 0.035015218\n",
      "Epoch: 0010 cost = 0.032333927\n",
      "Epoch: 0011 cost = 0.029966081\n",
      "Epoch: 0012 cost = 0.030528397\n",
      "Epoch: 0013 cost = 0.028782672\n",
      "Epoch: 0014 cost = 0.025811749\n",
      "Epoch: 0015 cost = 0.025037776\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "# Epoch: 0015 cost = 0.024607201\n",
    "# Learning Finished!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9932\n"
     ]
    }
   ],
   "source": [
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}))\n",
    "# Accuracy: 0.9938"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [3]\n",
      "Prediction:  [3]\n"
     ]
    }
   ],
   "source": [
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(logits, 1), feed_dict={X: mnist.test.images[r:r + 1], keep_prob: 1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25ef1185cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "          reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Python 응용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01. Class 모듈 활용\n",
    "<img src = \"./img/Lab11-CNN-class.png\" align = \"left\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:File `'./Lecture/lab-11-3-mnist_cnn_class.py'` not found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 min 0 sec\n"
     ]
    }
   ],
   "source": [
    "# Class를 통한 사용자함수를 정리\n",
    "import time; t1 = int(time.time())\n",
    "%run ./Lecture/lab-11-3-mnist_cnn_class.py\n",
    "print((int(time.time())-t1)//60,'min',(int(time.time())-t1)%60,'sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 02. TensorFlow.Layers \n",
    "- High Level APIs\n",
    "    1. Kernel, Pooling Stride 값은 4개 이상 List여야만 하지만, 간단한 index 2개 값만 입력\n",
    "    2. Drop Out 옵션도 Training 여부 옵션을 지정가능\n",
    "    3. tf.layers.dense(  unit = 마지막 layer 연결갯수 숫자를 지정)<p></p>\n",
    "<img src = \"./img/Lab11-CNN-layers01.png\" align =\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 03. Ensemble\n",
    "- 각 각의 모듈을 개별적으로 동작시켜 결과를 비교\n",
    "    1. models = []\n",
    "    2. num_models = 7 # 모델의 갯수\n",
    "    3. class Model : 을 지정후 이를 For 문으로 여러번 돌린다<p></p>\n",
    "    <img src = \"./img/Lab11-CNN-ems.png\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src = \"./img/Lab11-CNN-ems2.png\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./img/Lab11-CNN-ems3.png\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# num_models = 7 \n",
    "# 7단계 중첩모델을 활용\n",
    "\n",
    "import time; t1 = int(time.time())\n",
    "%run ./Lecture/lab-11-4-mnist_cnn_ensemble.py\n",
    "print((int(time.time())-t1)//60,'min',(int(time.time())-t1)%60,'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# num_models = 7 \n",
    "# 7단계 중첩모델의 layer 적용\n",
    "\n",
    "import time; t1 = int(time.time())\n",
    "%run ./Lecture/lab-11-5-mnist_cnn_ensemble_layers.py\n",
    "print((int(time.time())-t1)//60,'min',(int(time.time())-t1)%60,'sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04. Low 메모리용 모듈 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Low 메모리용 모듈\n",
    "import time; t1 = int(time.time())\n",
    "%run ./Lecture/lab-11-X-mnist_cnn_low_memory.py\n",
    "print((int(time.time())-t1)//60,'min',(int(time.time())-t1)%60,'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
