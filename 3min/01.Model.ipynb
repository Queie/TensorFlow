{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <strong>Tensor Flow Deep Learning\n",
    "<strong>딥러닝과 텐서플로의 만남</strong>\n",
    "1. <strong>규칙기반 알고리즘</strong> : for/ if/ boolean - 분명한 기준이 존재한 경우 효과적\n",
    "2. <strong>머신러닝 알고리즘</strong> : end-to-end 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "## <strong>1 Jupyter Notebook\n",
    "쥬피터 노트북\n",
    "### <strong> 01 tensor graph 설계\n",
    "Tensor() : graph 구조를 결과로 출력한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markbaum/Python/python36/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# constant : 상수, 문자형태도 입력가능\n",
    "import tensorflow as tf\n",
    "hello = tf.constant(\"Hello, Tensorflow!\")\n",
    "print(hello)\n",
    "\n",
    "# 'rank'  : Tensor 차원 수\n",
    "# 'shape' : Tensor 구조를 설명\n",
    "# [1., 2., 3.]                    : 'rank' 1차원 tensor, 'shape' [3]     (인덱스 3)\n",
    "# [[1., 2., 3.], [4., 5., 6.]]    : 'rank' 2차원 tensor, 'shape' [2,3]   (2차원 인덱스 3)\n",
    "# [[[1., 2., 3.]],[[7., 8., 9.]]] : 'rank' 3차원 tensor, 'shape' [2,1,3] (3차원 2x1x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(10)\n",
    "b = tf.constant(32)\n",
    "c = tf.add(a,b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <strong> 02 지연실행\n",
    "lazy evaluation : graph 구조를 그린 뒤, Tensor 연산을 실행한다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, Tensorflow!'\n",
      "[10, 32, 42]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run(hello))\n",
    "print(sess.run([a,b,c]))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "## <strong>2 PlaceHolder 와 변수\n",
    "parameter 를 설정\n",
    "1. <strong>scalar</strong> : 크기 값  <strong>ex)1</strong>\n",
    "2. <strong>vector</strong> : 화살표 1개 <strong>ex) [1,2,3] list 1개</strong> 열벡터로 행벡터도 존재한다\n",
    "3. <strong>matrix</strong> : 화살표들의 여러 묶음 <strong>ex) [[1,2],[3,4]]</strong>\n",
    "4. <strong>shape</strong> : 다차원 자료를 x 형태로 표시\n",
    "\n",
    "https://tensorflowkorea.gitbooks.io/tensorflow-kr/content/g3doc/resources/dims_types.html\n",
    "\n",
    "https://ghebook.blogspot.kr/2011/06/tensor.html\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*7aXSK5bdSFO9WZMswU5v1w.png\" align=\"left\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(?, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow 의 경직성을 입력 부분에 한해서 \n",
    "X = tf.placeholder(tf.float32, [None, 3]) # [row dim, col dim] 컬럼 3인 데이터를 설정 \n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf.Variable      : 그래프를 계산하면서 자료를 최적화\n",
    "# tf.random_normal : 초기값을 정규분포 랜덤 값으로 초기화\n",
    "W = tf.Variable(tf.random_normal([3, 2])) # [row dim, col dim]\n",
    "b = tf.Variable(tf.random_normal([2, 1]))\n",
    "expr = tf.matmul(X, W) + b # 가설함수 : 1차원 선형모델을 정의한다\n",
    "# ------------ graph 설계 완료 --------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://cfile2.uf.tistory.com/image/226F5B3952B78BC7123696\" align='left'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ------------ lazy evaluation -----------------\n",
    "sess = tf.Session()\n",
    "x_data = [[1, 2, 3], [4, 5, 6]]\n",
    "sess.run(tf.global_variables_initializer()) # Variable 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data : [[1, 2, 3], [4, 5, 6]],\n",
      "\n",
      "W(weight) : [[-0.30860955  0.4240455 ]\n",
      " [-0.26957437  0.26266518]\n",
      " [ 0.96613806 -0.3373982 ]],\n",
      "\n",
      "b(bias) : [[ 0.11888806]\n",
      " [-1.45605338]],\n",
      "\n",
      "expr(예측) : [[ 2.16954398  0.05606929]\n",
      " [ 1.75846469 -0.47093475]]\n"
     ]
    }
   ],
   "source": [
    "# placeholder 에 입력한 값\n",
    "print(\"x_data : {},\\n\\nW(weight) : {},\\n\\nb(bias) : {},\\n\\nexpr(예측) : {}\".format(\n",
    "    x_data, sess.run(W), sess.run(b), \n",
    "    # expr 실행 : feed_dict = 'X'매개변수와 입력값 연결 {dict 을 활용}\n",
    "    sess.run(expr, feed_dict={X: x_data})))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "## <strong>3 선형회귀 모델을 구현\n",
    "선형회귀 : x 와 y 의 관계를 파악한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "x_data = [1, 2, 3]\n",
    "y_data = [1, 2, 3]\n",
    "\n",
    "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "b = tf.Variable(tf.random_uniform([1], -1.0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"X:0\", dtype=float32)\n",
      "Tensor(\"Y:0\", dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# name : 값의 추적을 위해 이름을 설정\n",
    "# 변수, 연산함수에도 이름을 지정할 수 있다.\n",
    "X = tf.placeholder(tf.float32, name=\"X\")\n",
    "Y = tf.placeholder(tf.float32, name=\"Y\")\n",
    "print(X)\n",
    "print(Y)   # tensor 에도 이름이 붙여져서 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# W 와 X 가 Matrix가아니므로, tf.matmul 아닌 기본 곱셈 기호를 사용\n",
    "hypothesis = W * X + b          # 가설 수식: y = W * x + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))  # 예측에서 실제를 뺀, 제곱값들의 평균 (평균제곱오차)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1) # 경사하강법\n",
    "train_op  = optimizer.minimize(cost)                             # 비용 최소화 목표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6.18734 [ 0.65653455] [ 1.06382]\n",
      "20 0.0589633 [ 0.72475517] [ 0.62569624]\n",
      "40 0.0222779 [ 0.83081353] [ 0.38460067]\n",
      "60 0.00841721 [ 0.89600509] [ 0.23640491]\n",
      "80 0.00318025 [ 0.93607676] [ 0.14531253]\n",
      "\n",
      "=== Test ===\n",
      "X: 5, Y:[ 4.89022064] \n",
      "X: 2.5, Y:[ 2.49087048]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:  # sess.run : 1) train_op 와 cost 그래프 계산, \n",
    "                            #            2) 값을 feed_dict 를 통해 전달\n",
    "    sess.run(tf.global_variables_initializer())  # 세션을 생성하고 초기화합니다.\n",
    "    for step in range(100):                      # 최적화를 100번 수행\n",
    "        _, cost_val = sess.run([train_op, cost], feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 20 == 0: \n",
    "            print(step, cost_val, sess.run(W), sess.run(b))\n",
    "\n",
    "    # 모델의 성능평가\n",
    "    print(\"\\n=== Test ===\\nX: 5, Y:{} \\nX: 2.5, Y:{}\".format(\n",
    "        sess.run(hypothesis, feed_dict={X: 5}),     # X 가 5일때 Y를 예측\n",
    "        sess.run(hypothesis, feed_dict={X: 2.5})))  # X 가 2.5일때 Y를 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "## <strong>4 기본 신경망 구현\n",
    "뉴런 신경망을 연결한 딥러닝 알고리즘 \n",
    "1. ex) $ y = Sigmoid(X * W + b) $\n",
    "1. <strong>인공뉴런</strong> : <strong>weight</strong>(가중치) 와 <strong>활성화 함수</strong>의 연결로 구성\n",
    "1. <strong>activation function</strong> (활성화 함수) : Sigmoid, ReLU, tanh\n",
    "\n",
    "<img src=\"https://ujwlkarn.files.wordpress.com/2016/08/screen-shot-2016-08-08-at-11-53-41-am.png?w=748\" align=\"left\" \n",
    "\\width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 역전파 (backpropagation) : 출력층 결과를 입력층까지 역으로 전파하며 계산하여 최적화 과정이 훨씬 유용\n",
    "\n",
    "<img src=\"https://matthewmazur.files.wordpress.com/2018/03/output_1_backprop-4.png?w=525\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <strong>01 간단한 분류모델 만들기 (단일 신경망 모델)\n",
    "1. RBM (Restricted Boltzmann Machine) : 제한된 볼트만 머신\n",
    "\n",
    "<img src=\"https://deeplearning4j.org/img/neural-network-regression.png\" align=\"left\">\n",
    "<img arc=\"http://imonad.com/rbm/restricted-boltzmann-machine/rbm2.png\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 털과 날개 데이터로, 포유류/조류 분류 신경망 모델 생성\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "x_data = np.array([[0, 0], [1, 0], [1, 1], \n",
    "                   [0, 0], [0, 0], [0, 1]])   # 0: 털, 1: 날개 \n",
    "\n",
    "# one-hot-encoding : 기타([1, 0, 0]), 포유류([0, 1, 0]), 조류([0, 0, 1])\n",
    "y_data = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1], \n",
    "                   [1, 0, 0], [1, 0, 0], [0, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. 신경망 모델 구성 graph \n",
    "# X, Y 매개변수에 실측값을 입력하여 학습을 실행 ---------------------------------\n",
    "X = tf.placeholder(tf.float32, [None,2])\n",
    "Y = tf.placeholder(tf.float32, [None,3])\n",
    "\n",
    "# 신경망 (2차원) : [Train 데이터 특성, Target 레이블] -> [2, 3]\n",
    "# 자료 x, y 모두 6차원으로 동일해야 한다\n",
    "W = tf.Variable(tf.random_uniform([2, 3], -1., 1.)) # tf.random_uniform : 균등분포 난수를 대입 (-1 ~ 1)\n",
    "b = tf.Variable(tf.zeros([3]))                      # bias : [열벡터] 각 레이어의 아웃풋 갯수로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L = tf.add(tf.matmul(X, W), b)  # 신경망에 가중치 W과 편향 b을 적용합니다\n",
    "L = tf.nn.relu(L)               # ReLU 함수를 적용\n",
    "model = tf.nn.softmax(L)        # softmax 함수 : 전체 합이 1인 확률로 변환\n",
    "                                # 예) [8.04, 2.76, -6.52] -> [0.53 0.24 0.23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 교차 엔트로피 (Cross-Entropy) : 모델의 손실값 계산\n",
    "# cf) axis 옵션 : 평균 계산하는 방향(row)을 정의 (axis 이 없으면 -1.09 같은 총합 스칼라를 출력)\n",
    "#        Y         model           Y * tf.log(model)    reduce_sum(axis=1)\n",
    "# 예) [[1 0 0]  [[0.1 0.7 0.2]  -> [[-1.0  0    0]   -> [-1.0, -0.09]\n",
    "#     [0 1 0]]  [0.2 0.8 0.0]]     [ 0   -0.09 0]]\n",
    "\n",
    "# reduce_mean : axis = 1 차원의 데이터를 1개로 만들어서 차원을 축소한다\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(model), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train_op = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 0.940567\n",
      "40 0.934864\n",
      "60 0.929366\n",
      "80 0.923982\n",
      "100 0.918751\n"
     ]
    }
   ],
   "source": [
    "# 2. 신경망 모델 Train\n",
    "# 훈련 모델은 'model' 객체에 저장 -------------------------------------------------\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(100):\n",
    "    sess.run(train_op, feed_dict={X: x_data, Y: y_data})\n",
    "    if (step + 1) % 20 == 0:\n",
    "        print(step + 1, sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n",
    "\n",
    "# 결과 확인  0: 기타 1: 포유류, 2: 조류\n",
    "# tf.argmax: 예측값과 실제값의 행렬에서 tf.argmax 를 이용해 가장 큰 값을 가져옵니다.\n",
    "# 예) [[0 1 0] [1 0 0]] -> [1 0]\n",
    "#    [[0.2 0.7 0.1] [0.9 0.1 0.]] -> [1 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측값: [1 2 2 1 1 2]\n",
      "실제값: [0 1 2 0 0 2]\n",
      "Tensor(\"Equal:0\", shape=(?,), dtype=bool)\n",
      "정확도: 33.33\n"
     ]
    }
   ],
   "source": [
    "# 3. 신경망 모델 검증 'model' -----------------------------------------------------\n",
    "# model 의 테스트\n",
    "prediction = tf.argmax(model, 1) # test 결과, 동일한 훈련 데이터 중 '최댓값 컬럼'을 출력\n",
    "target = tf.argmax(Y, 1)         # Y 타겟 데이터중, 동일한 index 중 '최댓값 컬럼'을 출력\n",
    "print('예측값:', sess.run(prediction, feed_dict={X: x_data}))\n",
    "print('실제값:', sess.run(target,     feed_dict={Y: y_data}))\n",
    "\n",
    "# Accuracy 측정 (model 테스트 결과를 활용)\n",
    "is_correct = tf.equal(prediction, target)  # tf.equal(데이터, 대조군) : 일치여부를 확인 (boolean)\n",
    "print(is_correct)                          # 일치 결과를 True/ False 로 출력\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))  # True/ False를 확률로 계산\n",
    "print('정확도: %.2f' % sess.run(accuracy * 100, feed_dict={X: x_data, Y: y_data}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <strong>02 심층 신경망 모델 만들기 (Deep Learning)\n",
    "1. Deep Learning : 위의 신경망에 W(가중치)와 b(편향)값을 추가한다\n",
    "\n",
    "<img src=\"https://www.hindawi.com/journals/aai/2011/686258.fig.001.jpg\" align=\"left\">\n",
    "\n",
    "http://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=8,3&seed=0.18162&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 신경망의 레이어를 여러개로 구성하여 딥러닝 모델을 구현\n",
    "# 1. 입력 텐서를 정의한다\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x_data = np.array([[0, 0], [1, 0], [1, 1], \n",
    "                   [0, 0], [0, 0], [0, 1]])   # 0: 털, 1: 날개  (6x2)\n",
    "\n",
    "# one-hot-encoding : 기타([1, 0, 0]), 포유류([0, 1, 0]), 조류([0, 0, 1])\n",
    "y_data = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1], \n",
    "                   [1, 0, 0], [1, 0, 0], [0, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. 모델의 매개변수 타입과 성격을 정의\n",
    "# 1) 데이터 입력 Tensor 의 shape를 정의 : 그런데 [None, 2] 없이도 잘 실행되더라\n",
    "#  (1) weight : 가중치의 차원 [특성, 히든 레이어의 뉴런갯수]\n",
    "#  (2) bias   : 각 레이어의 아웃풋 갯수로 설정\n",
    "X = tf.placeholder(tf.float32, [None, 2])\n",
    "Y = tf.placeholder(tf.float32, [None, 3])\n",
    "\n",
    "# 2) 학습할 신경망 shape를 정의 : Hidden Layer 에서 10개의 신경망을 사용\n",
    "#  (1) 첫번째 가중치의 차원 : [입력 tensor - 2, 히든 layer 뉴런의 수 - 10]\n",
    "#      b1 은 히든 레이어의 뉴런 갯수 '10'를 설정\n",
    "W1 = tf.Variable(tf.random_uniform([2, 10], -1., 1.))\n",
    "b1 = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "#  (2) 두번째 가중치의 차원 : [히든 layer 신경망의 수 - 10, target tensor - 3]\n",
    "#      b2 는 최종 결과값, 분류 갯수 '3'을 설정\n",
    "W2 = tf.Variable(tf.random_uniform([10, 3], -1., 1.))\n",
    "b2 = tf.Variable(tf.zeros([3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 신경망의 히든 레이어에 가중치 W1과 편향 b1을 적용합니다\n",
    "L1 = tf.add(tf.matmul(X, W1), b1)\n",
    "L1 = tf.nn.relu(L1)\n",
    "\n",
    "# 최종적인 아웃풋을 계산 - 히든레이어에 두번째 신경망의 W2, b2를 적용, 3개의 출력값\n",
    "model = tf.add(tf.matmul(L1, W2), b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3. 손실함수를 정의한다\n",
    "# 텐서플로우의 기본적 '크로스 엔트로피'를 활용\n",
    "cost = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=model))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = 0.01)\n",
    "train_op = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.818313\n",
      "20 0.626637\n",
      "30 0.491294\n",
      "40 0.390916\n",
      "50 0.308921\n",
      "60 0.242926\n",
      "70 0.190848\n",
      "80 0.148578\n",
      "90 0.113751\n",
      "100 0.0867538\n"
     ]
    }
   ],
   "source": [
    "# 4. 모델을 학습한다\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(100):\n",
    "    sess.run(train_op, feed_dict={X: x_data, Y: y_data})\n",
    "    if (step + 1) % 10 == 0:\n",
    "        print(step + 1, sess.run(cost, feed_dict={X: x_data, Y: y_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측값: [0 1 2 0 0 2]\n",
      "실제값: [0 1 2 0 0 2]\n",
      "정확도: 100.00\n"
     ]
    }
   ],
   "source": [
    "# 5. 모델의 평가 : { 0: 기타 1: 포유류, 2: 조류 }\n",
    "prediction = tf.argmax(model, 1)\n",
    "target = tf.argmax(Y, 1)\n",
    "print('예측값:', sess.run(prediction, feed_dict={X: x_data}))\n",
    "print('실제값:', sess.run(target, feed_dict={Y: y_data}))\n",
    "\n",
    "is_correct = tf.equal(prediction, target)\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('정확도: %.2f' % sess.run(accuracy * 100, feed_dict={X: x_data, Y: y_data}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <strong>03 Word to Vector\n",
    "워드 to Vector\n",
    "\n",
    "https://www.tensorflow.org/tutorials/word2vec\n",
    "\n",
    "<img src=\"https://www.tensorflow.org/images/linear-relationships.png\" align=\"left\" width='600'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Word2Vec 모델을 간단하게 구현해봅니다.\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# matplot 한글 설정\n",
    "matplotlib.rc('font', family='D2Coding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 단어 벡터를 분석해볼 임의의 문장들\n",
    "sentences = [\"나 고양이 좋다\",\"나 강아지 좋다\",\"나 동물 좋다\",\"강아지 고양이 동물\",\"강아지 고양이 좋다\",\n",
    "             \"여자친구 고양이 강아지 좋다\",\"고양이 생선 우유 좋다\",\"강아지 생선 싫다 우유 좋다\",\n",
    "             \"강아지 고양이 눈 좋다\",\"나 여자친구 좋다\",\"여자친구 나 싫다\",\"여자친구 나 영화 책 음악 좋다\",\n",
    "             \"나 게임 만화 애니 좋다\",\"고양이 강아지 싫다\",]\n",
    "\n",
    "word_list = \" \".join(sentences).split() # 문장을 전부 합친다\n",
    "word_list = list(set(word_list))        # set() : 고유 단어 리스트를 생성\n",
    "word_dict = {w: i for i, w in enumerate(word_list)}  # 문자들의 인덱스 '연관배열'\n",
    "word_index = [word_dict[word] for word in word_list] # 단어를 참조 할 '인덱스 배열'생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 윈도우 사이즈를 1 로 하는 skip-gram 모델을 만듭니다.\n",
    "# 예) 나 게임 만화 애니 좋다\n",
    "#   -> ([나, 만화], 게임), ([게임, 애니], 만화), ([만화, 좋다], 애니)\n",
    "#   -> (게임, 나), (게임, 만화), (만화, 게임), (만화, 애니), (애니, 만화), (애니, 좋다)\n",
    "skip_grams = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1, len(word_index) - 1):\n",
    "    \n",
    "    target = word_index[i]                            # 중심단어 추출\n",
    "    context = [word_index[i - 1], word_index[i + 1]]  # 중심단어 앞, 뒤 단어를 list로 추출\n",
    "    # (target, context[0]), (target, context[1])..\n",
    "    for w in context:\n",
    "        skip_grams.append([target, w])   # [[target index-1, target index+1], target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(skip_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# skip-gram 데이터에서 무작위로 데이터를 뽑아 \n",
    "# 입력값과 출력값의 배치 데이터를 생성하는 함수\n",
    "def random_batch(data, size):\n",
    "    random_inputs, random_labels = [], []\n",
    "    random_index = np.random.choice(range(len(data)), size, replace=False)\n",
    "    for i in random_index:\n",
    "        random_inputs.append(data[i][0])     # target\n",
    "        random_labels.append([data[i][1]])   # context word\n",
    "    return random_inputs, random_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 옵션 설정\n",
    "training_epoch = 300  # 학습을 반복할 횟수\n",
    "learning_rate = 0.1   # 학습률\n",
    "batch_size = 20       # 한 번에 학습할 데이터의 크기\n",
    "\n",
    "# 단어 벡터를 구성할 임베딩 차원의 크기 : x, y 그래프 2 개의 값만 출력\n",
    "embedding_size = 2\n",
    "# word2vec 학습을 위한 nce_loss 함수의 샘플링 크기를 정의 (단) batch_size 보다 작아야 한다)\n",
    "num_sampled = 15\n",
    "voc_size = len(word_list) # 총 단어 갯수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 신경망 모델 구성\n",
    "inputs = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "# tf.nn.nce_loss : 출력값을 [batch_size, 1]로 구성해야 한다\n",
    "labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "# word2vec 모델의 결과 값인 임베딩 벡터를 저장\n",
    "# 1)총 단어 갯수, 2) 임베딩 갯수의 크기  두 개의 차원을 갖는다\n",
    "embeddings = tf.Variable(tf.random_uniform([voc_size, embedding_size], -1.0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 임베딩 벡터의 차원에서 학습할 입력값에 대한 행들을 뽑아옵니다.\n",
    "# 예) embeddings     inputs    selected\n",
    "#    [[1, 2, 3]  -> [2, 3] -> [[2, 3, 4]\n",
    "#     [2, 3, 4]                [3, 4, 5]]\n",
    "#     [3, 4, 5]\n",
    "#     [4, 5, 6]]\n",
    "selected_embed = tf.nn.embedding_lookup(embeddings, inputs)\n",
    "# nce_loss 함수에서 사용할 변수들을 정의\n",
    "nce_weights = tf.Variable(tf.random_uniform([voc_size, embedding_size], -1.0, 1.0))\n",
    "nce_biases = tf.Variable(tf.zeros([voc_size]))\n",
    "\n",
    "# nce_loss 함수를 직접 구현하려면 매우 복잡하지만,\n",
    "# 함수를 텐서플로우가 제공하므로 그냥 tf.nn.nce_loss 함수를 사용하기만 하면 됩니다.\n",
    "loss = tf.reduce_mean(\n",
    "            tf.nn.nce_loss(nce_weights, nce_biases, labels, selected_embed, num_sampled, voc_size))\n",
    "train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at step  50 :  3.2309\n",
      "loss at step  100 :  3.0807\n",
      "loss at step  150 :  2.98974\n",
      "loss at step  200 :  2.73107\n",
      "loss at step  250 :  2.89572\n",
      "loss at step  300 :  2.65647\n"
     ]
    }
   ],
   "source": [
    "# 신경망 모델 학습\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, training_epoch + 1):\n",
    "        batch_inputs, batch_labels = random_batch(skip_grams, batch_size)\n",
    "        _, loss_val = sess.run([train_op, loss],\n",
    "                               feed_dict={inputs: batch_inputs,\n",
    "                                          labels: batch_labels})\n",
    "        if step % 50 == 0:\n",
    "            print(\"loss at step \", step, \": \", loss_val)\n",
    "\n",
    "    # matplot 으로 출력하여 시각적으로 확인해보기 위해\n",
    "    # 시각화를 위해 임베딩 벡터의 결과 값을 계산하여 저장\n",
    "    # with 구문 안에서는 sess.run 대신 .eval() 를 사용 가능하다\n",
    "    trained_embeddings = embeddings.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAD8CAYAAACB3pQWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feb5b456240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 임베딩된 Word2Vec 결과 확인 : 단어간의 인접관계를 나타낸다\n",
    "for i, label in enumerate(word_list):\n",
    "    x, y = trained_embeddings[i]\n",
    "    plt.scatter(x, y)\n",
    "    plt.annotate(label, xy=(x, y), xytext=(5, 2),\n",
    "                 textcoords='offset points', ha='right', va='bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
