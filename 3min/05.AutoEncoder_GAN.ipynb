{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "# <strong>Tensor Flow Deep Learning\n",
    "<strong>Unsupervised Learning\n",
    "\n",
    "<strong>Chapter 7 : 합성곱 신경망 (Convolution Neural Network)</strong>\n",
    "\n",
    "<strong>RBM(Restricted Boltzmann Machine)<strong>\n",
    "\n",
    "http://scikit-learn.org/stable/auto_examples/neural_networks/plot_rbm_logistic_classification.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "## <strong>1 AutoEncoder 개념\n",
    "<strong>입력값과 출력값이 동일한 신경망</strong>으로, 가운데 Node의 갯수가 입력보다 적게 설계되어\n",
    "\n",
    "입력데이터를 압축 후 복원함으로써 <strong>노이즈를 제거하는데 효과적</strong>으로 알려져 있다\n",
    "1. 변이형 오토인코더 (Variational AutoEncoder)\n",
    "1. 잡음제거 오토인코더 (Denoising AutoEncoder) \n",
    "1. 기타 다양한 오토인코더로 구성\n",
    "1. 실무에선 <strong>RBM(Restricted Boltzmann Machine)</strong>을 대신 활용하기도 한다\n",
    "1. <strong>오토인코더</strong>는 피처를 축소, <strong>RBM은 확률분포</strong>에 기반하여 visible 변수, hidden 변수간 상호작용을 파악\n",
    "1. http://khanrc.tistory.com/entry/Autoencoder-vs-RBM-vs-CNN\n",
    "\n",
    "<img src=\"http://fastforwardlabs.github.io/blog-images/miriam/imgs_code/vae.4.png\" align=\"left\" width='400'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "## <strong>2 AutoEncoder 구현\n",
    "<strong>MNIST 데이터를 활용\n",
    "\n",
    "(참고) Optimizers 최적화 알고리즘\n",
    "1. SGD with Momentum\n",
    "1. RMS propagation   &nbsp;&nbsp;&nbsp;<--  using in codes\n",
    "1. Adagrad\n",
    "1. Adadelta\n",
    "1. Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markbaum/Python/python36/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# 대표적인 비지도(Unsupervised) 학습 방법인 Autoencoder 를 구현해봅니다.\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./data/mnist/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. 파라미터의 설정\n",
    "learning_rate = 0.01  # Activation Function의 파라미터\n",
    "training_epoch = 20   # 전체 데이터를 학습하는 총 횟수\n",
    "batch_size = 100      # 1번 학습시 호출할 이미지 데이터 숫자 (100개씩 랜덤추출)\n",
    "\n",
    "# 1) 신경망 레이어 구성 옵션\n",
    "n_hidden = 256        # 히든 레이어의 뉴런 갯수\n",
    "n_input  = 28*28      # 입력값 크기 - 이미지 픽셀수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. 신경망 모델 구성\n",
    "# 1) 입력값을 Y로 사용하므로, 별도 Y를 설정하지 않는다\n",
    "X = tf.placeholder(tf.float32, [None, n_input])\n",
    "\n",
    "# 2) 인코더 레이어와 디코더 레이어의 가중치와 편향 변수를 설정 \n",
    "# input -> encode -> decode -> output\n",
    "W_encode = tf.Variable(tf.random_normal([n_input, n_hidden]))\n",
    "b_encode = tf.Variable(tf.random_normal([n_hidden]))\n",
    "# cf) sigmoid 함수를 이용해 신경망 레이어를 구성시 : sigmoid(X * W + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3. 모델을 정의한다\n",
    "# 1) 인코더 레이어 구성\n",
    "# encode는 입력값보다 작은값으로 정보를 압축, decode 출력풋은 입력과 동일한 크기로 설정\n",
    "encoder = tf.nn.sigmoid(tf.add(tf.matmul(X, W_encode), b_encode))\n",
    "W_decode = tf.Variable(tf.random_normal([n_hidden, n_input]))\n",
    "b_decode = tf.Variable(tf.random_normal([n_input]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2) 디코더 레이어 구성 : 디코더가 최종 모델이 된다\n",
    "decoder = tf.nn.sigmoid(\n",
    "                tf.add(tf.matmul(encoder, W_decode), b_decode))\n",
    "\n",
    "# 3) 손실함수 정의\n",
    "# 디코더는 인풋과 최대한 같은 결과를 내야 하므로, 디코딩한 결과를 평가하기 위해\n",
    "# 입력 값인 X 를 실측 결과 값으로하여 decoder 와의 차이를 손실함수를 정의한다\n",
    "cost = tf.reduce_mean(tf.pow(X - decoder, 2))\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 Avg.cost = 0.1951\n",
      "Epoch: 0005 Avg.cost = 0.0385\n",
      "Epoch: 0009 Avg.cost = 0.0297\n",
      "Epoch: 0013 Avg.cost = 0.0256\n",
      "Epoch: 0017 Avg.cost = 0.0246\n",
      "최적화 완료!\n"
     ]
    }
   ],
   "source": [
    "# 4. 신경망 모델 학습\n",
    "# 1) 모델학습 초기화\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "# 2) 모델의 훈련\n",
    "for epoch in range(training_epoch):\n",
    "    total_cost = 0\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        _, cost_val = sess.run([optimizer, cost], feed_dict={X: batch_xs})\n",
    "        total_cost += cost_val\n",
    "    if epoch % 4 == 0:\n",
    "        print('Epoch:', '%04d'%(epoch+1),\n",
    "              'Avg.cost =', '{:.4f}'.format(total_cost / total_batch))\n",
    "print('최적화 완료!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAACNCAYAAACT6v+eAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nphRFURRFUYLg/wGJ51Iim3OK5AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f854cbe5828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5. 모델의 성능평가\n",
    "sample_size = 10\n",
    "samples = sess.run(decoder,\n",
    "                   feed_dict = {X: mnist.test.images[ :sample_size]})\n",
    "fig, ax = plt.subplots(2, sample_size, figsize=(sample_size, 2))\n",
    "for i in range(sample_size):\n",
    "    # 원본 이미지를 출력\n",
    "    ax[0][i].set_axis_off()\n",
    "    ax[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))\n",
    "    # AutoEncoder로 생성한 이미지를 출력\n",
    "    ax[1][i].set_axis_off()\n",
    "    ax[1][i].imshow(np.reshape(samples[i], (28, 28)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "# <strong>Tensor Flow Deep Learning\n",
    "<strong>Unsupervised Learning\n",
    "\n",
    "<strong>Chapter 8 : GAN (Generative Adversarial Network)</strong>\n",
    "\n",
    "대립하는 두 신경망을 경쟁시킴으로써 결과물 생성하는 학습모듈\n",
    "1. Discriminator(구분자)에게 이미지가 진짜임을 판단하게 한다\n",
    "1. Generator(생성자)를 통해 노이즈로 부터 임의 이미지를 만들고, 이를 진짜 이미지여부를 판단한다\n",
    "1. <strong>생성자가 가짜 이미지</strong>를 만들고, <strong>구분자가 이를 구분하는 훈련</strong>을 통해서 진짜 이미지 구별능력을 향상시킨다\n",
    "\n",
    "<strong>ex) 위조지폐 범죄자와, 경찰을 경쟁시켜 완벽한 위조지폐/ 원본화폐를 찾는 학습모듈을 생성\n",
    "\n",
    "<img src=\"https://oshearesearch.com/wp-content/uploads/2016/07/mnist_gan.png\" align='left' width='600'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "## <strong>1 GNA Deep Learning\n",
    "https://arxiv.org/abs/1406.2661\n",
    "\n",
    "Generator(생성자)가 실제와 상당히 비슷한 이미지를 생성하는 능력을 키운다\n",
    "1. 이미지에서 고흐풍의 <strong>이미지를 재현</strong>\n",
    "1. 테두리만 있는 <strong>이미지를 자동채색</strong>\n",
    "1. <strong>모자이크 이미지를 복원</strong> 등에서 탁월한 성능을 나타낸다\n",
    "1. 기타 <strong>자연어 문장 생성</strong>의 연구에서도 활발한 성능을 나타낸다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "## <strong>2 GNA 기본 모델의 구현\n",
    "<strong>Unsupervised 학습인 Generative Adversarial Network (GAN) 2016 을 구현한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./data/mnist/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. 파라미터 설정\n",
    "# 1) 옵션 설정\n",
    "total_epoch = 100\n",
    "batch_size = 100\n",
    "learning_rate = 0.0002\n",
    "\n",
    "# 2) 신경망 레이어 구성 옵션\n",
    "n_hidden = 256\n",
    "n_input = 28 * 28\n",
    "n_noise = 128  # 생성기의 입력값으로 사용할 노이즈의 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. 신경망의 파라미터를 설정\n",
    "# 1) 입력/ 출력부분 설정\n",
    "# GAN 도 Unsupervised 학습이므로 Y 를 사용하지 않는다\n",
    "X = tf.placeholder(tf.float32, [None, n_input])\n",
    "# 대신 노이즈 Z를 추가 입력값으로 사용\n",
    "Z = tf.placeholder(tf.float32, [None, n_noise])\n",
    "\n",
    "# 2) Generator : 생성기 신경망의 변수를 설정\n",
    "G_W1 = tf.Variable(tf.random_normal([n_noise, n_hidden], stddev=0.01)) # 입력부분\n",
    "G_b1 = tf.Variable(tf.zeros([n_hidden]))\n",
    "G_W2 = tf.Variable(tf.random_normal([n_hidden, n_input], stddev=0.01))\n",
    "G_b2 = tf.Variable(tf.zeros([n_input]))\n",
    "\n",
    "# 3) Discriminator : 판별기 신경망에 사용하는 변수를 설정\n",
    "D_W1 = tf.Variable(tf.random_normal([n_input, n_hidden], stddev=0.01))\n",
    "D_b1 = tf.Variable(tf.zeros([n_hidden]))\n",
    "# 판별기의 최종 결과값이 진짜와 얼마나 가까운지를 판단 : Scalar\n",
    "D_W2 = tf.Variable(tf.random_normal([n_hidden, 1], stddev=0.01)) # 출력부분\n",
    "D_b2 = tf.Variable(tf.zeros([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3. 신경망의 모델을 정의한다\n",
    "# 생성기(G) 신경망 정의\n",
    "def generator(noise_z):\n",
    "    hidden = tf.nn.relu(tf.matmul(noise_z, G_W1) + G_b1)\n",
    "    output = tf.nn.sigmoid(tf.matmul(hidden, G_W2) + G_b2)\n",
    "    return output\n",
    "\n",
    "# 판별기(D) 신경망 정의\n",
    "def discriminator(inputs):\n",
    "    hidden = tf.nn.relu(tf.matmul(inputs, D_W1) + D_b1)\n",
    "    output = tf.nn.sigmoid(tf.matmul(hidden, D_W2) + D_b2)\n",
    "    return output\n",
    "\n",
    "# 랜덤한 노이즈(Z)를 생성\n",
    "def get_noise(batch_size, n_noise):\n",
    "    return np.random.normal(size=(batch_size, n_noise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4. 노이즈를 이용해 랜덤한 이미지를 생성\n",
    "G = generator(Z)\n",
    "# 노이즈를 이용해 생성한 이미지가 진짜 이미지인지 판별\n",
    "D_gene = discriminator(G)\n",
    "# 진짜 이미지를 이용해 판별한 결과를 출력\n",
    "D_real = discriminator(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5. 이미지 판별기/ 생성기의 코스트 함수\n",
    "# GAN 모델의 최적화는 loss_G, loss_D 를 최대로 갖는 모델을 설계한다\n",
    "# 하지만 loss_D와 loss_G는 경쟁관계로 서로 반대로 움직인다\n",
    "# 논문의 수식에서는 loss_D 를 최대화하기 위해, D_gene 를 최소화 한다\n",
    "# tf.log(D_real) : 판별기에 진짜 이미지를 넣었을 때 최대값을 출력한다\n",
    "# tf.log(1 - D_gene) : 가짜 이미지를 넣었을 때에도 최대값을 출력한다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 이것은 판별기는 생성기가 만들어낸 이미지가 가짜라고 판단하도록 판별기 신경망을 학습시킵니다.\n",
    "loss_D = tf.reduce_mean(tf.log(D_real) + tf.log(1 - D_gene))\n",
    "# loss_G 를 최대로 하기 위해서는, D_gene 도 같이 최대가 되어야 한다\n",
    "# cf) 논문에서는 loss_D 와 같은 수식으로 최소화 하는 생성기를 찾는다\n",
    "loss_G = tf.reduce_mean(tf.log(D_gene))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loss_D 는 판별기 신경망에 사용되는 변수를 사용하고,\n",
    "# loss_G 는 생성기 신경망에 사용되는 변수만 사용하여 최적화를 합니다.\n",
    "D_var_list = [D_W1, D_b1, D_W2, D_b2]\n",
    "G_var_list = [G_W1, G_b1, G_W2, G_b2]\n",
    "\n",
    "# GAN 논문의 수식에 따르면 loss 를 극대화 해야하지만, minimize 하는 최적화 함수를 사용하기 때문에\n",
    "# 최적화 하려는 loss_D 와 loss_G 에 음수 부호를 붙여줍니다.\n",
    "train_D = tf.train.AdamOptimizer(learning_rate).minimize(-loss_D,\n",
    "                                                         var_list=D_var_list)\n",
    "train_G = tf.train.AdamOptimizer(learning_rate).minimize(-loss_G,\n",
    "                                                         var_list=G_var_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 6. 신경망 모델의 학습\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "loss_val_D, loss_val_G = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0000 D loss: -0.5188 G loss: -2.18\n",
      "Epoch: 0001 D loss: -0.113 G loss: -3.31\n",
      "Epoch: 0002 D loss: -0.5994 G loss: -1.543\n",
      "Epoch: 0003 D loss: -0.3491 G loss: -2.151\n",
      "Epoch: 0004 D loss: -0.2998 G loss: -2.416\n",
      "Epoch: 0005 D loss: -0.2007 G loss: -2.722\n",
      "Epoch: 0006 D loss: -0.2776 G loss: -2.632\n",
      "Epoch: 0007 D loss: -0.3037 G loss: -2.38\n",
      "Epoch: 0008 D loss: -0.3299 G loss: -2.453\n",
      "Epoch: 0009 D loss: -0.3954 G loss: -2.461\n",
      "Epoch: 0010 D loss: -0.3446 G loss: -2.272\n",
      "Epoch: 0011 D loss: -0.4267 G loss: -2.403\n",
      "Epoch: 0012 D loss: -0.4867 G loss: -2.182\n",
      "Epoch: 0013 D loss: -0.3464 G loss: -2.831\n",
      "Epoch: 0014 D loss: -0.3517 G loss: -2.429\n",
      "Epoch: 0015 D loss: -0.4713 G loss: -2.264\n",
      "Epoch: 0016 D loss: -0.5212 G loss: -2.445\n",
      "Epoch: 0017 D loss: -0.4488 G loss: -2.447\n",
      "Epoch: 0018 D loss: -0.5065 G loss: -2.391\n",
      "Epoch: 0019 D loss: -0.4624 G loss: -2.243\n",
      "Epoch: 0020 D loss: -0.5645 G loss: -2.121\n",
      "Epoch: 0021 D loss: -0.4033 G loss: -2.503\n",
      "Epoch: 0022 D loss: -0.5633 G loss: -2.863\n",
      "Epoch: 0023 D loss: -0.4842 G loss: -2.226\n",
      "Epoch: 0024 D loss: -0.5859 G loss: -2.043\n",
      "Epoch: 0025 D loss: -0.5121 G loss: -2.215\n",
      "Epoch: 0026 D loss: -0.5874 G loss: -2.365\n",
      "Epoch: 0027 D loss: -0.6512 G loss: -2.359\n",
      "Epoch: 0028 D loss: -0.4346 G loss: -2.81\n",
      "Epoch: 0029 D loss: -0.6089 G loss: -2.385\n",
      "Epoch: 0030 D loss: -0.568 G loss: -2.409\n",
      "Epoch: 0031 D loss: -0.4352 G loss: -2.435\n",
      "Epoch: 0032 D loss: -0.4679 G loss: -2.478\n",
      "Epoch: 0033 D loss: -0.5016 G loss: -2.553\n",
      "Epoch: 0034 D loss: -0.4325 G loss: -2.451\n",
      "Epoch: 0035 D loss: -0.5907 G loss: -2.645\n",
      "Epoch: 0036 D loss: -0.5383 G loss: -2.271\n",
      "Epoch: 0037 D loss: -0.5434 G loss: -2.009\n",
      "Epoch: 0038 D loss: -0.7128 G loss: -2.088\n",
      "Epoch: 0039 D loss: -0.584 G loss: -2.242\n",
      "Epoch: 0040 D loss: -0.6497 G loss: -2.211\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(total_epoch):\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        noise = get_noise(batch_size, n_noise)\n",
    "        # 판별기와 생성기 신경망을 각각 학습시킵니다.\n",
    "        _, loss_val_D = sess.run([train_D, loss_D], feed_dict={X: batch_xs, Z: noise})\n",
    "        _, loss_val_G = sess.run([train_G, loss_G], feed_dict={Z: noise})\n",
    "    print('Epoch:', '%04d' % epoch,\n",
    "          'D loss: {:.4}'.format(loss_val_D),\n",
    "          'G loss: {:.4}'.format(loss_val_G))\n",
    "\n",
    "    # 7. 학습이 되어가는 모습을 보기 위해 주기적으로 이미지를 생성하여 저장\n",
    "    if epoch == 0 or (epoch + 1) % 10 == 0:\n",
    "        sample_size = 10\n",
    "        noise = get_noise(sample_size, n_noise)\n",
    "        samples = sess.run(G, feed_dict={Z: noise})\n",
    "        fig, ax = plt.subplots(1, sample_size, figsize=(sample_size, 1))\n",
    "        for i in range(sample_size):\n",
    "            ax[i].set_axis_off()\n",
    "            ax[i].imshow(np.reshape(samples[i], (28, 28)))\n",
    "        # samples 폴더에, 이미지 생성결과를 저장한다\n",
    "        plt.savefig('.data/gan_sample/{}.png'.format(str(epoch).zfill(3)), bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "print('최적화 완료!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "## <strong>3 원하는 숫자의 이미지 생성모델 구현\n",
    "<strong>특정한 숫자 이미지를 생성하는 모델을 설계한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GAN 모델을 이용해 단순히 랜덤한 숫자를 생성하는 아닌,\n",
    "# 원하는 손글씨 숫자를 생성하는 모델을 만들어봅니다.\n",
    "# 이런 방식으로 흑백 사진을 컬러로 만든다든가, 또는 선화를 채색한다든가 하는 응용이 가능합니다.\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./data/mnist/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. 파라미터 설정\n",
    "total_epoch = 100\n",
    "batch_size = 100\n",
    "n_hidden = 256\n",
    "n_input = 28 * 28\n",
    "n_noise = 128\n",
    "n_class = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. 신경망 모델 구성\n",
    "X = tf.placeholder(tf.float32, [None, n_input])\n",
    "# 노이즈와 실제 이미지에, 그에 해당하는 숫자에 대한 정보를 넣어주기 위해 사용합니다.\n",
    "Y = tf.placeholder(tf.float32, [None, n_class])\n",
    "Z = tf.placeholder(tf.float32, [None, n_noise])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(noise, labels):\n",
    "    with tf.variable_scope('generator'):\n",
    "        # noise 값에 labels 정보를 추가합니다.\n",
    "        inputs = tf.concat([noise, labels], 1)\n",
    "        # TensorFlow 에서 제공하는 유틸리티 함수를 이용해 신경망을 매우 간단하게 구성할 수 있습니다.\n",
    "        hidden = tf.layers.dense(inputs, n_hidden, activation = tf.nn.relu)\n",
    "        output = tf.layers.dense(hidden, n_input, activation = tf.nn.sigmoid)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(inputs, labels, reuse = None):\n",
    "    with tf.variable_scope('discriminator') as scope:\n",
    "        # 노이즈에서 생성한 이미지와 실제 이미지를 판별하는 모델의 변수를 동일하게 하기 위해,\n",
    "        # 이전에 사용되었던 변수를 재사용하도록 합니다.\n",
    "        if reuse:\n",
    "            scope.reuse_variables()\n",
    "        inputs = tf.concat([inputs, labels], 1)\n",
    "        hidden = tf.layers.dense(inputs, n_hidden, activation = tf.nn.relu)\n",
    "        output = tf.layers.dense(hidden, 1, activation = None)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_noise(batch_size, n_noise):\n",
    "    return np.random.uniform(-1., 1., size=[batch_size, n_noise])\n",
    "\n",
    "# 생성 모델과 판별 모델에 Y 즉, labels 정보를 추가하여\n",
    "# labels 정보에 해당하는 이미지를 생성할 수 있도록 유도합니다.\n",
    "G = generator(Z, Y)\n",
    "D_real = discriminator(X, Y)\n",
    "D_gene = discriminator(G, Y, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 손실함수는 다음을 참고하여 GAN 논문에 나온 방식과는 약간 다르게 작성하였습니다.\n",
    "# http://bamos.github.io/2016/08/09/deep-completion/\n",
    "# 진짜 이미지를 판별하는 D_real 값은 1에 가깝도록,\n",
    "# 가짜 이미지를 판별하는 D_gene 값은 0에 가깝도록 하는 손실 함수입니다.\n",
    "loss_D_real = tf.reduce_mean(\n",
    "                    tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                        logits=D_real, labels=tf.ones_like(D_real)))\n",
    "loss_D_gene = tf.reduce_mean(\n",
    "                    tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                        logits=D_gene, labels=tf.zeros_like(D_gene)))\n",
    "# loss_D_real 과 loss_D_gene 을 더한 뒤 이 값을 최소화 하도록 최적화합니다.\n",
    "loss_D = loss_D_real + loss_D_gene\n",
    "# 가짜 이미지를 진짜에 가깝게 만들도록 생성망을 학습시키기 위해, D_gene 을 최대한 1에 가깝도록 만드는 손실함수입니다.\n",
    "loss_G = tf.reduce_mean(\n",
    "                    tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                        logits=D_gene, labels=tf.ones_like(D_gene)))\n",
    "\n",
    "# TensorFlow 에서 제공하는 유틸리티 함수를 이용해\n",
    "# discriminator 와 generator scope 에서 사용된 변수들을 쉽게 가져올 수 있습니다.\n",
    "vars_D = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                           scope='discriminator')\n",
    "vars_G = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                           scope='generator')\n",
    "\n",
    "train_D = tf.train.AdamOptimizer().minimize(loss_D,\n",
    "                                            var_list=vars_D)\n",
    "train_G = tf.train.AdamOptimizer().minimize(loss_G,\n",
    "                                            var_list=vars_G)\n",
    "\n",
    "#########\n",
    "# 신경망 모델 학습\n",
    "######\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "loss_val_D, loss_val_G = 0, 0\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        noise = get_noise(batch_size, n_noise)\n",
    "\n",
    "        _, loss_val_D = sess.run([train_D, loss_D],\n",
    "                                 feed_dict={X: batch_xs, Y: batch_ys, Z: noise})\n",
    "        _, loss_val_G = sess.run([train_G, loss_G],\n",
    "                                 feed_dict={Y: batch_ys, Z: noise})\n",
    "\n",
    "    print('Epoch:', '%04d' % epoch,\n",
    "          'D loss: {:.4}'.format(loss_val_D),\n",
    "          'G loss: {:.4}'.format(loss_val_G))\n",
    "\n",
    "    #########\n",
    "    # 학습이 되어가는 모습을 보기 위해 주기적으로 레이블에 따른 이미지를 생성하여 저장\n",
    "    ######\n",
    "    if epoch == 0 or (epoch + 1) % 10 == 0:\n",
    "        sample_size = 10\n",
    "        noise = get_noise(sample_size, n_noise)\n",
    "        samples = sess.run(G,\n",
    "                           feed_dict={Y: mnist.test.labels[:sample_size],\n",
    "                                      Z: noise})\n",
    "\n",
    "        fig, ax = plt.subplots(2, sample_size, figsize=(sample_size, 2))\n",
    "\n",
    "        for i in range(sample_size):\n",
    "            ax[0][i].set_axis_off()\n",
    "            ax[1][i].set_axis_off()\n",
    "\n",
    "            ax[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))\n",
    "            ax[1][i].imshow(np.reshape(samples[i], (28, 28)))\n",
    "\n",
    "        plt.savefig('samples2/{}.png'.format(str(epoch).zfill(3)), bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "print('최적화 완료!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
