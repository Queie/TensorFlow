{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "# <strong>Tensor Flow Deep Learning\n",
    "<strong>Unsupervised Learning\n",
    "\n",
    "<strong>Chapter 7 : 합성곱 신경망 (Convolution Neural Network)</strong>\n",
    "\n",
    "<strong>RBM(Restricted Boltzmann Machine)<strong>\n",
    "\n",
    "http://scikit-learn.org/stable/auto_examples/neural_networks/plot_rbm_logistic_classification.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "## <strong>1 AutoEncoder 개념\n",
    "<strong>입력값과 출력값이 동일한 신경망</strong>으로, 가운데 Node의 갯수가 입력보다 적게 설계되어\n",
    "\n",
    "입력데이터를 압축 후 복원함으로써 <strong>노이즈를 제거하는데 효과적</strong>으로 알려져 있다\n",
    "1. 변이형 오토인코더 (Variational AutoEncoder)\n",
    "1. 잡음제거 오토인코더 (Denoising AutoEncoder) \n",
    "1. 기타 다양한 오토인코더로 구성\n",
    "1. 실무에선 <strong>RBM(Restricted Boltzmann Machine)</strong>을 대신 활용하기도 한다\n",
    "1. <strong>오토인코더</strong>는 피처를 축소, <strong>RBM은 확률분포</strong>에 기반하여 visible 변수, hidden 변수간 상호작용을 파악\n",
    "1. http://khanrc.tistory.com/entry/Autoencoder-vs-RBM-vs-CNN\n",
    "\n",
    "<img src=\"http://fastforwardlabs.github.io/blog-images/miriam/imgs_code/vae.4.png\" align=\"left\" width='400'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "## <strong>2 AutoEncoder 구현\n",
    "<strong>MNIST 데이터를 활용\n",
    "\n",
    "(참고) Optimizers 최적화 알고리즘\n",
    "1. SGD with Momentum\n",
    "1. RMS propagation   &nbsp;&nbsp;&nbsp;<--  using in codes\n",
    "1. Adagrad\n",
    "1. Adadelta\n",
    "1. Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markbaum/Python/python36/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# 대표적인 비지도(Unsupervised) 학습 방법인 Autoencoder 를 구현해봅니다.\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./data/mnist/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. 파라미터의 설정\n",
    "learning_rate = 0.01  # Activation Function의 파라미터\n",
    "training_epoch = 20   # 전체 데이터를 학습하는 총 횟수\n",
    "batch_size = 100      # 1번 학습시 호출할 이미지 데이터 숫자 (100개씩 랜덤추출)\n",
    "\n",
    "# 1) 신경망 레이어 구성 옵션\n",
    "n_hidden = 256        # 히든 레이어의 뉴런 갯수\n",
    "n_input  = 28*28      # 입력값 크기 - 이미지 픽셀수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. 신경망 모델 구성\n",
    "# 1) 입력값을 Y로 사용하므로, 별도 Y를 설정하지 않는다\n",
    "X = tf.placeholder(tf.float32, [None, n_input])\n",
    "\n",
    "# 2) 인코더 레이어와 디코더 레이어의 가중치와 편향 변수를 설정 \n",
    "# input -> encode -> decode -> output\n",
    "W_encode = tf.Variable(tf.random_normal([n_input, n_hidden]))\n",
    "b_encode = tf.Variable(tf.random_normal([n_hidden]))\n",
    "# cf) sigmoid 함수를 이용해 신경망 레이어를 구성시 : sigmoid(X * W + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3. 모델을 정의한다\n",
    "# 1) 인코더 레이어 구성\n",
    "# encode는 입력값보다 작은값으로 정보를 압축, decode 출력풋은 입력과 동일한 크기로 설정\n",
    "encoder = tf.nn.sigmoid(tf.add(tf.matmul(X, W_encode), b_encode))\n",
    "W_decode = tf.Variable(tf.random_normal([n_hidden, n_input]))\n",
    "b_decode = tf.Variable(tf.random_normal([n_input]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2) 디코더 레이어 구성 : 디코더가 최종 모델이 된다\n",
    "decoder = tf.nn.sigmoid(\n",
    "                tf.add(tf.matmul(encoder, W_decode), b_decode))\n",
    "\n",
    "# 3) 손실함수 정의\n",
    "# 디코더는 인풋과 최대한 같은 결과를 내야 하므로, 디코딩한 결과를 평가하기 위해\n",
    "# 입력 값인 X 를 실측 결과 값으로하여 decoder 와의 차이를 손실함수를 정의한다\n",
    "cost = tf.reduce_mean(tf.pow(X - decoder, 2))\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 Avg.cost = 0.1931\n",
      "Epoch: 0005 Avg.cost = 0.0374\n",
      "Epoch: 0009 Avg.cost = 0.0297\n",
      "Epoch: 0013 Avg.cost = 0.0275\n",
      "Epoch: 0017 Avg.cost = 0.0264\n",
      "최적화 완료!\n"
     ]
    }
   ],
   "source": [
    "# 4. 신경망 모델 학습\n",
    "# 1) 모델학습 초기화\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "# 2) 모델의 훈련\n",
    "for epoch in range(training_epoch):\n",
    "    total_cost = 0\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        _, cost_val = sess.run([optimizer, cost], feed_dict={X: batch_xs})\n",
    "        total_cost += cost_val\n",
    "    if epoch % 4 == 0:\n",
    "        print('Epoch:', '%04d'%(epoch+1),\n",
    "              'Avg.cost =', '{:.4f}'.format(total_cost / total_batch))\n",
    "print('최적화 완료!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAACNCAYAAACT6v+eAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKUVRFEVRlDDQyZSiKIqiKEoY/D9ZSRJ2gJZAqgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f31e445ba90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5. 모델의 성능평가\n",
    "sample_size = 10\n",
    "samples = sess.run(decoder,\n",
    "                   feed_dict = {X: mnist.test.images[ :sample_size]})\n",
    "fig, ax = plt.subplots(2, sample_size, figsize=(sample_size, 2))\n",
    "for i in range(sample_size):\n",
    "    # 원본 이미지를 출력\n",
    "    ax[0][i].set_axis_off()\n",
    "    ax[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))\n",
    "    # AutoEncoder로 생성한 이미지를 출력\n",
    "    ax[1][i].set_axis_off()\n",
    "    ax[1][i].imshow(np.reshape(samples[i], (28, 28)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "# <strong>Tensor Flow Deep Learning\n",
    "<strong>Unsupervised Learning\n",
    "\n",
    "<strong>Chapter 8 : GAN (Generative Adversarial Network)</strong>\n",
    "\n",
    "대립하는 두 신경망을 경쟁시킴으로써 결과물 생성하는 학습모듈\n",
    "1. Discriminator(구분자)에게 이미지가 진짜임을 판단하게 한다\n",
    "1. Generator(생성자)를 통해 노이즈로 부터 임의 이미지를 만들고, 이를 진짜 이미지여부를 판단한다\n",
    "1. <strong>생성자가 가짜 이미지</strong>를 만들고, <strong>구분자가 이를 구분하는 훈련</strong>을 통해서 진짜 이미지 구별능력을 향상시킨다\n",
    "\n",
    "<strong>ex) 위조지폐 범죄자와, 경찰을 경쟁시켜 완벽한 위조지폐/ 원본화폐를 찾는 학습모듈을 생성\n",
    "\n",
    "<img src=\"https://oshearesearch.com/wp-content/uploads/2016/07/mnist_gan.png\" align='left' width='600'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "## <strong>1 GNA Deep Learning\n",
    "https://arxiv.org/abs/1406.2661\n",
    "\n",
    "Generator(생성자)가 실제와 상당히 비슷한 이미지를 생성하는 능력을 키운다\n",
    "1. 이미지에서 고흐풍의 <strong>이미지를 재현</strong>\n",
    "1. 테두리만 있는 <strong>이미지를 자동채색</strong>\n",
    "1. <strong>모자이크 이미지를 복원</strong> 등에서 탁월한 성능을 나타낸다\n",
    "1. 기타 <strong>자연어 문장 생성</strong>의 연구에서도 활발한 성능을 나타낸다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "## <strong>2 GNA 기본 모델의 구현\n",
    "<strong>Unsupervised 학습인 Generative Adversarial Network (GAN) 2016 을 구현한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./data/mnist/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. 파라미터 설정\n",
    "# 1) 옵션 설정\n",
    "total_epoch = 50\n",
    "batch_size = 100\n",
    "learning_rate = 0.0002\n",
    "\n",
    "# 2) 신경망 레이어 구성 옵션\n",
    "n_hidden = 256\n",
    "n_input = 28 * 28\n",
    "n_noise = 128  # 생성기의 입력값으로 사용할 노이즈의 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. 신경망의 파라미터를 설정\n",
    "# 1) 입력/ 출력부분 설정\n",
    "# GAN 도 Unsupervised 학습이므로 Y 를 사용하지 않는다\n",
    "X = tf.placeholder(tf.float32, [None, n_input])\n",
    "# 대신 노이즈 Z를 추가 입력값으로 사용\n",
    "Z = tf.placeholder(tf.float32, [None, n_noise])\n",
    "\n",
    "# 2) Generator : 생성기 신경망의 변수를 설정\n",
    "G_W1 = tf.Variable(tf.random_normal([n_noise, n_hidden], stddev=0.01)) # 입력부분\n",
    "G_b1 = tf.Variable(tf.zeros([n_hidden]))\n",
    "G_W2 = tf.Variable(tf.random_normal([n_hidden, n_input], stddev=0.01))\n",
    "G_b2 = tf.Variable(tf.zeros([n_input]))\n",
    "\n",
    "# 3) Discriminator : 판별기 신경망에 사용하는 변수를 설정\n",
    "D_W1 = tf.Variable(tf.random_normal([n_input, n_hidden], stddev=0.01))\n",
    "D_b1 = tf.Variable(tf.zeros([n_hidden]))\n",
    "# 판별기의 최종 결과값이 진짜와 얼마나 가까운지를 판단 : Scalar\n",
    "D_W2 = tf.Variable(tf.random_normal([n_hidden, 1], stddev=0.01)) # 출력부분\n",
    "D_b2 = tf.Variable(tf.zeros([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3. 신경망의 모델을 정의한다\n",
    "# 생성기(G) 신경망 정의\n",
    "def generator(noise_z):\n",
    "    hidden = tf.nn.relu(tf.matmul(noise_z, G_W1) + G_b1)\n",
    "    output = tf.nn.sigmoid(tf.matmul(hidden, G_W2) + G_b2)\n",
    "    return output\n",
    "\n",
    "# 판별기(D) 신경망 정의\n",
    "def discriminator(inputs):\n",
    "    hidden = tf.nn.relu(tf.matmul(inputs, D_W1) + D_b1)\n",
    "    output = tf.nn.sigmoid(tf.matmul(hidden, D_W2) + D_b2)\n",
    "    return output\n",
    "\n",
    "# 랜덤한 노이즈(Z)를 생성\n",
    "def get_noise(batch_size, n_noise):\n",
    "    return np.random.normal(size=(batch_size, n_noise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4. 노이즈를 이용해 랜덤한 이미지를 생성\n",
    "G = generator(Z)\n",
    "# 노이즈를 이용해 생성한 이미지가 진짜 이미지인지 판별\n",
    "D_gene = discriminator(G)\n",
    "# 진짜 이미지를 이용해 판별한 결과를 출력\n",
    "D_real = discriminator(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5. 이미지 판별기/ 생성기의 코스트 함수\n",
    "# GAN 모델의 최적화는 loss_G, loss_D 를 최대로 갖는 모델을 설계한다\n",
    "# 하지만 loss_D와 loss_G는 경쟁관계로 서로 반대로 움직인다\n",
    "# 논문의 수식에서는 loss_D 를 최대화하기 위해, D_gene 를 최소화 한다\n",
    "# tf.log(D_real) : 판별기에 진짜 이미지를 넣었을 때 최대값을 출력한다\n",
    "# tf.log(1 - D_gene) : 가짜 이미지를 넣었을 때에도 최대값을 출력한다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 이것은 판별기는 생성기가 만들어낸 이미지가 가짜라고 판단하도록 판별기 신경망을 학습시킵니다.\n",
    "loss_D = tf.reduce_mean(tf.log(D_real) + tf.log(1 - D_gene))\n",
    "# loss_G 를 최대로 하기 위해서는, D_gene 도 같이 최대가 되어야 한다\n",
    "# cf) 논문에서는 loss_D 와 같은 수식으로 최소화 하는 생성기를 찾는다\n",
    "loss_G = tf.reduce_mean(tf.log(D_gene))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loss_D 는 판별기 신경망에 사용되는 변수를 사용하고,\n",
    "# loss_G 는 생성기 신경망에 사용되는 변수만 사용하여 최적화를 합니다.\n",
    "D_var_list = [D_W1, D_b1, D_W2, D_b2]\n",
    "G_var_list = [G_W1, G_b1, G_W2, G_b2]\n",
    "\n",
    "# GAN 논문의 수식에 따르면 loss 를 극대화 해야하지만, minimize 하는 최적화 함수를 사용하기 때문에\n",
    "# 최적화 하려는 loss_D 와 loss_G 에 음수 부호를 붙여줍니다.\n",
    "train_D = tf.train.AdamOptimizer(learning_rate).minimize(-loss_D,\n",
    "                                                         var_list=D_var_list)\n",
    "train_G = tf.train.AdamOptimizer(learning_rate).minimize(-loss_G,\n",
    "                                                         var_list=G_var_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 6. 신경망 모델의 학습\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "loss_val_D, loss_val_G = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0000 D loss: -0.2683 \n",
      "G loss: -2.574\n",
      "Epoch: 0003 D loss: -0.3794 \n",
      "G loss: -2.227\n",
      "Epoch: 0006 D loss: -0.2935 \n",
      "G loss: -2.709\n",
      "Epoch: 0009 D loss: -0.5099 \n",
      "G loss: -1.874\n",
      "Epoch: 0012 D loss: -0.4449 \n",
      "G loss: -2.44\n",
      "Epoch: 0015 D loss: -0.4726 \n",
      "G loss: -2.549\n",
      "Epoch: 0018 D loss: -0.4627 \n",
      "G loss: -2.276\n",
      "Epoch: 0021 D loss: -0.4595 \n",
      "G loss: -2.412\n",
      "Epoch: 0024 D loss: -0.486 \n",
      "G loss: -2.107\n",
      "Epoch: 0027 D loss: -0.5461 \n",
      "G loss: -2.107\n",
      "Epoch: 0030 D loss: -0.6256 \n",
      "G loss: -2.417\n",
      "Epoch: 0033 D loss: -0.3869 \n",
      "G loss: -2.63\n",
      "Epoch: 0036 D loss: -0.517 \n",
      "G loss: -2.497\n",
      "Epoch: 0039 D loss: -0.5831 \n",
      "G loss: -2.133\n",
      "Epoch: 0042 D loss: -0.6225 \n",
      "G loss: -1.776\n",
      "Epoch: 0045 D loss: -0.6426 \n",
      "G loss: -2.286\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-e040b6d1fe01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_noise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# 판별기와 생성기 신경망을 각각 학습시킵니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_val_D\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_D\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_val_G\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_G\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_G\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/markbaum/Python/python36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/markbaum/Python/python36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/markbaum/Python/python36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/markbaum/Python/python36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/markbaum/Python/python36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(total_epoch):\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        noise = get_noise(batch_size, n_noise)\n",
    "        # 판별기와 생성기 신경망을 각각 학습시킵니다.\n",
    "        _, loss_val_D = sess.run([train_D, loss_D], feed_dict={X: batch_xs, Z: noise})\n",
    "        _, loss_val_G = sess.run([train_G, loss_G], feed_dict={Z: noise})\n",
    "    if epoch % 3 == 0 :\n",
    "        print('Epoch:', '%04d' % epoch,\n",
    "              'D loss: {:.4} \\nG loss: {:.4}'.format(loss_val_D,loss_val_G))\n",
    "\n",
    "    # 7. 학습이 되어가는 모습을 보기 위해 주기적으로 이미지를 생성하여 저장\n",
    "    if epoch == 0 or (epoch + 1) % 10 == 0:\n",
    "        sample_size = 10\n",
    "        noise = get_noise(sample_size, n_noise)\n",
    "        samples = sess.run(G, feed_dict={Z: noise})\n",
    "        fig, ax = plt.subplots(1, sample_size, figsize=(sample_size, 1))\n",
    "        for i in range(sample_size):\n",
    "            ax[i].set_axis_off()\n",
    "            ax[i].imshow(np.reshape(samples[i], (28, 28)))\n",
    "        # samples 폴더에, 이미지 생성결과를 저장한다\n",
    "        plt.savefig('gan_sample/{}.png'.format(str(epoch).zfill(3)), bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "print('최적화 완료!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "## <strong>3 원하는 숫자의 이미지 생성모델 구현\n",
    "<strong>특정한 숫자 이미지를 생성하는 모델을 설계한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GAN 모델을 이용해 원하는 손글씨 숫자를 생성하는 모델을 생성\n",
    "# (흑백 사진을 컬러로 변경, 선화의 채색등의 응용이 가능)\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./data/mnist/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. 파라미터 설정\n",
    "total_epoch = 100\n",
    "batch_size = 100\n",
    "n_hidden = 256\n",
    "n_input = 28 * 28\n",
    "n_noise = 128\n",
    "n_class = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. 신경망 모델 구성\n",
    "X = tf.placeholder(tf.float32, [None, n_input])\n",
    "Y = tf.placeholder(tf.float32, [None, n_class]) # 노이즈 추가를 위한 매개변수\n",
    "Z = tf.placeholder(tf.float32, [None, n_noise])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (1) GAN 모델의 생성 1 (생성자) : tf.variable_scope()로 생성자를 정의한다\n",
    "def generator(noise, labels):\n",
    "    with tf.variable_scope('generator') :                    \n",
    "        inputs = tf.concat([noise, labels], 1)                                # noise 에 labels 정보를 추가한다\n",
    "        hidden = tf.layers.dense(inputs, n_hidden, activation = tf.nn.relu)   # 신경망 모델 : TF 유틸리티 함수를 활용\n",
    "        output = tf.layers.dense(hidden, n_input, activation = tf.nn.sigmoid) \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (2) GAN 모델의 생성 2 (구분자) : tf.variable_scope()로 구분자를 정의한다\n",
    "# tf.variable_scope.reuse_variables() : 이전에 사용된 매개변수를 재사용 !!!\n",
    "# cf) 앞의 코드들은 '생성자', '구분자' 개별 매개변수를 사용하여 불필요한 반복을 요한다\n",
    "def discriminator(inputs, labels, reuse = None):\n",
    "    with tf.variable_scope('discriminator') as scope:\n",
    "        if reuse:               \n",
    "            scope.reuse_variables()\n",
    "        inputs = tf.concat([inputs, labels], 1)\n",
    "        hidden = tf.layers.dense(inputs, n_hidden, activation = tf.nn.relu)\n",
    "        output = tf.layers.dense(hidden, 1, activation = None)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (3) 노이즈를 균등분포로 생성한다\n",
    "def get_noise(batch_size, n_noise):\n",
    "    return np.random.uniform(-1., 1., size=[batch_size, n_noise])\n",
    "\n",
    "# '임의생성 이미지 데이터'의 '구분자'를 하나씩 정의한다\n",
    "# generator() : 매개변수 생성\n",
    "# discriminator() : 생성, 판별모델에 Y (labels 정보)를 추가한다 (labels 해당 이미지를 생성도록 유도)\n",
    "# discriminator(  , reuse = True) : '구분자'의 변수들을 재사용\n",
    "G = generator(Z, Y)\n",
    "D_real = discriminator(X, Y)\n",
    "D_gene = discriminator(G, Y, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3. 손실함수 (GAN 논문과는 변형을 주었다) - http://bamos.github.io/2016/08/09/deep-completion/\n",
    "# D_real (진짜를 구분)는 1에 가깝도록, D_gene (가짜를 구분)는 0에 가깝도록 한다\n",
    "loss_D_real = tf.reduce_mean(\n",
    "                    tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                        logits=D_real, labels=tf.ones_like(D_real)))\n",
    "loss_D_gene = tf.reduce_mean(\n",
    "                    tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                        logits=D_gene, labels=tf.zeros_like(D_gene)))\n",
    "\n",
    "# loss_D_real 과 loss_D_gene 를 더한 값을, 최소화로 하는 최적값을 계산한다\n",
    "loss_D = loss_D_real + loss_D_gene \n",
    "# '생성자' 학습을 위한 손실함수를 정의한다 (D_gene 를 1에 가깝도록 손실함수를 정의)\n",
    "loss_G = tf.reduce_mean(\n",
    "                    tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                        logits=D_gene, labels=tf.ones_like(D_gene)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4. 개별 매개변수와 함수를 종합하여 모델을 완성한다\n",
    "# tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='') : 유틸리티 함수로 변수들을 쉽게 가져올 수 있다.\n",
    "vars_D = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='discriminator')\n",
    "train_D = tf.train.AdamOptimizer().minimize(loss_D, var_list=vars_D)\n",
    "vars_G = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='generator')\n",
    "train_G = tf.train.AdamOptimizer().minimize(loss_G, var_list=vars_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5. 신경망 모델 학습 (running Session)\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "loss_val_D, loss_val_G = 0, 0\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        noise = get_noise(batch_size, n_noise)\n",
    "        _, loss_val_D = sess.run([train_D, loss_D],\n",
    "                                 feed_dict={X: batch_xs, Y: batch_ys, Z: noise})\n",
    "        _, loss_val_G = sess.run([train_G, loss_G],\n",
    "                                 feed_dict={Y: batch_ys, Z: noise})\n",
    "\n",
    "    print('Epoch:', '%04d' % epoch, 'D loss: {:.4} \\nG loss: {:.4}'.format(loss_val_D,loss_val_G))\n",
    "\n",
    "    if epoch == 0 or (epoch + 1) % 10 == 0:     # 학습과정을 기록, 주기적으로 레이블에 이미지를 저장\n",
    "        sample_size = 10\n",
    "        noise = get_noise(sample_size, n_noise)\n",
    "        samples = sess.run(G,\n",
    "                           feed_dict={Y: mnist.test.labels[:sample_size],\n",
    "                                      Z: noise})\n",
    "\n",
    "        fig, ax = plt.subplots(2, sample_size, figsize=(sample_size, 2))\n",
    "\n",
    "        for i in range(sample_size):\n",
    "            ax[0][i].set_axis_off()\n",
    "            ax[1][i].set_axis_off()\n",
    "            ax[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))\n",
    "            ax[1][i].imshow(np.reshape(samples[i], (28, 28)))\n",
    "        plt.savefig('gan_sample2/{}.png'.format(str(epoch).zfill(3)), bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "print('최적화 완료!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
