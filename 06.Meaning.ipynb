{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6 - Semantic Analysis – Meaning Matters\n",
    "\n",
    "의미 분석 - 본질의 표현 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NER\n",
    "# HMM을 사용한 NER 시스템\n",
    "# 기계 학습툴킷을 사용한 NER 훈련\n",
    "# POS 태깅을 사용한 NER \n",
    "# Wordnet에서 synset if의 생성\n",
    "# Wordnet을 사용한 의미 판별"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## 1 Introducing semantic analysis\n",
    "의미분석 : 문장을 공식을 활용하여, 명제기호로 표현 (P,Q,R...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 의미분석 : 데이터베이스를 질의하고, 정보를 검색\n",
    "# Gensim : 문서 indexing, 주제 modeling, 유사성 검색을 수행\n",
    "# polyglot : 다국어를 지원하는 NLP 도구로 40개 언어를 지원한다\n",
    "\n",
    "# P  : It is raining. (원인문장)\n",
    "# Q  : I'll wear raincoat. (결과문장)\n",
    "# P→Q: If it is raining, I'll wear a raincoat.(원인 -> 결과)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01 Introduction\n",
    "기본 연산함수 내용정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negation       \t-\n",
      "conjunction    \t&\n",
      "disjunction    \t|\n",
      "implication    \t->\n",
      "equivalence    \t<->\n"
     ]
    }
   ],
   "source": [
    "# Boolean로 사용가능한 연산자를 출력\n",
    "import nltk\n",
    "nltk.boolean_ops()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(X | (Y -> Z))\n",
      "-(X & Y)\n",
      "(X & Y)\n",
      "(X <-> --X)\n"
     ]
    }
   ],
   "source": [
    "# Well formed Formulas : 명제기호나, 명제 기호와 Boolean 연산의 조합을 활용\n",
    "import nltk\n",
    "input_expr = nltk.sem.Expression.fromstring\n",
    "print(input_expr('X | (Y -> Z)'))\n",
    "print(input_expr('-(X & Y)'))\n",
    "print(input_expr('X & Y'))\n",
    "print(input_expr('X <-> -- X'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# 논리 표현식에 True/ False 값을 매핑\n",
    "import nltk\n",
    "value = nltk.Valuation([('X', True), ('Y', False), ('Z', True)])\n",
    "print(value['Z'])\n",
    "domain = set()\n",
    "v = nltk.Assignment(domain)\n",
    "u = nltk.Model(domain, value)\n",
    "print(u.evaluate('(X & Y)', v))\n",
    "print(u.evaluate('-(X & Y)', v))\n",
    "print(u.evaluate('(X & Z)', v))\n",
    "print(u.evaluate('(X | Y)', v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marcus\n",
      "e\n",
      "run\n",
      "<e,?>\n"
     ]
    }
   ],
   "source": [
    "# NLTK의 상수 및 술어를 포함하는 1차 술어논리를 구현\n",
    "import nltk\n",
    "input_expr = nltk.sem.Expression.fromstring\n",
    "expression = input_expr('run(marcus)', type_check=True)\n",
    "print(expression.argument)\n",
    "print(expression.argument.type)\n",
    "print(expression.function)\n",
    "print(expression.function.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e\n"
     ]
    }
   ],
   "source": [
    "sign = {'run': '<e, t>'}\n",
    "expression = input_expr('run(marcus)', signature=sign)\n",
    "print(expression.function.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% start S\n",
      "S[SEM=(?np + WHERE + ?vp)] -> NP[SEM=?np] VP[SEM=?vp]\n",
      "VP[SEM=(?v + ?pp)] -> IV[SEM=?v] PP[SEM=?pp]\n",
      "VP[SEM=(?v + ?ap)] -> IV[SEM=?v] AP[SEM=?ap]\n",
      "VP[SEM=(?v + ?np)] -> TV[SEM=?v] NP[SEM=?np]\n",
      "VP[SEM=(?vp1 + ?c + ?vp2)] -> VP[SEM=?vp1] Conj[SEM=?c] VP[SEM=?vp2]\n",
      "NP[SEM=(?det + ?n)] -> Det[SEM=?det] N[SEM=?n]\n",
      "NP[SEM=(?n + ?pp)]  -> N[SEM=?n] PP[SEM=?pp]\n",
      "NP[SEM=?n]  -> N[SEM=?n]  | CardN[SEM=?n] \n",
      "CardN[SEM='1000'] -> '1,000,000' \n",
      "PP[SEM=(?p + ?np)] -> P[SEM=?p] NP[SEM=?np]\n",
      "AP[SEM=?pp] -> A[SEM=?a] PP[SEM=?pp]\n",
      "NP[SEM='Country=\"greece\"'] -> 'Greece'\n",
      "NP[SEM='Country=\"china\"'] -> 'China'\n",
      "Det[SEM='SELECT'] -> 'Which' | 'What'\n",
      "Conj[SEM='AND'] -> 'and'\n",
      "N[SEM='City FROM city_table'] -> 'cities'\n",
      "N[SEM='Population'] -> 'populations'\n",
      "IV[SEM=''] -> 'are'\n",
      "TV[SEM=''] -> 'have'\n",
      "A -> 'located'\n",
      "P[SEM=''] -> 'in'\n",
      "P[SEM='>'] -> 'above'\n"
     ]
    }
   ],
   "source": [
    "# Signature는 연관유형 및 비논리 상수를 매핑\n",
    "\n",
    "import nltk\n",
    "nltk.data.show_cfg('grammars/book_grammars/sql1.fcfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT City FROM city_table WHERE Country=\"greece\"\n"
     ]
    }
   ],
   "source": [
    "from nltk import load_parser\n",
    "test = load_parser('grammars/book_grammars/sql1.fcfg')\n",
    "q = \" What cities are in Greece\"\n",
    "t = list(test.parse(q.split()))\n",
    "ans = t[0].label()['SEM']\n",
    "ans = [s for s in ans if s]\n",
    "q = ' '.join(ans)\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "athens "
     ]
    }
   ],
   "source": [
    "from nltk.sem import chat80\n",
    "r = chat80.sql_query('corpora/city_database/city.db', q)\n",
    "for p in r:\n",
    "    print(p[0], end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02 NER 소개\n",
    "Named Entity Recognition : 고유명사, 개체명이 문서에 위치하는 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#    SNO  Named entity tag Meaning\n",
    "# 01 NEP  Name of Person\n",
    "# 02 NED  Name of Designation\n",
    "# 03 NEO  Name of Organization\n",
    "# 04 NEA  Name of Abbreviation\n",
    "# 05 NEB  Name of Brand\n",
    "# 06 NETP Title of Person\n",
    "# 07 NETO Title of Object\n",
    "# 08 NEL  Name of Location\n",
    "# 09 NETI Time\n",
    "# 10 NEN  Number\n",
    "# 11 NEM  Measure\n",
    "# 12 NETE Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jaipur', 'Ajmer', 'UdaipurIN']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk에서 튜플로(entity, relation, entity) 저장한 뒤, 'entity'값을 검색한다\n",
    "locations=[('Jaipur', 'IN', 'Rajasthan'),('Ajmer', 'IN', 'Rajasthan'),\n",
    "           ('UdaipurIN', 'IN','Rajasthan'),('Mumbai', 'IN', 'Maharashtra'),\n",
    "           ('Ahmedabad', 'IN', 'Gujrat')]\n",
    "\n",
    "q = [x1     for (x1, relation, x2) in locations     if x2 == 'Rajasthan']\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NER을 수행하기 위한, '스탠포드 tagger'를 활용한다\n",
    "\n",
    "from nltk.tag import StanfordNERTagger\n",
    "# sentence = StanfordNERTagger('english.all.3class.distsim.crf.ser.gz')  # Lookup Error가 발생한다\n",
    "# sentence.tag('John goes to NY'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  The/DT\n",
      "  total/NN\n",
      "  of/IN\n",
      "  18/CD\n",
      "  deaths/NNS\n",
      "  from/IN\n",
      "  malignant/JJ\n",
      "  mesothelioma/NN\n",
      "  ,/,\n",
      "  lung/NN\n",
      "  cancer/NN\n",
      "  and/CC\n",
      "  asbestosis/NN\n",
      "  was/VBD\n",
      "  far/RB\n",
      "  higher/JJR\n",
      "  than/IN\n",
      "  */-NONE-\n",
      "  expected/VBN\n",
      "  *?*/-NONE-\n",
      "  ,/,\n",
      "  the/DT\n",
      "  researchers/NNS\n",
      "  said/VBD\n",
      "  0/-NONE-\n",
      "  *T*-1/-NONE-\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "# 개체명이 존재할 경우, 이를 감지하고 'NE'태그로 tag를 지정\n",
    "import nltk\n",
    "sentences1 = nltk.corpus.treebank.tagged_sents()[17]\n",
    "print(nltk.ne_chunk(sentences1, binary=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  A/DT\n",
      "  (NE Lorillard/NNP)\n",
      "  spokewoman/NN\n",
      "  said/VBD\n",
      "  ,/,\n",
      "  ``/``\n",
      "  This/DT\n",
      "  is/VBZ\n",
      "  an/DT\n",
      "  old/JJ\n",
      "  story/NN\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "sentences2 = nltk.corpus.treebank.tagged_sents()[7]\n",
    "print(nltk.ne_chunk(sentences2, binary=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  A/DT\n",
      "  (ORGANIZATION Lorillard/NNP)\n",
      "  spokewoman/NN\n",
      "  said/VBD\n",
      "  ,/,\n",
      "  ``/``\n",
      "  This/DT\n",
      "  is/VBZ\n",
      "  an/DT\n",
      "  old/JJ\n",
      "  story/NN\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "print(nltk.ne_chunk(sentences2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(PER Vandenbussche/Adj)\n",
      "('zelf', 'Pron')\n",
      "('besloot', 'V')\n",
      "('dat', 'Conj')\n",
      "('het', 'Art')\n",
      "('hof', 'N')\n",
      "('\"', 'Punc')\n",
      "('de', 'Art')\n",
      "('politieke', 'Adj')\n",
      "('zeden', 'N')\n",
      "('uit', 'Prep')\n",
      "('het', 'Art')\n",
      "('verleden', 'N')\n",
      "('\"', 'Punc')\n",
      "('heeft', 'V')\n",
      "('willen', 'V')\n",
      "('veroordelen', 'V')\n",
      "('.', 'Punc')\n"
     ]
    }
   ],
   "source": [
    "# 개체명을 감지하는 nltk를 다른예제로 수행\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import conll2002\n",
    "for documents in conll2002.chunked_sents('ned.train')[25]:\n",
    "    print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Tree('S', [('I', 'PRP'), ('went', 'VBD'), ('to', 'TO'), Tree('GPE', [('Greece', 'NNP')]), ('to', 'TO'), ('meet', 'VB'), Tree('PERSON', [('John', 'NNP')])])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chunk는 plain text를 의미상 관련된 순서로 분할하는데 사용\n",
    "# 영어, 네델란드어, 스페인어, 포르투갈어를 활용가능하다\n",
    "\n",
    "import nltk\n",
    "sentence = \"I went to Greece to meet John\"\n",
    "tok = nltk.word_tokenize(sentence)\n",
    "pos_tag = nltk.pos_tag(tok)\n",
    "nltk.ne_chunk(pos_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03 은닉 마르코프 모델을 사용한 NER 시스템\n",
    "Named Entity Recognition : 고유명사, 개체명이 문서에 위치하는 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HMM은 확률분포와 관련된 유한집함으로 구성된 Stochastic Finite State Automaton로 정의된다\n",
    "# HMM은 '마르코프 체인'속성에 따라, 이전 tag의 확률에 따라 값이 변하므로\n",
    "# 단점은 많은 훈련과 의존성이 따르지만\n",
    "# 장점은 간단한 방법으로도 가능하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HMM POS tagging demo\n",
      "\n",
      "Training HMM...\n",
      "Testing...\n",
      "Test: the/AT fulton/NP county/NN grand/JJ jury/NN said/VBD friday/NR an/AT investigation/NN of/IN atlanta's/NP$ recent/JJ primary/NN election/NN produced/VBD ``/`` no/AT evidence/NN ''/'' that/CS any/DTI irregularities/NNS took/VBD place/NN ./.\n",
      "\n",
      "Untagged: the fulton county grand jury said friday an investigation of atlanta's recent primary election produced `` no evidence '' that any irregularities took place .\n",
      "\n",
      "HMM-tagged: the/AT fulton/NP county/NN grand/JJ jury/NN said/VBD friday/NR an/AT investigation/NN of/IN atlanta's/NP$ recent/JJ primary/NN election/NN produced/VBD ``/`` no/AT evidence/NN ''/'' that/CS any/DTI irregularities/NNS took/VBD place/NN ./.\n",
      "\n",
      "Entropy: 18.7331739705\n",
      "\n",
      "------------------------------------------------------------\n",
      "Test: the/AT jury/NN further/RBR said/VBD in/IN term-end/NN presentments/NNS that/CS the/AT city/NN executive/JJ committee/NN ,/, which/WDT had/HVD over-all/JJ charge/NN of/IN the/AT election/NN ,/, ``/`` deserves/VBZ the/AT praise/NN and/CC thanks/NNS of/IN the/AT city/NN of/IN atlanta/NP ''/'' for/IN the/AT manner/NN in/IN which/WDT the/AT election/NN was/BEDZ conducted/VBN ./.\n",
      "\n",
      "Untagged: the jury further said in term-end presentments that the city executive committee , which had over-all charge of the election , `` deserves the praise and thanks of the city of atlanta '' for the manner in which the election was conducted .\n",
      "\n",
      "HMM-tagged: the/AT jury/NN further/RBR said/VBD in/IN term-end/AT presentments/NN that/CS the/AT city/NN executive/NN committee/NN ,/, which/WDT had/HVD over-all/VBN charge/NN of/IN the/AT election/NN ,/, ``/`` deserves/VBZ the/AT praise/NN and/CC thanks/NNS of/IN the/AT city/NN of/IN atlanta/NP ''/'' for/IN the/AT manner/NN in/IN which/WDT the/AT election/NN was/BEDZ conducted/VBN ./.\n",
      "\n",
      "Entropy: 27.0708725519\n",
      "\n",
      "------------------------------------------------------------\n",
      "Test: the/AT september-october/NP term/NN jury/NN had/HVD been/BEN charged/VBN by/IN fulton/NP superior/JJ court/NN judge/NN durwood/NP pye/NP to/TO investigate/VB reports/NNS of/IN possible/JJ ``/`` irregularities/NNS ''/'' in/IN the/AT hard-fought/JJ primary/NN which/WDT was/BEDZ won/VBN by/IN mayor-nominate/NN ivan/NP allen/NP jr./NP ./.\n",
      "\n",
      "Untagged: the september-october term jury had been charged by fulton superior court judge durwood pye to investigate reports of possible `` irregularities '' in the hard-fought primary which was won by mayor-nominate ivan allen jr. .\n",
      "\n",
      "HMM-tagged: the/AT september-october/JJ term/NN jury/NN had/HVD been/BEN charged/VBN by/IN fulton/NP superior/JJ court/NN judge/NN durwood/TO pye/VB to/TO investigate/VB reports/NNS of/IN possible/JJ ``/`` irregularities/NNS ''/'' in/IN the/AT hard-fought/JJ primary/NN which/WDT was/BEDZ won/VBN by/IN mayor-nominate/NP ivan/NP allen/NP jr./NP ./.\n",
      "\n",
      "Entropy: 33.8281874237\n",
      "\n",
      "------------------------------------------------------------\n",
      "Test: ``/`` only/RB a/AT relative/JJ handful/NN of/IN such/JJ reports/NNS was/BEDZ received/VBN ''/'' ,/, the/AT jury/NN said/VBD ,/, ``/`` considering/IN the/AT widespread/JJ interest/NN in/IN the/AT election/NN ,/, the/AT number/NN of/IN voters/NNS and/CC the/AT size/NN of/IN this/DT city/NN ''/'' ./.\n",
      "\n",
      "Untagged: `` only a relative handful of such reports was received '' , the jury said , `` considering the widespread interest in the election , the number of voters and the size of this city '' .\n",
      "\n",
      "HMM-tagged: ``/`` only/RB a/AT relative/JJ handful/NN of/IN such/JJ reports/NNS was/BEDZ received/VBN ''/'' ,/, the/AT jury/NN said/VBD ,/, ``/`` considering/IN the/AT widespread/JJ interest/NN in/IN the/AT election/NN ,/, the/AT number/NN of/IN voters/NNS and/CC the/AT size/NN of/IN this/DT city/NN ''/'' ./.\n",
      "\n",
      "Entropy: 11.4378198596\n",
      "\n",
      "------------------------------------------------------------\n",
      "Test: the/AT jury/NN said/VBD it/PPS did/DOD find/VB that/CS many/AP of/IN georgia's/NP$ registration/NN and/CC election/NN laws/NNS ``/`` are/BER outmoded/JJ or/CC inadequate/JJ and/CC often/RB ambiguous/JJ ''/'' ./.\n",
      "\n",
      "Untagged: the jury said it did find that many of georgia's registration and election laws `` are outmoded or inadequate and often ambiguous '' .\n",
      "\n",
      "HMM-tagged: the/AT jury/NN said/VBD it/PPS did/DOD find/VB that/CS many/AP of/IN georgia's/NP$ registration/NN and/CC election/NN laws/NNS ``/`` are/BER outmoded/VBG or/CC inadequate/JJ and/CC often/RB ambiguous/VB ''/'' ./.\n",
      "\n",
      "Entropy: 20.8163623192\n",
      "\n",
      "------------------------------------------------------------\n",
      "Test: it/PPS recommended/VBD that/CS fulton/NP legislators/NNS act/VB ``/`` to/TO have/HV these/DTS laws/NNS studied/VBN and/CC revised/VBN to/IN the/AT end/NN of/IN modernizing/VBG and/CC improving/VBG them/PPO ''/'' ./.\n",
      "\n",
      "Untagged: it recommended that fulton legislators act `` to have these laws studied and revised to the end of modernizing and improving them '' .\n",
      "\n",
      "HMM-tagged: it/PPS recommended/VBD that/CS fulton/NP legislators/NNS act/VB ``/`` to/TO have/HV these/DTS laws/NNS studied/VBD and/CC revised/VBD to/IN the/AT end/NN of/IN modernizing/NP and/CC improving/VBG them/PPO ''/'' ./.\n",
      "\n",
      "Entropy: 20.3244921203\n",
      "\n",
      "------------------------------------------------------------\n",
      "Test: the/AT grand/JJ jury/NN commented/VBD on/IN a/AT number/NN of/IN other/AP topics/NNS ,/, among/IN them/PPO the/AT atlanta/NP and/CC fulton/NP county/NN purchasing/VBG departments/NNS which/WDT it/PPS said/VBD ``/`` are/BER well/QL operated/VBN and/CC follow/VB generally/RB accepted/VBN practices/NNS which/WDT inure/VB to/IN the/AT best/JJT interest/NN of/IN both/ABX governments/NNS ''/'' ./.\n",
      "\n",
      "Untagged: the grand jury commented on a number of other topics , among them the atlanta and fulton county purchasing departments which it said `` are well operated and follow generally accepted practices which inure to the best interest of both governments '' .\n",
      "\n",
      "HMM-tagged: the/AT grand/JJ jury/NN commented/VBD on/IN a/AT number/NN of/IN other/AP topics/NNS ,/, among/IN them/PPO the/AT atlanta/NP and/CC fulton/NP county/NN purchasing/NN departments/NNS which/WDT it/PPS said/VBD ``/`` are/BER well/RB operated/VBN and/CC follow/VB generally/RB accepted/VBN practices/NNS which/WDT inure/VBZ to/IN the/AT best/JJT interest/NN of/IN both/ABX governments/NNS ''/'' ./.\n",
      "\n",
      "Entropy: 31.3834231469\n",
      "\n",
      "------------------------------------------------------------\n",
      "Test: merger/NN proposed/VBN\n",
      "\n",
      "Untagged: merger proposed\n",
      "\n",
      "HMM-tagged: merger/PPS proposed/VBD\n",
      "\n",
      "Entropy: 5.6718203946\n",
      "\n",
      "------------------------------------------------------------\n",
      "Test: however/WRB ,/, the/AT jury/NN said/VBD it/PPS believes/VBZ ``/`` these/DTS two/CD offices/NNS should/MD be/BE combined/VBN to/TO achieve/VB greater/JJR efficiency/NN and/CC reduce/VB the/AT cost/NN of/IN administration/NN ''/'' ./.\n",
      "\n",
      "Untagged: however , the jury said it believes `` these two offices should be combined to achieve greater efficiency and reduce the cost of administration '' .\n",
      "\n",
      "HMM-tagged: however/WRB ,/, the/AT jury/NN said/VBD it/PPS believes/VBZ ``/`` these/DTS two/CD offices/NNS should/MD be/BE combined/VBN to/TO achieve/VB greater/JJR efficiency/NN and/CC reduce/VB the/AT cost/NN of/IN administration/NN ''/'' ./.\n",
      "\n",
      "Entropy: 8.27545943908\n",
      "\n",
      "------------------------------------------------------------\n",
      "Test: the/AT city/NN purchasing/VBG department/NN ,/, the/AT jury/NN said/VBD ,/, ``/`` is/BEZ lacking/VBG in/IN experienced/VBN clerical/JJ personnel/NNS as/CS a/AT result/NN of/IN city/NN personnel/NNS policies/NNS ''/'' ./.\n",
      "\n",
      "Untagged: the city purchasing department , the jury said , `` is lacking in experienced clerical personnel as a result of city personnel policies '' .\n",
      "\n",
      "HMM-tagged: the/AT city/NN purchasing/NN department/NN ,/, the/AT jury/NN said/VBD ,/, ``/`` is/BEZ lacking/VBG in/IN experienced/AT clerical/JJ personnel/NNS as/CS a/AT result/NN of/IN city/NN personnel/NNS policies/NNS ''/'' ./.\n",
      "\n",
      "Entropy: 16.7622537278\n",
      "\n",
      "------------------------------------------------------------\n",
      "accuracy over 284 tokens: 92.96\n"
     ]
    }
   ],
   "source": [
    "# HMM을 사용해서 NER을 수행하는 Annotation, HMM train, HMM test 단계를 거친다\n",
    "\n",
    "import nltk\n",
    "nltk.tag.hmm.demo_pos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NER tagger의 결과는 response 와 answer key로써 인간의 해석으로 정의가 가능하다\n",
    "# 1 Correct(일치) : 응답이 대답키와 정확히 일치\n",
    "# 2 Incorrect(불일치) : 응답이 대답키와 같지 않은경우\n",
    "# 3 Missing (실종) : 응답 tag 미지정, 대답 tag 지정\n",
    "# 4 Spurious(가짜) : 응답 tag 지정, 대답 tag 미지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NER 기반 시스템의 성능평가\n",
    "# 1 Precision (P) : 정확도 측정\n",
    "#   P = Correct / ( Correct + Incorrect + Missing )\n",
    "# 2 Recall (R) \n",
    "#   R = Correct / ( Correct + Incorrect + Spurious )\n",
    "# 3 F-Measure\n",
    "#   F-Measure = (2 * PREC * REC) / (PRE + REC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04 기계학습 툴킷을 사용한 NER 훈련\n",
    "NER의 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1 규칙 기반 혹은 수동 접근\n",
    "#   리스트 look up 접근\n",
    "#   언어 접근\n",
    "\n",
    "# 2 기계학습 기반 접근, 혹은 자동화된 접근\n",
    "#   은닉 마르코프 모델\n",
    "#   최대 엔트로피 마르코프 모델\n",
    "#   조건부 임의 필드\n",
    "#   SVM (서포트 벡터 머신)\n",
    "#   Decision Tree\n",
    "\n",
    "# 기계학습 기반이 규칙기반에 비해 성능이 더 좋다, \n",
    "# 규칙기반과 기계학습을 함께 사용하면 최적의 NER을 잘 찾을 수 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05 POS 태깅을 사용한 NER\n",
    "형태소 분석기 (Pos tagging)의 tag 목록\n",
    "\n",
    "https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('John', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('Smith', 'NNP'),\n",
       " ('are', 'VBP'),\n",
       " ('going', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('NY', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('Germany', 'NNP')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POS 태깅을 사용해 NER을 수해한다\n",
    "import nltk\n",
    "from nltk import pos_tag, word_tokenize\n",
    "pos_tag(word_tokenize(\"John and Smith are going to NY and Germany\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John -> NP\n",
      "and -> CC\n",
      "Smith -> None\n",
      "went -> VBD\n",
      "to -> TO\n",
      "NY -> None\n",
      "and -> CC\n",
      "Germany -> None\n"
     ]
    }
   ],
   "source": [
    "# NLTK에서 POS 태깅이 수행되고, POS태그 정보가 객체명을 검색하는 예제\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk.tag import UnigramTagger\n",
    "tagger = UnigramTagger(brown.tagged_sents(categories='news')[:700])\n",
    "\n",
    "sentence = ['John','and','Smith','went','to','NY','and','Germany']\n",
    "for word, tag in tagger.tag(sentence):\n",
    "    print(word,'->',tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 결과\n",
    "# John은 NP로 태깅되어 개체명이 식별되고, 일부 DB에 없는 내용은 None으로 tag가 지정된다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## 2 Wordnet의 synset id 생성\n",
    "Wordnet은 영어어휘 DB로 정의가 가능하다\n",
    "\n",
    "상위어, 동의어, 반의어 및 하위어 같은 개념의존성을 synsets를 사용해서 찾을 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# synsets : Wordnet중 '영어'의 단어 묶음을 synsets으로 명명한다\n",
    "# Iterate over all synsets with a given part of speech tag.\n",
    "# If no pos is specified, all synsets for all parts of speech\n",
    "# will be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주어진 품사tag로 sunsets을 반복한다, POS를 지정하지 않으면 sunsets이 로드된다\n",
    "def all_synsets(self, pos=None):\n",
    "    if pos is None:\n",
    "        pos_tags = self._FILEMAP.keys()\n",
    "    else:\n",
    "        pos_tags = [pos]\n",
    "        cache = self._synset_offset_cache\n",
    "        from_pos_and_line = self._synset_from_pos_and_line\n",
    "        for pos_tag in pos_tags:  # 각 품사에 대한 synsets을 생성\n",
    "        # self._data_file_map 에 포함된 file poitners들은 재사용이 불가능하다\n",
    "            if pos_tag == ADJ_SAT:\n",
    "                pos_tag = ADJ\n",
    "                fileid = 'data.%s' % self._FILEMAP[pos_tag]\n",
    "                data_file = self.open(fileid)\n",
    "                try:\n",
    "                    offset = data_file.tell() # POS 파일에 각 행에 대한 synset을 생성 \n",
    "                    line = data_file.readline()\n",
    "                    while line:\n",
    "                        if not line[0].isspace():\n",
    "                            if offset in cache[pos_tag]:\n",
    "                                synset = cache[pos_tag][offset] # synset 이 캐시에 로드를 확인\n",
    "                            else: # 로드되지 않을떄, line을 파싱한다\n",
    "                                synset = from_pos_and_line(pos_tag, line)\n",
    "                                cache[pos_tag][offset] = synset\n",
    "                        # satellites은 형용사로 파일에 포함되어 있다, satellite은 synset을 생성한다\n",
    "                        if synset._pos == ADJ_SAT: yield synset\n",
    "                        else: yield synset # 기타 다른 POS태그는 모든 synsets을 얻는다\n",
    "                    offset = data_file.tell()\n",
    "                    line = data_file.readline()\n",
    "                except:      # 오픈한 여분의 파일 핸들을 닫는다\n",
    "                    data_file.close()\n",
    "                    raise\n",
    "        else: data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('cat.n.01'),\n",
       " Synset('guy.n.01'),\n",
       " Synset('cat.n.03'),\n",
       " Synset('kat.n.01'),\n",
       " Synset('cat-o'-nine-tails.n.01'),\n",
       " Synset('caterpillar.n.02'),\n",
       " Synset('big_cat.n.01'),\n",
       " Synset('computerized_tomography.n.01'),\n",
       " Synset('cat.v.01'),\n",
       " Synset('vomit.v.01')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# synsets를 사용해 단어를 검색하는데 사용\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import wordnet as wn\n",
    "wn.synsets('cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('cat.v.01'), Synset('vomit.v.01')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('cat', pos=wn.VERB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('cat.n.01')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('cat.n.01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feline mammal usually having thick soft fur and no ability to roar: domestic cats; wildcats\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cat.n.01 은 cat 명사범주에 속하며, cat의 의미가 하나면 존재함을 의미\n",
    "print(wn.synset('cat.n.01').definition())\n",
    "len(wn.synset('cat.n.01').examples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('cat.n.01.cat'), Lemma('cat.n.01.true_cat')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('cat.n.01').lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat', 'true_cat']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[str(lemma.name()) for lemma in wn.synset('cat.n.01').lemmas()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('cat.n.01')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.lemma('cat.n.01.cat').synset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat', 'eng', 'eus', 'glg', 'ita', 'pol', 'spa']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk ISO 639 언어코드를 사용한 Sunsets \n",
    "# 및 오픈 다중 언어의 사용하는 코딩\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import wordnet as wn\n",
    "sorted(wn.langs()[::4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gatto']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('cat.n.01').lemma_names('ita')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('cat.n.01.kat'), Lemma('cat.n.01.mis'), Lemma('cat.n.01.missekat')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(wn.synset('cat.n.01').lemmas('dan'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('cat.n.01.Gato-doméstico'),\n",
       " Lemma('cat.n.01.Gato_doméstico'),\n",
       " Lemma('cat.n.01.bichano'),\n",
       " Lemma('cat.n.01.gata'),\n",
       " Lemma('cat.n.01.gato'),\n",
       " Lemma('cat.n.01.gato-doméstico')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(wn.synset('cat.n.01').lemmas('por'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64797"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordnet.all_lemma_names(pos='n', lang='jpn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('feline.n.01')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat = wn.synset('cat.n.01')\n",
    "cat.hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('domestic_cat.n.01'), Synset('wildcat.n.03')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat.hyponyms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## 3 Wordnet을 사용한 의미판별\n",
    "의미판별을 위해, Sense(감각) 혹은 의미(meaning)에 기초하여, 둘 이상의 동일한 철자 혹은 동일한 소리를 구별하는 직업이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Question : Lesk 의 개념은 무엇인가??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lesk 알고리즘\n",
    "#   오리지널, cos() Lesk, simple Lesk, 적용/확장 Lesk, 강화 Lesk\n",
    "# 최대 유사성 (similarity) : 정보의 내용, 경로 유사성\n",
    "# Supervised WSD (지도방식) : IMS(It Makes Sense), SVM WSD\n",
    "# 벡터 공간 모델 : 토픽모델 LDA, LSI/LSA, NMF\n",
    "# 그래프 기반 모델 : Babelfly, UKB\n",
    "# 베이스라인 : Random Sense, Highest lemma counts, First NLTK sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NLTK의 WordNet의 감각 유사성 알고리즘\n",
    "# Resnik Score: 두 개의 token의 유사성을 결정하는 점수\n",
    "# Wu-Palmer Similarity: 두 감각의 깊이에 기초한 token의 유사성\n",
    "# Path Distance Similarity: IS-분류법에 기반한 token의 유사성\n",
    "# Leacock Chodorow Similarity: 유사성 점수는 감각이 가장 짧은 경로 및 깊이에 기반\n",
    "# Lin Similarity: 유사성 점수는 두 개의 입력 synsets의 정보 컨텐츠에 기초하여 반환\n",
    "# Jiang-Conrath Similarity: Least Common Subsumer와 두개의 입력 Synsets의 정보에 기초하여 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path similarity (경로 유사성) 를 나타내는 NLTK의 예제\n",
    "from nltk.corpus import wordnet\n",
    "lion = wordnet.synset('lion.n.01')\n",
    "cat = wordnet.synset('cat.n.01')\n",
    "lion.path_similarity(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2512917986064953"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leacock Chodorow Similarity\n",
    "from nltk.corpus import wordnet\n",
    "lion = wordnet.synset('lion.n.01')\n",
    "cat = wordnet.synset('cat.n.01')\n",
    "lion.lch_similarity(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.896551724137931"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wu-Palmer Similarity\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "lion = wordnet.synset('lion.n.01')\n",
    "cat = wordnet.synset('cat.n.01')\n",
    "lion.wup_similarity(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.663481537685325\n",
      "7.339696591781996\n",
      "0.36425897775957294\n",
      "0.30578008567889475\n",
      "0.8560734335071154\n"
     ]
    }
   ],
   "source": [
    "# Resnik Similarity, Lin Similarity, and Jiang-Conrath Similarity\n",
    "from nltk.corpus import wordnet, wordnet_ic\n",
    "brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
    "semcor_ic = wordnet_ic.ic('ic-semcor.dat')\n",
    "\n",
    "from nltk.corpus import genesis\n",
    "genesis_ic = wn.ic(genesis, False, 0.0)\n",
    "lion = wn.synset('lion.n.01')\n",
    "cat = wn.synset('cat.n.01')\n",
    "print(lion.res_similarity(cat, brown_ic))\n",
    "print(lion.res_similarity(cat, genesis_ic))\n",
    "print(lion.jcn_similarity(cat, brown_ic))\n",
    "print(lion.jcn_similarity(cat, genesis_ic))\n",
    "print(lion.lin_similarity(cat, semcor_ic))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
