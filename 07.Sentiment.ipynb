{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7 Sentiment Analysis\n",
    "\n",
    "https://www.lucypark.kr/slides/2015-pyconkr/#1 Gensim을 활용 한글 긍/부정 분석\n",
    "\n",
    "http://bcho.tistory.com/1010 나이브 베이즈 분류의 기본개념"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 문장 시퀀스 뒤에 감정을 결정하는 과정으로 정의한다\n",
    "# Speaker 혹은 Text사고를 표현하는 사람의 감정을 판단하는데 사용\n",
    "\n",
    "    # 1 감정분석 소개\n",
    "    # 2 영화 리뷰의 감정분석\n",
    "    # 3 텍스트 전처리\n",
    "    # 4 NER를 사용한 감정분석 -  176 p (on_tology) 방법만 설명\n",
    "    # 5 기계학습을 사용한 감정분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## 1 Introduction\n",
    "감정분석 소개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# target : 이진분류(긍정, 부정), 멀티분류 (긍정, 부정, 중립)\n",
    "# 감정과 토픽 마이닝을 결합한 '토픽-감정분석'을 시행한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 감정분석 : lexicon (어휘목록) 을 사용해서 수행할 수 있다\n",
    "# 1 labMT (10,000단어 분석)\n",
    "# 2 Warringer (13,915단어 분석)\n",
    "# 3 OpinionFinder's Subjectivity Lexic (8221단어 분석)\n",
    "# 4 ANEW  (1034단어 분석)    : Affective Norms for English Words\n",
    "# 5 AFINN (2477단어 분석)    : Finn Arup Nielson 에 의한 분류\n",
    "# 6 Balance Affective (277 단어) : 1(긍정), 2(부정), 3(불안정), 4(중립)\n",
    "# 7 BAWL  (2200단어 분석)    : Berlin Affective Word List Reloaded\n",
    "# 8 BFAN  (210단어로 구성)    : Bilingual Finnish Affective Norms\n",
    "# 9 CDGE  : Compass DeRose Guide to Emotion Words\n",
    "# 10 DAL  : Dictionary of Affect in Language\n",
    "# 11 WDAL : Whissell's Dictionary of Affect in Language\n",
    "# 등등..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## 2 영화 리뷰의 감정분석\n",
    "sentiment analysis for movie review\n",
    "\n",
    "https://github.com/PacktPublishing/Mastering-Natural-Language-Processing-with-Python/blob/master/Chapter%207/ch7_1.py\n",
    "\n",
    "http://www.nltk.org/book/ch06.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01 학습을 위한 Train 데이터 생성하기\n",
    "nltk의 movie_review 데이터를 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "movie_reviews.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg/cv000_29416.txt',\n",
       " 'neg/cv001_19502.txt',\n",
       " 'neg/cv002_17424.txt',\n",
       " 'neg/cv003_12683.txt',\n",
       " 'neg/cv004_12641.txt']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.fileids(movie_reviews.categories()[0])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a couple of criminals ( mario van peebles and loretta devine ) move into a rich family's house in hopes of conning them out of their jewels . \r\n",
      "however , someone else steals the jewels before they are able to get to them . \r\n",
      "writer mario van peebles delivers a clever script with several unexpected plot twists , but director mario van peebles undermines his own high points with haphazard camera work , editing and pacing . \r\n",
      "it felt as though the film should have been wrapping up at the hour mark , but alas there was still 35 more minutes to go . \r\n",
      "daniel baldwin ( i can't believe i'm about to type this ) gives the best performance in the film , outshining the other talented members of the cast . \r\n",
      "[r] \r\n"
     ]
    }
   ],
   "source": [
    "! cat /home/markbaum/nltk_data/corpora/movie_reviews/neg/cv435_24355.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docs        : 2000\n",
      "docs[13][1] : neg\n",
      "docs[13][0] : 1144 ['a', 'all', 'fate', 'like', 'intersperesed', 'the', '.', 'who', 'like', 'characters', '.', 'looks', 'us', 'obviously', 'give']\n"
     ]
    }
   ],
   "source": [
    "docs = [(list(movie_reviews.words(fid)), cat) \n",
    "        for cat in movie_reviews.categories()   # ['neg', 'pos']\n",
    "        for fid in movie_reviews.fileids(cat)]  # 'neg/cv000_29416.txt', ....\n",
    "\n",
    "print('docs        :', len(docs))\n",
    "print('docs[13][1] :', docs[13][1])\n",
    "print('docs[13][0] :', len(docs[13][0]), docs[13][0][::80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영화리뷰 token의 총 합 : 39768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['plot', 'seymour', 'strives']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 긍/부정 분류된 textdml token을 뒤섞어서 1개로 합친다\n",
    "import nltk, random\n",
    "random.shuffle(docs)\n",
    "all_tokens = nltk.FreqDist(x.lower()    for  x  in  movie_reviews.words())\n",
    "print('영화리뷰 token의 총 합 :', len(all_tokens.keys()))\n",
    "\n",
    "# 39,768개 중  2,000개  Train 데이터 추출\n",
    "token_features = list(all_tokens.keys())[:2000]\n",
    "token_features[::800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 중간결과\n",
    "# doc            : neg, pos target을 표시한, text의 token list를 수집\n",
    "# token_features : all_tokens.keys())[:2000]의    token list를 수집"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02 all.tokens [:2000]표본을 추출하여 학습모델을 생성\n",
    "'pos/cv957_8737.txt' 리뷰가 긍정/ 부정 여부를 \n",
    "\n",
    "<strong>나이브 베이즈 분류기</strong>를 활용하여 판단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'token_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-de1882e74c1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdoc_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovie_reviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtoken_file\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'token_file' is not defined"
     ]
    }
   ],
   "source": [
    "# 리뷰 데이터의 Token이 표본DB 포함여부 판단\n",
    "def doc_features(docs):\n",
    "    doc_words = set(docs)  # 리뷰 txt의 token을 집합으로 추출\n",
    "    features = {}\n",
    "    \n",
    "    # all_tokens[:2000] 표본에 대해, 리뷰 token의 포함여부를 판단 \n",
    "    for i, word in enumerate(token_features):\n",
    "        features['contains(%s)' % word] = (word in doc_words)\n",
    "        #if i == 5 : break\n",
    "    return features\n",
    "\n",
    "doc_features(['test','fine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contains(plot)': False,\n",
       " 'contains(:)': False,\n",
       " 'contains(two)': False,\n",
       " 'contains(teen)': False,\n",
       " 'contains(couples)': False,\n",
       " 'contains(go)': False,\n",
       " 'contains(to)': False,\n",
       " 'contains(a)': False,\n",
       " 'contains(church)': False,\n",
       " 'contains(party)': False,\n",
       " 'contains(,)': False,\n",
       " 'contains(drink)': False,\n",
       " 'contains(and)': False,\n",
       " 'contains(then)': False,\n",
       " 'contains(drive)': False,\n",
       " 'contains(.)': False,\n",
       " 'contains(they)': False,\n",
       " 'contains(get)': False,\n",
       " 'contains(into)': False,\n",
       " 'contains(an)': False,\n",
       " 'contains(accident)': False,\n",
       " 'contains(one)': False,\n",
       " 'contains(of)': False,\n",
       " 'contains(the)': False,\n",
       " 'contains(guys)': False,\n",
       " 'contains(dies)': False,\n",
       " 'contains(but)': False,\n",
       " 'contains(his)': False,\n",
       " 'contains(girlfriend)': False,\n",
       " 'contains(continues)': False,\n",
       " 'contains(see)': False,\n",
       " 'contains(him)': False,\n",
       " 'contains(in)': False,\n",
       " 'contains(her)': False,\n",
       " 'contains(life)': False,\n",
       " 'contains(has)': False,\n",
       " 'contains(nightmares)': False,\n",
       " 'contains(what)': False,\n",
       " \"contains(')\": False,\n",
       " 'contains(s)': False,\n",
       " 'contains(deal)': False,\n",
       " 'contains(?)': False,\n",
       " 'contains(watch)': False,\n",
       " 'contains(movie)': False,\n",
       " 'contains(\")': False,\n",
       " 'contains(sorta)': False,\n",
       " 'contains(find)': False,\n",
       " 'contains(out)': False,\n",
       " 'contains(critique)': False,\n",
       " 'contains(mind)': False,\n",
       " 'contains(-)': False,\n",
       " 'contains(fuck)': False,\n",
       " 'contains(for)': False,\n",
       " 'contains(generation)': False,\n",
       " 'contains(that)': False,\n",
       " 'contains(touches)': False,\n",
       " 'contains(on)': False,\n",
       " 'contains(very)': False,\n",
       " 'contains(cool)': False,\n",
       " 'contains(idea)': False,\n",
       " 'contains(presents)': False,\n",
       " 'contains(it)': False,\n",
       " 'contains(bad)': False,\n",
       " 'contains(package)': False,\n",
       " 'contains(which)': False,\n",
       " 'contains(is)': False,\n",
       " 'contains(makes)': False,\n",
       " 'contains(this)': False,\n",
       " 'contains(review)': False,\n",
       " 'contains(even)': False,\n",
       " 'contains(harder)': False,\n",
       " 'contains(write)': False,\n",
       " 'contains(since)': False,\n",
       " 'contains(i)': False,\n",
       " 'contains(generally)': False,\n",
       " 'contains(applaud)': False,\n",
       " 'contains(films)': False,\n",
       " 'contains(attempt)': False,\n",
       " 'contains(break)': False,\n",
       " 'contains(mold)': False,\n",
       " 'contains(mess)': False,\n",
       " 'contains(with)': False,\n",
       " 'contains(your)': False,\n",
       " 'contains(head)': False,\n",
       " 'contains(such)': False,\n",
       " 'contains(()': False,\n",
       " 'contains(lost)': False,\n",
       " 'contains(highway)': False,\n",
       " 'contains(&)': False,\n",
       " 'contains(memento)': False,\n",
       " 'contains())': False,\n",
       " 'contains(there)': False,\n",
       " 'contains(are)': False,\n",
       " 'contains(good)': False,\n",
       " 'contains(ways)': False,\n",
       " 'contains(making)': False,\n",
       " 'contains(all)': False,\n",
       " 'contains(types)': False,\n",
       " 'contains(these)': False,\n",
       " 'contains(folks)': False,\n",
       " 'contains(just)': False,\n",
       " 'contains(didn)': False,\n",
       " 'contains(t)': False,\n",
       " 'contains(snag)': False,\n",
       " 'contains(correctly)': False,\n",
       " 'contains(seem)': False,\n",
       " 'contains(have)': False,\n",
       " 'contains(taken)': False,\n",
       " 'contains(pretty)': False,\n",
       " 'contains(neat)': False,\n",
       " 'contains(concept)': False,\n",
       " 'contains(executed)': False,\n",
       " 'contains(terribly)': False,\n",
       " 'contains(so)': False,\n",
       " 'contains(problems)': False,\n",
       " 'contains(well)': False,\n",
       " 'contains(its)': False,\n",
       " 'contains(main)': False,\n",
       " 'contains(problem)': False,\n",
       " 'contains(simply)': False,\n",
       " 'contains(too)': False,\n",
       " 'contains(jumbled)': False,\n",
       " 'contains(starts)': False,\n",
       " 'contains(off)': False,\n",
       " 'contains(normal)': False,\n",
       " 'contains(downshifts)': False,\n",
       " 'contains(fantasy)': False,\n",
       " 'contains(world)': False,\n",
       " 'contains(you)': False,\n",
       " 'contains(as)': False,\n",
       " 'contains(audience)': False,\n",
       " 'contains(member)': False,\n",
       " 'contains(no)': False,\n",
       " 'contains(going)': False,\n",
       " 'contains(dreams)': False,\n",
       " 'contains(characters)': False,\n",
       " 'contains(coming)': False,\n",
       " 'contains(back)': False,\n",
       " 'contains(from)': False,\n",
       " 'contains(dead)': False,\n",
       " 'contains(others)': False,\n",
       " 'contains(who)': False,\n",
       " 'contains(look)': False,\n",
       " 'contains(like)': False,\n",
       " 'contains(strange)': False,\n",
       " 'contains(apparitions)': False,\n",
       " 'contains(disappearances)': False,\n",
       " 'contains(looooot)': False,\n",
       " 'contains(chase)': False,\n",
       " 'contains(scenes)': False,\n",
       " 'contains(tons)': False,\n",
       " 'contains(weird)': False,\n",
       " 'contains(things)': False,\n",
       " 'contains(happen)': False,\n",
       " 'contains(most)': False,\n",
       " 'contains(not)': False,\n",
       " 'contains(explained)': False,\n",
       " 'contains(now)': False,\n",
       " 'contains(personally)': False,\n",
       " 'contains(don)': False,\n",
       " 'contains(trying)': False,\n",
       " 'contains(unravel)': False,\n",
       " 'contains(film)': False,\n",
       " 'contains(every)': False,\n",
       " 'contains(when)': False,\n",
       " 'contains(does)': False,\n",
       " 'contains(give)': False,\n",
       " 'contains(me)': False,\n",
       " 'contains(same)': False,\n",
       " 'contains(clue)': False,\n",
       " 'contains(over)': False,\n",
       " 'contains(again)': False,\n",
       " 'contains(kind)': False,\n",
       " 'contains(fed)': False,\n",
       " 'contains(up)': False,\n",
       " 'contains(after)': False,\n",
       " 'contains(while)': False,\n",
       " 'contains(biggest)': False,\n",
       " 'contains(obviously)': False,\n",
       " 'contains(got)': False,\n",
       " 'contains(big)': False,\n",
       " 'contains(secret)': False,\n",
       " 'contains(hide)': False,\n",
       " 'contains(seems)': False,\n",
       " 'contains(want)': False,\n",
       " 'contains(completely)': False,\n",
       " 'contains(until)': False,\n",
       " 'contains(final)': False,\n",
       " 'contains(five)': False,\n",
       " 'contains(minutes)': False,\n",
       " 'contains(do)': False,\n",
       " 'contains(make)': False,\n",
       " 'contains(entertaining)': False,\n",
       " 'contains(thrilling)': False,\n",
       " 'contains(or)': False,\n",
       " 'contains(engaging)': False,\n",
       " 'contains(meantime)': False,\n",
       " 'contains(really)': False,\n",
       " 'contains(sad)': False,\n",
       " 'contains(part)': False,\n",
       " 'contains(arrow)': False,\n",
       " 'contains(both)': False,\n",
       " 'contains(dig)': False,\n",
       " 'contains(flicks)': False,\n",
       " 'contains(we)': False,\n",
       " 'contains(actually)': False,\n",
       " 'contains(figured)': False,\n",
       " 'contains(by)': False,\n",
       " 'contains(half)': False,\n",
       " 'contains(way)': False,\n",
       " 'contains(point)': False,\n",
       " 'contains(strangeness)': False,\n",
       " 'contains(did)': False,\n",
       " 'contains(start)': False,\n",
       " 'contains(little)': False,\n",
       " 'contains(bit)': False,\n",
       " 'contains(sense)': False,\n",
       " 'contains(still)': False,\n",
       " 'contains(more)': False,\n",
       " 'contains(guess)': False,\n",
       " 'contains(bottom)': False,\n",
       " 'contains(line)': False,\n",
       " 'contains(movies)': False,\n",
       " 'contains(should)': False,\n",
       " 'contains(always)': False,\n",
       " 'contains(sure)': False,\n",
       " 'contains(before)': False,\n",
       " 'contains(given)': False,\n",
       " 'contains(password)': False,\n",
       " 'contains(enter)': False,\n",
       " 'contains(understanding)': False,\n",
       " 'contains(mean)': False,\n",
       " 'contains(showing)': False,\n",
       " 'contains(melissa)': False,\n",
       " 'contains(sagemiller)': False,\n",
       " 'contains(running)': False,\n",
       " 'contains(away)': False,\n",
       " 'contains(visions)': False,\n",
       " 'contains(about)': False,\n",
       " 'contains(20)': False,\n",
       " 'contains(throughout)': False,\n",
       " 'contains(plain)': False,\n",
       " 'contains(lazy)': False,\n",
       " 'contains(!)': False,\n",
       " 'contains(okay)': False,\n",
       " 'contains(people)': False,\n",
       " 'contains(chasing)': False,\n",
       " 'contains(know)': False,\n",
       " 'contains(need)': False,\n",
       " 'contains(how)': False,\n",
       " 'contains(giving)': False,\n",
       " 'contains(us)': False,\n",
       " 'contains(different)': False,\n",
       " 'contains(offering)': False,\n",
       " 'contains(further)': False,\n",
       " 'contains(insight)': False,\n",
       " 'contains(down)': False,\n",
       " 'contains(apparently)': False,\n",
       " 'contains(studio)': False,\n",
       " 'contains(took)': False,\n",
       " 'contains(director)': False,\n",
       " 'contains(chopped)': False,\n",
       " 'contains(themselves)': False,\n",
       " 'contains(shows)': False,\n",
       " 'contains(might)': False,\n",
       " 'contains(ve)': False,\n",
       " 'contains(been)': False,\n",
       " 'contains(decent)': False,\n",
       " 'contains(here)': False,\n",
       " 'contains(somewhere)': False,\n",
       " 'contains(suits)': False,\n",
       " 'contains(decided)': False,\n",
       " 'contains(turning)': False,\n",
       " 'contains(music)': False,\n",
       " 'contains(video)': False,\n",
       " 'contains(edge)': False,\n",
       " 'contains(would)': False,\n",
       " 'contains(actors)': False,\n",
       " 'contains(although)': False,\n",
       " 'contains(wes)': False,\n",
       " 'contains(bentley)': False,\n",
       " 'contains(seemed)': False,\n",
       " 'contains(be)': False,\n",
       " 'contains(playing)': False,\n",
       " 'contains(exact)': False,\n",
       " 'contains(character)': False,\n",
       " 'contains(he)': False,\n",
       " 'contains(american)': False,\n",
       " 'contains(beauty)': False,\n",
       " 'contains(only)': False,\n",
       " 'contains(new)': False,\n",
       " 'contains(neighborhood)': False,\n",
       " 'contains(my)': False,\n",
       " 'contains(kudos)': False,\n",
       " 'contains(holds)': False,\n",
       " 'contains(own)': False,\n",
       " 'contains(entire)': False,\n",
       " 'contains(feeling)': False,\n",
       " 'contains(unraveling)': False,\n",
       " 'contains(overall)': False,\n",
       " 'contains(doesn)': False,\n",
       " 'contains(stick)': False,\n",
       " 'contains(because)': False,\n",
       " 'contains(entertain)': False,\n",
       " 'contains(confusing)': False,\n",
       " 'contains(rarely)': False,\n",
       " 'contains(excites)': False,\n",
       " 'contains(feels)': False,\n",
       " 'contains(redundant)': False,\n",
       " 'contains(runtime)': False,\n",
       " 'contains(despite)': False,\n",
       " 'contains(ending)': False,\n",
       " 'contains(explanation)': False,\n",
       " 'contains(craziness)': False,\n",
       " 'contains(came)': False,\n",
       " 'contains(oh)': False,\n",
       " 'contains(horror)': False,\n",
       " 'contains(slasher)': False,\n",
       " 'contains(flick)': False,\n",
       " 'contains(packaged)': False,\n",
       " 'contains(someone)': False,\n",
       " 'contains(assuming)': False,\n",
       " 'contains(genre)': False,\n",
       " 'contains(hot)': False,\n",
       " 'contains(kids)': False,\n",
       " 'contains(also)': False,\n",
       " 'contains(wrapped)': False,\n",
       " 'contains(production)': False,\n",
       " 'contains(years)': False,\n",
       " 'contains(ago)': False,\n",
       " 'contains(sitting)': False,\n",
       " 'contains(shelves)': False,\n",
       " 'contains(ever)': False,\n",
       " 'contains(whatever)': False,\n",
       " 'contains(skip)': False,\n",
       " 'contains(where)': False,\n",
       " 'contains(joblo)': False,\n",
       " 'contains(nightmare)': False,\n",
       " 'contains(elm)': False,\n",
       " 'contains(street)': False,\n",
       " 'contains(3)': False,\n",
       " 'contains(7)': False,\n",
       " 'contains(/)': False,\n",
       " 'contains(10)': False,\n",
       " 'contains(blair)': False,\n",
       " 'contains(witch)': False,\n",
       " 'contains(2)': False,\n",
       " 'contains(crow)': False,\n",
       " 'contains(9)': False,\n",
       " 'contains(salvation)': False,\n",
       " 'contains(4)': False,\n",
       " 'contains(stir)': False,\n",
       " 'contains(echoes)': False,\n",
       " 'contains(8)': False,\n",
       " 'contains(happy)': False,\n",
       " 'contains(bastard)': False,\n",
       " 'contains(quick)': False,\n",
       " 'contains(damn)': False,\n",
       " 'contains(y2k)': False,\n",
       " 'contains(bug)': False,\n",
       " 'contains(starring)': False,\n",
       " 'contains(jamie)': False,\n",
       " 'contains(lee)': False,\n",
       " 'contains(curtis)': False,\n",
       " 'contains(another)': False,\n",
       " 'contains(baldwin)': False,\n",
       " 'contains(brother)': False,\n",
       " 'contains(william)': False,\n",
       " 'contains(time)': False,\n",
       " 'contains(story)': False,\n",
       " 'contains(regarding)': False,\n",
       " 'contains(crew)': False,\n",
       " 'contains(tugboat)': False,\n",
       " 'contains(comes)': False,\n",
       " 'contains(across)': False,\n",
       " 'contains(deserted)': False,\n",
       " 'contains(russian)': False,\n",
       " 'contains(tech)': False,\n",
       " 'contains(ship)': False,\n",
       " 'contains(kick)': False,\n",
       " 'contains(power)': False,\n",
       " 'contains(within)': False,\n",
       " 'contains(gore)': False,\n",
       " 'contains(bringing)': False,\n",
       " 'contains(few)': False,\n",
       " 'contains(action)': False,\n",
       " 'contains(sequences)': False,\n",
       " 'contains(virus)': False,\n",
       " 'contains(empty)': False,\n",
       " 'contains(flash)': False,\n",
       " 'contains(substance)': False,\n",
       " 'contains(why)': False,\n",
       " 'contains(was)': False,\n",
       " 'contains(middle)': False,\n",
       " 'contains(nowhere)': False,\n",
       " 'contains(origin)': False,\n",
       " 'contains(pink)': False,\n",
       " 'contains(flashy)': False,\n",
       " 'contains(thing)': False,\n",
       " 'contains(hit)': False,\n",
       " 'contains(mir)': False,\n",
       " 'contains(course)': False,\n",
       " 'contains(donald)': False,\n",
       " 'contains(sutherland)': False,\n",
       " 'contains(stumbling)': False,\n",
       " 'contains(around)': False,\n",
       " 'contains(drunkenly)': False,\n",
       " 'contains(hey)': False,\n",
       " 'contains(let)': False,\n",
       " 'contains(some)': False,\n",
       " 'contains(robots)': False,\n",
       " 'contains(acting)': False,\n",
       " 'contains(below)': False,\n",
       " 'contains(average)': False,\n",
       " 'contains(likes)': False,\n",
       " 'contains(re)': False,\n",
       " 'contains(likely)': False,\n",
       " 'contains(work)': False,\n",
       " 'contains(halloween)': False,\n",
       " 'contains(h20)': False,\n",
       " 'contains(wasted)': False,\n",
       " 'contains(real)': False,\n",
       " 'contains(star)': False,\n",
       " 'contains(stan)': False,\n",
       " 'contains(winston)': False,\n",
       " 'contains(robot)': False,\n",
       " 'contains(design)': False,\n",
       " 'contains(schnazzy)': False,\n",
       " 'contains(cgi)': False,\n",
       " 'contains(occasional)': False,\n",
       " 'contains(shot)': False,\n",
       " 'contains(picking)': False,\n",
       " 'contains(brain)': False,\n",
       " 'contains(if)': False,\n",
       " 'contains(body)': False,\n",
       " 'contains(parts)': False,\n",
       " 'contains(turn)': False,\n",
       " 'contains(otherwise)': False,\n",
       " 'contains(much)': False,\n",
       " 'contains(sunken)': False,\n",
       " 'contains(jaded)': False,\n",
       " 'contains(viewer)': False,\n",
       " 'contains(thankful)': False,\n",
       " 'contains(invention)': False,\n",
       " 'contains(timex)': False,\n",
       " 'contains(indiglo)': False,\n",
       " 'contains(based)': False,\n",
       " 'contains(late)': False,\n",
       " 'contains(1960)': False,\n",
       " 'contains(television)': False,\n",
       " 'contains(show)': False,\n",
       " 'contains(name)': False,\n",
       " 'contains(mod)': False,\n",
       " 'contains(squad)': False,\n",
       " 'contains(tells)': False,\n",
       " 'contains(tale)': False,\n",
       " 'contains(three)': False,\n",
       " 'contains(reformed)': False,\n",
       " 'contains(criminals)': False,\n",
       " 'contains(under)': False,\n",
       " 'contains(employ)': False,\n",
       " 'contains(police)': False,\n",
       " 'contains(undercover)': False,\n",
       " 'contains(however)': False,\n",
       " 'contains(wrong)': False,\n",
       " 'contains(evidence)': False,\n",
       " 'contains(gets)': False,\n",
       " 'contains(stolen)': False,\n",
       " 'contains(immediately)': False,\n",
       " 'contains(suspicion)': False,\n",
       " 'contains(ads)': False,\n",
       " 'contains(cuts)': False,\n",
       " 'contains(claire)': False,\n",
       " 'contains(dane)': False,\n",
       " 'contains(nice)': False,\n",
       " 'contains(hair)': False,\n",
       " 'contains(cute)': False,\n",
       " 'contains(outfits)': False,\n",
       " 'contains(car)': False,\n",
       " 'contains(chases)': False,\n",
       " 'contains(stuff)': False,\n",
       " 'contains(blowing)': False,\n",
       " 'contains(sounds)': False,\n",
       " 'contains(first)': False,\n",
       " 'contains(fifteen)': False,\n",
       " 'contains(quickly)': False,\n",
       " 'contains(becomes)': False,\n",
       " 'contains(apparent)': False,\n",
       " 'contains(certainly)': False,\n",
       " 'contains(slick)': False,\n",
       " 'contains(looking)': False,\n",
       " 'contains(complete)': False,\n",
       " 'contains(costumes)': False,\n",
       " 'contains(isn)': False,\n",
       " 'contains(enough)': False,\n",
       " 'contains(best)': False,\n",
       " 'contains(described)': False,\n",
       " 'contains(cross)': False,\n",
       " 'contains(between)': False,\n",
       " 'contains(hour)': False,\n",
       " 'contains(long)': False,\n",
       " 'contains(cop)': False,\n",
       " 'contains(stretched)': False,\n",
       " 'contains(span)': False,\n",
       " 'contains(single)': False,\n",
       " 'contains(clich)': False,\n",
       " 'contains(matter)': False,\n",
       " 'contains(elements)': False,\n",
       " 'contains(recycled)': False,\n",
       " 'contains(everything)': False,\n",
       " 'contains(already)': False,\n",
       " 'contains(seen)': False,\n",
       " 'contains(nothing)': False,\n",
       " 'contains(spectacular)': False,\n",
       " 'contains(sometimes)': False,\n",
       " 'contains(bordering)': False,\n",
       " 'contains(wooden)': False,\n",
       " 'contains(danes)': False,\n",
       " 'contains(omar)': False,\n",
       " 'contains(epps)': False,\n",
       " 'contains(deliver)': False,\n",
       " 'contains(their)': False,\n",
       " 'contains(lines)': False,\n",
       " 'contains(bored)': False,\n",
       " 'contains(transfers)': False,\n",
       " 'contains(onto)': False,\n",
       " 'contains(escape)': False,\n",
       " 'contains(relatively)': False,\n",
       " 'contains(unscathed)': False,\n",
       " 'contains(giovanni)': False,\n",
       " 'contains(ribisi)': False,\n",
       " 'contains(plays)': False,\n",
       " 'contains(resident)': False,\n",
       " 'contains(crazy)': False,\n",
       " 'contains(man)': False,\n",
       " 'contains(ultimately)': False,\n",
       " 'contains(being)': False,\n",
       " 'contains(worth)': False,\n",
       " 'contains(watching)': False,\n",
       " 'contains(unfortunately)': False,\n",
       " 'contains(save)': False,\n",
       " 'contains(convoluted)': False,\n",
       " 'contains(apart)': False,\n",
       " 'contains(occupying)': False,\n",
       " 'contains(screen)': False,\n",
       " 'contains(young)': False,\n",
       " 'contains(cast)': False,\n",
       " 'contains(clothes)': False,\n",
       " 'contains(hip)': False,\n",
       " 'contains(soundtrack)': False,\n",
       " 'contains(appears)': False,\n",
       " 'contains(geared)': False,\n",
       " 'contains(towards)': False,\n",
       " 'contains(teenage)': False,\n",
       " 'contains(mindset)': False,\n",
       " 'contains(r)': False,\n",
       " 'contains(rating)': False,\n",
       " 'contains(content)': False,\n",
       " 'contains(justify)': False,\n",
       " 'contains(juvenile)': False,\n",
       " 'contains(older)': False,\n",
       " 'contains(information)': False,\n",
       " 'contains(literally)': False,\n",
       " 'contains(spoon)': False,\n",
       " 'contains(hard)': False,\n",
       " 'contains(instead)': False,\n",
       " 'contains(telling)': False,\n",
       " 'contains(dialogue)': False,\n",
       " 'contains(poorly)': False,\n",
       " 'contains(written)': False,\n",
       " 'contains(extremely)': False,\n",
       " 'contains(predictable)': False,\n",
       " 'contains(progresses)': False,\n",
       " 'contains(won)': False,\n",
       " 'contains(care)': False,\n",
       " 'contains(heroes)': False,\n",
       " 'contains(any)': False,\n",
       " 'contains(jeopardy)': False,\n",
       " 'contains(ll)': False,\n",
       " 'contains(aren)': False,\n",
       " 'contains(basing)': False,\n",
       " 'contains(nobody)': False,\n",
       " 'contains(remembers)': False,\n",
       " 'contains(questionable)': False,\n",
       " 'contains(wisdom)': False,\n",
       " 'contains(especially)': False,\n",
       " 'contains(considers)': False,\n",
       " 'contains(target)': False,\n",
       " 'contains(fact)': False,\n",
       " 'contains(number)': False,\n",
       " 'contains(memorable)': False,\n",
       " 'contains(can)': False,\n",
       " 'contains(counted)': False,\n",
       " 'contains(hand)': False,\n",
       " 'contains(missing)': False,\n",
       " 'contains(finger)': False,\n",
       " 'contains(times)': False,\n",
       " 'contains(checked)': False,\n",
       " 'contains(six)': False,\n",
       " 'contains(clear)': False,\n",
       " 'contains(indication)': False,\n",
       " 'contains(them)': False,\n",
       " 'contains(than)': False,\n",
       " 'contains(cash)': False,\n",
       " 'contains(spending)': False,\n",
       " 'contains(dollar)': False,\n",
       " 'contains(judging)': False,\n",
       " 'contains(rash)': False,\n",
       " 'contains(awful)': False,\n",
       " 'contains(seeing)': False,\n",
       " 'contains(avoid)': False,\n",
       " 'contains(at)': False,\n",
       " 'contains(costs)': False,\n",
       " 'contains(quest)': False,\n",
       " 'contains(camelot)': False,\n",
       " 'contains(warner)': False,\n",
       " 'contains(bros)': False,\n",
       " 'contains(feature)': False,\n",
       " 'contains(length)': False,\n",
       " 'contains(fully)': False,\n",
       " 'contains(animated)': False,\n",
       " 'contains(steal)': False,\n",
       " 'contains(clout)': False,\n",
       " 'contains(disney)': False,\n",
       " 'contains(cartoon)': False,\n",
       " 'contains(empire)': False,\n",
       " 'contains(mouse)': False,\n",
       " 'contains(reason)': False,\n",
       " 'contains(worried)': False,\n",
       " 'contains(other)': False,\n",
       " 'contains(recent)': False,\n",
       " 'contains(challenger)': False,\n",
       " 'contains(throne)': False,\n",
       " 'contains(last)': False,\n",
       " 'contains(fall)': False,\n",
       " 'contains(promising)': False,\n",
       " 'contains(flawed)': False,\n",
       " 'contains(20th)': False,\n",
       " 'contains(century)': False,\n",
       " 'contains(fox)': False,\n",
       " 'contains(anastasia)': False,\n",
       " 'contains(hercules)': False,\n",
       " 'contains(lively)': False,\n",
       " 'contains(colorful)': False,\n",
       " 'contains(palate)': False,\n",
       " 'contains(had)': False,\n",
       " 'contains(beat)': False,\n",
       " 'contains(hands)': False,\n",
       " 'contains(crown)': False,\n",
       " 'contains(1997)': False,\n",
       " 'contains(piece)': False,\n",
       " 'contains(animation)': False,\n",
       " 'contains(year)': False,\n",
       " 'contains(contest)': False,\n",
       " 'contains(arrival)': False,\n",
       " 'contains(magic)': False,\n",
       " 'contains(kingdom)': False,\n",
       " 'contains(mediocre)': False,\n",
       " 'contains(--)': False,\n",
       " 'contains(d)': False,\n",
       " 'contains(pocahontas)': False,\n",
       " 'contains(those)': False,\n",
       " 'contains(keeping)': False,\n",
       " 'contains(score)': False,\n",
       " 'contains(nearly)': False,\n",
       " 'contains(dull)': False,\n",
       " 'contains(revolves)': False,\n",
       " 'contains(adventures)': False,\n",
       " 'contains(free)': False,\n",
       " 'contains(spirited)': False,\n",
       " 'contains(kayley)': False,\n",
       " 'contains(voiced)': False,\n",
       " 'contains(jessalyn)': False,\n",
       " 'contains(gilsig)': False,\n",
       " 'contains(early)': False,\n",
       " 'contains(daughter)': False,\n",
       " 'contains(belated)': False,\n",
       " 'contains(knight)': False,\n",
       " 'contains(king)': False,\n",
       " 'contains(arthur)': False,\n",
       " 'contains(round)': False,\n",
       " 'contains(table)': False,\n",
       " 'contains(dream)': False,\n",
       " 'contains(follow)': False,\n",
       " 'contains(father)': False,\n",
       " 'contains(footsteps)': False,\n",
       " 'contains(she)': False,\n",
       " 'contains(chance)': False,\n",
       " 'contains(evil)': False,\n",
       " 'contains(warlord)': False,\n",
       " 'contains(ruber)': False,\n",
       " 'contains(gary)': False,\n",
       " 'contains(oldman)': False,\n",
       " 'contains(ex)': False,\n",
       " 'contains(gone)': False,\n",
       " 'contains(steals)': False,\n",
       " 'contains(magical)': False,\n",
       " 'contains(sword)': False,\n",
       " 'contains(excalibur)': False,\n",
       " 'contains(accidentally)': False,\n",
       " 'contains(loses)': False,\n",
       " 'contains(dangerous)': False,\n",
       " 'contains(booby)': False,\n",
       " 'contains(trapped)': False,\n",
       " 'contains(forest)': False,\n",
       " 'contains(help)': False,\n",
       " 'contains(hunky)': False,\n",
       " 'contains(blind)': False,\n",
       " 'contains(timberland)': False,\n",
       " 'contains(dweller)': False,\n",
       " 'contains(garrett)': False,\n",
       " 'contains(carey)': False,\n",
       " 'contains(elwes)': False,\n",
       " 'contains(headed)': False,\n",
       " 'contains(dragon)': False,\n",
       " 'contains(eric)': False,\n",
       " 'contains(idle)': False,\n",
       " 'contains(rickles)': False,\n",
       " 'contains(arguing)': False,\n",
       " 'contains(itself)': False,\n",
       " 'contains(able)': False,\n",
       " 'contains(medieval)': False,\n",
       " 'contains(sexist)': False,\n",
       " 'contains(prove)': False,\n",
       " 'contains(fighter)': False,\n",
       " 'contains(side)': False,\n",
       " 'contains(pure)': False,\n",
       " 'contains(showmanship)': False,\n",
       " 'contains(essential)': False,\n",
       " 'contains(element)': False,\n",
       " 'contains(expected)': False,\n",
       " 'contains(climb)': False,\n",
       " 'contains(high)': False,\n",
       " 'contains(ranks)': False,\n",
       " 'contains(differentiates)': False,\n",
       " 'contains(something)': False,\n",
       " 'contains(saturday)': False,\n",
       " 'contains(morning)': False,\n",
       " 'contains(subpar)': False,\n",
       " 'contains(instantly)': False,\n",
       " 'contains(forgettable)': False,\n",
       " 'contains(songs)': False,\n",
       " 'contains(integrated)': False,\n",
       " 'contains(computerized)': False,\n",
       " 'contains(footage)': False,\n",
       " 'contains(compare)': False,\n",
       " 'contains(run)': False,\n",
       " 'contains(angry)': False,\n",
       " 'contains(ogre)': False,\n",
       " 'contains(herc)': False,\n",
       " 'contains(battle)': False,\n",
       " 'contains(hydra)': False,\n",
       " 'contains(rest)': False,\n",
       " 'contains(case)': False,\n",
       " 'contains(stink)': False,\n",
       " 'contains(none)': False,\n",
       " 'contains(remotely)': False,\n",
       " 'contains(interesting)': False,\n",
       " 'contains(race)': False,\n",
       " 'contains(bland)': False,\n",
       " 'contains(end)': False,\n",
       " 'contains(tie)': False,\n",
       " 'contains(win)': False,\n",
       " 'contains(comedy)': False,\n",
       " 'contains(shtick)': False,\n",
       " 'contains(awfully)': False,\n",
       " 'contains(cloying)': False,\n",
       " 'contains(least)': False,\n",
       " 'contains(signs)': False,\n",
       " 'contains(pulse)': False,\n",
       " 'contains(fans)': False,\n",
       " \"contains(-')\": False,\n",
       " 'contains(90s)': False,\n",
       " 'contains(tgif)': False,\n",
       " 'contains(will)': False,\n",
       " 'contains(thrilled)': False,\n",
       " 'contains(jaleel)': False,\n",
       " 'contains(urkel)': False,\n",
       " 'contains(white)': False,\n",
       " 'contains(bronson)': False,\n",
       " 'contains(balki)': False,\n",
       " 'contains(pinchot)': False,\n",
       " 'contains(sharing)': False,\n",
       " 'contains(nicely)': False,\n",
       " 'contains(realized)': False,\n",
       " 'contains(though)': False,\n",
       " 'contains(m)': False,\n",
       " 'contains(loss)': False,\n",
       " 'contains(recall)': False,\n",
       " 'contains(specific)': False,\n",
       " 'contains(providing)': False,\n",
       " 'contains(voice)': False,\n",
       " 'contains(talent)': False,\n",
       " 'contains(enthusiastic)': False,\n",
       " 'contains(paired)': False,\n",
       " 'contains(singers)': False,\n",
       " 'contains(sound)': False,\n",
       " 'contains(musical)': False,\n",
       " 'contains(moments)': False,\n",
       " 'contains(jane)': False,\n",
       " 'contains(seymour)': False,\n",
       " 'contains(celine)': False,\n",
       " 'contains(dion)': False,\n",
       " 'contains(must)': False,\n",
       " 'contains(strain)': False,\n",
       " 'contains(through)': False,\n",
       " 'contains(aside)': False,\n",
       " 'contains(children)': False,\n",
       " 'contains(probably)': False,\n",
       " 'contains(adults)': False,\n",
       " 'contains(grievous)': False,\n",
       " 'contains(error)': False,\n",
       " 'contains(lack)': False,\n",
       " 'contains(personality)': False,\n",
       " 'contains(learn)': False,\n",
       " 'contains(goes)': False,\n",
       " 'contains(synopsis)': False,\n",
       " 'contains(mentally)': False,\n",
       " 'contains(unstable)': False,\n",
       " 'contains(undergoing)': False,\n",
       " 'contains(psychotherapy)': False,\n",
       " 'contains(saves)': False,\n",
       " 'contains(boy)': False,\n",
       " 'contains(potentially)': False,\n",
       " 'contains(fatal)': False,\n",
       " 'contains(falls)': False,\n",
       " 'contains(love)': False,\n",
       " 'contains(mother)': False,\n",
       " 'contains(fledgling)': False,\n",
       " 'contains(restauranteur)': False,\n",
       " 'contains(unsuccessfully)': False,\n",
       " 'contains(attempting)': False,\n",
       " 'contains(gain)': False,\n",
       " 'contains(woman)': False,\n",
       " 'contains(favor)': False,\n",
       " 'contains(takes)': False,\n",
       " 'contains(pictures)': False,\n",
       " 'contains(kills)': False,\n",
       " 'contains(comments)': False,\n",
       " 'contains(stalked)': False,\n",
       " 'contains(yet)': False,\n",
       " 'contains(seemingly)': False,\n",
       " 'contains(endless)': False,\n",
       " 'contains(string)': False,\n",
       " 'contains(spurned)': False,\n",
       " 'contains(psychos)': False,\n",
       " 'contains(getting)': False,\n",
       " 'contains(revenge)': False,\n",
       " 'contains(type)': False,\n",
       " 'contains(stable)': False,\n",
       " 'contains(category)': False,\n",
       " 'contains(1990s)': False,\n",
       " 'contains(industry)': False,\n",
       " 'contains(theatrical)': False,\n",
       " 'contains(direct)': False,\n",
       " 'contains(proliferation)': False,\n",
       " 'contains(may)': False,\n",
       " 'contains(due)': False,\n",
       " 'contains(typically)': False,\n",
       " 'contains(inexpensive)': False,\n",
       " 'contains(produce)': False,\n",
       " 'contains(special)': False,\n",
       " 'contains(effects)': False,\n",
       " 'contains(stars)': False,\n",
       " 'contains(serve)': False,\n",
       " 'contains(vehicles)': False,\n",
       " 'contains(nudity)': False,\n",
       " 'contains(allowing)': False,\n",
       " 'contains(frequent)': False,\n",
       " 'contains(night)': False,\n",
       " 'contains(cable)': False,\n",
       " 'contains(wavers)': False,\n",
       " 'contains(slightly)': False,\n",
       " 'contains(norm)': False,\n",
       " 'contains(respect)': False,\n",
       " 'contains(psycho)': False,\n",
       " 'contains(never)': False,\n",
       " 'contains(affair)': False,\n",
       " 'contains(;)': False,\n",
       " 'contains(contrary)': False,\n",
       " 'contains(rejected)': False,\n",
       " 'contains(rather)': False,\n",
       " 'contains(lover)': False,\n",
       " 'contains(wife)': False,\n",
       " 'contains(husband)': False,\n",
       " 'contains(entry)': False,\n",
       " 'contains(doomed)': False,\n",
       " 'contains(collect)': False,\n",
       " 'contains(dust)': False,\n",
       " 'contains(viewed)': False,\n",
       " 'contains(midnight)': False,\n",
       " 'contains(provide)': False,\n",
       " 'contains(suspense)': False,\n",
       " 'contains(sets)': False,\n",
       " 'contains(interspersed)': False,\n",
       " 'contains(opening)': False,\n",
       " 'contains(credits)': False,\n",
       " 'contains(instance)': False,\n",
       " 'contains(serious)': False,\n",
       " 'contains(sounding)': False,\n",
       " 'contains(narrator)': False,\n",
       " 'contains(spouts)': False,\n",
       " 'contains(statistics)': False,\n",
       " 'contains(stalkers)': False,\n",
       " 'contains(ponders)': False,\n",
       " 'contains(cause)': False,\n",
       " 'contains(stalk)': False,\n",
       " 'contains(implicitly)': False,\n",
       " 'contains(implied)': False,\n",
       " 'contains(men)': False,\n",
       " 'contains(shown)': False,\n",
       " 'contains(snapshot)': False,\n",
       " 'contains(actor)': False,\n",
       " 'contains(jay)': False,\n",
       " 'contains(underwood)': False,\n",
       " 'contains(states)': False,\n",
       " 'contains(daryl)': False,\n",
       " 'contains(gleason)': False,\n",
       " 'contains(stalker)': False,\n",
       " 'contains(brooke)': False,\n",
       " 'contains(daniels)': False,\n",
       " 'contains(meant)': False,\n",
       " 'contains(called)': False,\n",
       " 'contains(guesswork)': False,\n",
       " 'contains(required)': False,\n",
       " 'contains(proceeds)': False,\n",
       " 'contains(begins)': False,\n",
       " 'contains(obvious)': False,\n",
       " 'contains(sequence)': False,\n",
       " 'contains(contrived)': False,\n",
       " 'contains(quite)': False,\n",
       " 'contains(brings)': False,\n",
       " 'contains(victim)': False,\n",
       " 'contains(together)': False,\n",
       " 'contains(obsesses)': False,\n",
       " 'contains(follows)': False,\n",
       " 'contains(tries)': False,\n",
       " 'contains(woo)': False,\n",
       " 'contains(plans)': False,\n",
       " 'contains(become)': False,\n",
       " 'contains(desperate)': False,\n",
       " 'contains(elaborate)': False,\n",
       " 'contains(include)': False,\n",
       " 'contains(cliche)': False,\n",
       " 'contains(murdered)': False,\n",
       " 'contains(pet)': False,\n",
       " 'contains(require)': False,\n",
       " 'contains(found)': False,\n",
       " 'contains(exception)': False,\n",
       " 'contains(cat)': False,\n",
       " 'contains(shower)': False,\n",
       " 'contains(events)': False,\n",
       " 'contains(lead)': False,\n",
       " 'contains(inevitable)': False,\n",
       " 'contains(showdown)': False,\n",
       " 'contains(survives)': False,\n",
       " 'contains(invariably)': False,\n",
       " 'contains(conclusion)': False,\n",
       " 'contains(turkey)': False,\n",
       " 'contains(uniformly)': False,\n",
       " 'contains(adequate)': False,\n",
       " 'contains(anything)': False,\n",
       " 'contains(home)': False,\n",
       " 'contains(either)': False,\n",
       " 'contains(turns)': False,\n",
       " 'contains(toward)': False,\n",
       " 'contains(melodrama)': False,\n",
       " 'contains(overdoes)': False,\n",
       " 'contains(words)': False,\n",
       " 'contains(manages)': False,\n",
       " 'contains(creepy)': False,\n",
       " 'contains(pass)': False,\n",
       " 'contains(demands)': False,\n",
       " 'contains(maryam)': False,\n",
       " 'contains(abo)': False,\n",
       " 'contains(close)': False,\n",
       " 'contains(played)': False,\n",
       " 'contains(bond)': False,\n",
       " 'contains(chick)': False,\n",
       " 'contains(living)': False,\n",
       " 'contains(daylights)': False,\n",
       " 'contains(equally)': False,\n",
       " 'contains(title)': False,\n",
       " 'contains(ditzy)': False,\n",
       " 'contains(strong)': False,\n",
       " 'contains(independent)': False,\n",
       " 'contains(business)': False,\n",
       " 'contains(owner)': False,\n",
       " 'contains(needs)': False,\n",
       " 'contains(proceed)': False,\n",
       " 'contains(example)': False,\n",
       " 'contains(suspicions)': False,\n",
       " 'contains(ensure)': False,\n",
       " 'contains(use)': False,\n",
       " 'contains(excuse)': False,\n",
       " 'contains(decides)': False,\n",
       " 'contains(return)': False,\n",
       " 'contains(toolbox)': False,\n",
       " 'contains(left)': False,\n",
       " 'contains(place)': False,\n",
       " ...}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_features(['test','fine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.83\n",
      "Most Informative Features\n",
      "    contains(schumacher) = True              neg : pos    =     12.2 : 1.0\n",
      " contains(unimaginative) = True              neg : pos    =      8.2 : 1.0\n",
      "        contains(suvari) = True              neg : pos    =      6.9 : 1.0\n",
      "        contains(shoddy) = True              neg : pos    =      6.9 : 1.0\n",
      "     contains(atrocious) = True              neg : pos    =      6.9 : 1.0\n",
      "          contains(mena) = True              neg : pos    =      6.9 : 1.0\n",
      "      contains(medicine) = True              neg : pos    =      6.2 : 1.0\n",
      "        contains(turkey) = True              neg : pos    =      6.2 : 1.0\n",
      "       contains(jumbled) = True              neg : pos    =      6.2 : 1.0\n",
      "       contains(unravel) = True              pos : neg    =      5.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# docs (긍/부정리뷰의 token 모음) 데이터의 \n",
    "# Train(90%), Test(10%)로 나눈다 \n",
    "feature_sets = [(doc_features(d), c) for (d,c) in docs]\n",
    "train_sets, test_sets = feature_sets[100:], feature_sets[:100]\n",
    "\n",
    "# 나이브 베이즈 분류기로 정확도를 판단\n",
    "classifiers = nltk.NaiveBayesClassifier.train(train_sets)\n",
    "print('Accuracy :', nltk.classify.accuracy(classifiers, test_sets))\n",
    "classifiers.show_most_informative_features() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# unimaginative : 상상력이 없는\n",
    "# shoddy        : 겉만 번지르르한 싸구려,  재생 털실\n",
    "# atrocious     : 극악 무도한\n",
    "# 추출한 단어 자체가 선명해서, 결과도 분명하고 정확도도 높은 결과를 도출한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03 Train DB의 활용\n",
    "http://www.nltk.org/book/ch06.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#classifiers = nltk.NaiveBayesClassifier.train(train_sets)\n",
    "tokens = doc_features(movie_reviews.words('neg/cv264_14108.txt'))\n",
    "classifiers.classify(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = doc_features(movie_reviews.words('pos/cv000_29590.txt'))\n",
    "classifiers.classify(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = doc_features(movie_reviews.words('neg/cv569_26750.txt'))\n",
    "classifiers.classify(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classicied_review(filename, stopword = True):\n",
    "    with open(filename,'r',encoding='utf8') as f:\n",
    "        text = f.read()\n",
    "\n",
    "    from nltk import word_tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    if stopword == True:  # 불용어를 제거\n",
    "        from nltk.corpus import stopwords\n",
    "        tokens = [ word   for word in tokens   \n",
    "                          if word not in stopwords.words('english') ]\n",
    "\n",
    "    tokens = doc_features(tokens)\n",
    "    return classifiers.classify(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = './data/review_MadMax.txt'\n",
    "classicied_review(filename, stopword = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = './data/review_InterStella.txt'\n",
    "classicied_review(filename, stopword = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = './data/review_IT.txt'\n",
    "classicied_review(filename, stopword = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = './data/review_Gravity.txt'\n",
    "classicied_review(filename, stopword = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 결과\n",
    "# 정확도가 반복을 할 수록 오른다\n",
    "# train 데이터가 적은경우, 없는 단어에는 1을 출력\n",
    "# Smoothing은 'Add one smoothing' 을 활용한 결과로 추측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## 3 텍스트 전처리\n",
    "https://github.com/sujithvm/nlp-modules/blob/master/sentiment%20analysis/sentiment_analyzer.py\n",
    "\n",
    "1. 단어(word)\n",
    "2. 태그(tag) \n",
    "3. 표제어/주제(lemma)\n",
    "\n",
    "3개의 연산 결과를 추출한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# text --> 문장 --> token\n",
    "import nltk\n",
    "class Splitter(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.nltk_splitter = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "        self.nltk_tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "\n",
    "    def split(self, text):\n",
    "        sentences = self.nltk_splitter.tokenize(text)             # txt --> 문장\n",
    "        tokenized_sentences = [self.nltk_tokenizer.tokenize(sent) # 문장 --> token\n",
    "                               for sent in sentences]\n",
    "        return tokenized_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Why', 'are', 'you', 'looking', 'disappointed', '.'],\n",
       " ['We', 'will', 'go', 'to', 'restaurant', 'for', 'dinner', '.']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Txt --> 문장 --> token\n",
    "text = \"\"\"Why are you looking disappointed. \n",
    "We will go to restaurant for dinner.\"\"\"\n",
    "\n",
    "splitter = Splitter()\n",
    "splitted_sentences = splitter.split(text)\n",
    "splitted_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Why', ['WRB']),\n",
       "  ('are', ['VBP']),\n",
       "  ('you', ['PRP']),\n",
       "  ('looking', ['VBG']),\n",
       "  ('disappointed', ['VBN']),\n",
       "  ('.', ['.'])],\n",
       " [('We', ['PRP']),\n",
       "  ('will', ['MD']),\n",
       "  ('go', ['VB']),\n",
       "  ('to', ['TO']),\n",
       "  ('restaurant', ['VB']),\n",
       "  ('for', ['IN']),\n",
       "  ('dinner', ['NN']),\n",
       "  ('.', ['.'])]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3개 성분을 추출 후, 묶어서 정리\n",
    "# 단어(word/token), 표제어/주제(lemme), 태그(tag)\n",
    "class POSTagger(object):\n",
    "    def __init__(self): \n",
    "        pass\n",
    "    def pos_tag(self, sentences):\n",
    "        # 입력 sentence 에 token을 첨부한다\n",
    "        pos = [nltk.pos_tag(sentence)       for sentence in sentences]\n",
    "\n",
    "        # 첨부된 token을 tuple 형식으로 묶어서, list에 정리한다\n",
    "        pos = [[(word, [postag]) \n",
    "                for (word, postag) in sentence] \n",
    "                for sentence in pos]\n",
    "        return pos\n",
    "\n",
    "postagger = POSTagger()\n",
    "pos_tagged_sentences = postagger.pos_tag(splitted_sentences)\n",
    "pos_tagged_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 폴더내 파일들의 text에 대해 긍정/ 부정 tag 작업 시행\n",
    "# dictionary를 활용해서 tag를 생성\n",
    "import nltk, yaml, sys, re ,os \n",
    "class DictionaryTagger(object):\n",
    "\n",
    "    def __init__(self, dictionary_paths):\n",
    "        # 해당 폴더에 있는 text 파일 목록을 수집한다\n",
    "        files = [open(path, 'r')     for path in dictionary_paths]      \n",
    "        map(lambda x: x.close(),     files)\n",
    "\n",
    "        # http://egloos.zum.com/sweeper/v/3042272\n",
    "        # yaml : 텍스트 파일의 내용을 파싱한다 \n",
    "        dictionaries = [yaml.load(dict_file) \n",
    "                                     for dict_file in files]\n",
    "\n",
    "        self.dictionary ,self.max_key_size = {}, 0\n",
    "        for curr_dict in dictionaries:\n",
    "            for key in curr_dict:\n",
    "                # key 값으로 존재하는 경우, dict에 내용을 추가한다\n",
    "                if key in self.dictionary:             \n",
    "                    self.dictionary[key].extend(curr_dict[key])                    \n",
    "\n",
    "                # key 값이 없는경우, 새로운 dictionary 목록을 생성한다\n",
    "                else:\n",
    "                    self.dictionary[key] = curr_dict[key]                   \n",
    "                    self.max_key_size = max(self.max_key_size, len(key))\n",
    "\n",
    "    # 문장의 token의, tag를 list를 추출한다            \n",
    "    def tag(self, pos_tagged_sentences):\n",
    "        return [self.tag_sentence(sentence) \n",
    "                          for sentence in pos_tagged_sentences]\n",
    "\n",
    "    # token의 tag추출 함수 (주제도 함께 추출할지를 옵션으로 설정)\n",
    "    def tag_sentence(self, sentence, tag_with_lemmas = False):\n",
    "        tag_sentence = []\n",
    "        N = len(sentence)\n",
    "        if self.max_key_size == 0: \n",
    "            self.max_key_size = N\n",
    "        i = 0\n",
    "        while (i < N): # 문장 내 token의 갯수만큼 반복한다\n",
    "            j = min(i + self.max_key_size, N)\n",
    "            \n",
    "            tagged = False\n",
    "            while (j > i):\n",
    "                expression_form  = ' '.join([word[0]   for word in sentence[i:j]]).lower()\n",
    "                expression_lemma = ' '.join([word[1]   for word in sentence[i:j]]).lower()\n",
    "\n",
    "                if tag_with_lemmas:\n",
    "                    literal = expression_lemma\n",
    "                else:\n",
    "                    literal = expression_form\n",
    "\n",
    "                if literal in self.dictionary:\n",
    "                    is_single_token = j - i == 1  # j-1 이 1이 맞는지를  True/ False 로 입력\n",
    "                    original_position = i         # 시작값\n",
    "                    i = j\n",
    "                    taggings = [tag     for tag in self.dictionary[literal]] # value 추출\n",
    "                    tagged_expression = (expression_form, expression_lemma, taggings)\n",
    "\n",
    "                    if is_single_token:  # 위 판단이 True인 경우 \n",
    "                        original_token_tagging = sentence[original_position][2]\n",
    "                        tagged_expression[2].extend(original_token_tagging) # tag 값을 덧붙인다\n",
    "                    tag_sentence.append(tagged_expression)\n",
    "                    tagged = True\n",
    "                else:\n",
    "                    j = j - 1   # j 값을 1씩 줄이면서 위의 작업에 적합한 조건으로 조절을 해 나아간다 \n",
    "\n",
    "            # tagged 값이 기존에 없는경우, 새로 추가한다\n",
    "            if not tagged:\n",
    "                tag_sentence.append(sentence[i])\n",
    "                i += 1\n",
    "        return tag_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 긍/부정 정리된 dictionary 목록의 표현을 Counting\n",
    "def value_of(sentiment):\n",
    "    if sentiment == 'positive': return 1\n",
    "    if sentiment == 'negative': return -1\n",
    "    return 0\n",
    "\n",
    "def sentiment_score(review):\n",
    "    return sum([sentence_score(sentence, None, 0.0) for sentence in review])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## 4 NER를 사용한 감정분석 -  176 p (on_tology)\n",
    "개체명(고유명사) 인식 Named-entity recognition (NER) - 감정식별을 위한 전처리 \n",
    "\n",
    "    token의 개체명을 별도의 기준으로 식별 후, 클래스로 분류하는 과정으로 \n",
    "    히든마르코프, 최대엔트로피 마르코프, SVM, 의사결정나무 등을 활용한다\n",
    "    개체명으로 인식되면, 감정분석에 기여하지 않으므로, 제외한 나머지들로 감정분석을 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## 5 기계학습을 사용한 감정분석\n",
    "Twitter text 데이터에 대한 통계, 자동화, 기계학습 분류기\n",
    "\n",
    "출처 : http://www.nltk.org/book/ch06.html\n",
    "\n",
    "data : https://github.com/ravikiranj/twitter-sentiment-analyzer\n",
    "\n",
    "<img src = \"http://www.nltk.org/images/supervised-classification.png\" align='left' width = '500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01 nltk의 모듈\n",
    "nltk.sentiment.sentiment_analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nltk.sentiment.sentiment_analyzer() 는 기계학습 기반의 감정분석 모듈\n",
    "import nltk.sentiment.sentiment_analyzer\n",
    "from nltk.sentiment import SentimentAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02 트위터 예제 분석\n",
    "https://github.com/ravikiranj\n",
    "\n",
    "https://gist.github.com/ravikiranj/2639121\n",
    "\n",
    "http://www.nltk.org/howto/twitter.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 중복되는 문자를 단일로 처리\n",
    "def replaceTwoOrMore(s):\n",
    "    pattern = re.compile(r\"(.)\\1{1,}\", re.DOTALL)\n",
    "    return pattern.sub(r\"\\1\\1\", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 불용어 목록을 파일에서 읽어온다\n",
    "def getStopWordList(stopWordListFileName):\n",
    "    stopWords = []   # 불용어 목록 파일의 text를 '공백'을 기준으로 token생성 뒤, list로 출력\n",
    "    stopWords.append('AT_USER')\n",
    "    stopWords.append('URL')\n",
    "    fp = open(stopWordListFileName, 'r')\n",
    "    line = fp.readline()\n",
    "    while line:\n",
    "        word = line.strip()\n",
    "        stopWords.append(word)\n",
    "        line = fp.readline()\n",
    "    fp.close()\n",
    "    return stopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 여러번 반복된 단어들의 전처리\n",
    "def getFeatureVector(tweet):\n",
    "    featureVector = []\n",
    "    words = tweet.split()       # 공백을 기분으로 token 단어를 생성\n",
    "    for w in words:             \n",
    "        w = replaceTwoOrMore(w) # 2번 이상 반복된 단어를 단일로 전처리 (사용자함수)\n",
    "        w = w.strip('\\'\"?,.')   # 문장부호를 제거\n",
    "        val = re.search(r\"^[a-zA-Z][a-zA-Z0-9]*$\", w) # 알파벳 여부 확인\n",
    "\n",
    "    # 해당 단어가 숫자/영어가 아니거나, 불용어에 해당하면 무시\n",
    "    if(w in stopWords or val is None):\n",
    "        pass # continue 는 '반복문'에서 가능\n",
    "    else:\n",
    "        featureVector.append(w.lower()) # 소문자로 변환한다\n",
    "    return featureVector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://gist.github.com/ravikiranj/2639031\n",
    "# 트위터 데이터 전처리 함수\n",
    "def processTweet(tweet):\n",
    "    tweet = tweet.lower()  # 데이터를 소문자로 바꾼다\n",
    "\n",
    "    # www.* 또는 https?://* ==> URL 로 변환\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL', tweet)\n",
    "    tweet = re.sub('@[^\\s]+','AT_USER',tweet)   # @username ==> AT_USER로 변환\n",
    "    tweet = re.sub('[\\s]+', ' ', tweet)         # 공백을 제거   \n",
    "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)  # 해시태그 '#' 제거\n",
    "    tweet = tweet.strip('\\'\"')                  # triming\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@PrincessSuperC Hey Cici sweetheart! Just wanted to let u know I luv u! OH! and will the mixtape drop soon? FANTASY RIDE MAY 5TH!!!!  \\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 트위터 데이터가 .txt인 경우\n",
    "import re, csv\n",
    "stopWords = []\n",
    "\n",
    "# Tweets 데이터는 1줄씩 모든 프로세스를 진행한다\n",
    "fp = open('data/sampleTweets.txt', 'r') # Data text 파일\n",
    "line = fp.readline()\n",
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426 ['AT_USER', 'URL', '', 'a', 'about', 'above', 'across', 'after', 'again', 'against']\n"
     ]
    }
   ],
   "source": [
    "st = open('data/stopwords.txt', 'r')    # Stop word text 파일 \n",
    "stopWords = getStopWordList('./data/stopwords.txt')\n",
    "print(len(stopWords), stopWords[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "['twitter']\n",
      "[]\n",
      "['makeitcount']\n",
      "['sigh']\n",
      "['hurts']\n",
      "['hurts']\n"
     ]
    }
   ],
   "source": [
    "while line:  # 트위터 데이터 1줄씩 처리\n",
    "    processedTweet = processTweet(line)\n",
    "    featureVector = getFeatureVector(processedTweet)\n",
    "    print(featureVector)\n",
    "    line = fp.readline()\n",
    "fp.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 트위터 데이터가 .CSV 인 경우\n",
    "# Tweets are read one by one and then processed.\n",
    "inpTweets = csv.reader(open('./data/sampletwitter.csv', 'r'), delimiter=',') #, quotechar='|')\n",
    "tweets = []\n",
    "for row in inpTweets:\n",
    "    sentiment = row[0]\n",
    "    tweet = row[1]\n",
    "    processedTweet = processTweet(tweet)\n",
    "    featureVector = getFeatureVector(processedTweet) #, stopWords)\n",
    "    tweets.append((featureVector, sentiment));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 특징 추출하는 메서드\n",
    "def extract_features(tweet):\n",
    "    tweet_words = set(tweet)\n",
    "    features = {}\n",
    "    for word in featureList:\n",
    "        features['contains(%s)' % word] = (word in tweet_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nltk.classify.naivebayes.NaiveBayesClassifier at 0x7fcc9011d940>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 나이브베이즈 분류기로 감정분석\n",
    "NaiveBClassifier = nltk.NaiveBayesClassifier.train(train_sets)\n",
    "NaiveBClassifier\n",
    "# processedTestTweet = processTweet(test_sets)\n",
    "# Testing the classifiertestTweet = 'I liked this book on Sentiment Analysis a lot.'\n",
    "# processedTestTweet = processTweet(test_sets)\n",
    "# NaiveBClassifier.classify(extract_features(getFeatureVector(processedTestTweet)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i liked this book on sentiment analysis a lot.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testTweet = 'I liked this book on Sentiment Analysis a lot.'\n",
    "processedTestTweet = processTweet(testTweet)\n",
    "processedTestTweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lot']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getFeatureVector(processedTestTweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'analysis' in stopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i liked this book on sentiment analysis a lot.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processedTestTweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lot']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getFeatureVector(processedTestTweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testTweet = 'I am so badly hurt'\n",
    "processedTestTweet = processTweet(testTweet)\n",
    "# nltk.classify.accuracy(NaiveBClassifier, processedTestTweet)\n",
    "# NaiveBClassifier.classify(extract_features(getFeatureVector(processedTestTweet)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['twitter']\n"
     ]
    }
   ],
   "source": [
    "featureVector = getFeatureVector(processedTweet)\n",
    "print(featureVector)\n",
    "# line = fp.readline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03  nltk.sentiment.sentiment_analyzer 예제\n",
    "http://www.nltk.org/howto/probability.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the movie begins in the past where a young boy named sam attempts to save celebi from a hunter . \\nemerging from the human psyche and showing characteristics of abstract expressionism , minimalism and russian constructivism , graffiti removal has secured its place in the history of modern art while being created by artists who are unconscious of their artistic achievements . \\nspurning her mother's insistence that she get on with her life , mary is thrown out of the house , rejected by joe , and e\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import subjectivity\n",
    "subjectivity.raw()[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subj_docs : 100 (['smart', 'and', 'alert', ',', 'thirteen', 'conversations', 'about', 'one', 'thing', 'is', 'a', 'small', 'gem', '.'], 'subj')\n",
      "obj_docs  : 100 (['the', 'movie', 'begins', 'in', 'the', 'past', 'where', 'a', 'young', 'boy', 'named', 'sam', 'attempts', 'to', 'save', 'celebi', 'from', 'a', 'hunter', '.'], 'obj')\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "n_instances = 100\n",
    "\n",
    "# Each document is represented by a tuple (sentence, label)\n",
    "subj_docs = [(sent, 'subj') for sent in subjectivity.sents(categories='subj')[:n_instances]]\n",
    "print('subj_docs :',len(subj_docs), subj_docs[0])\n",
    "obj_docs = [(sent, 'obj') for sent in subjectivity.sents(categories='obj')[:n_instances]]\n",
    "print('obj_docs  :',len(obj_docs), obj_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train, test 데이터를 생성\n",
    "train_subj_docs = subj_docs[:80]\n",
    "train_obj_docs  =  obj_docs[:80]\n",
    "training_docs = train_subj_docs + train_obj_docs\n",
    "\n",
    "test_subj_docs  = subj_docs[80:100]\n",
    "test_obj_docs   =  obj_docs[80:100]\n",
    "testing_docs  = test_subj_docs + test_obj_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3799, ['smart', 'and', 'alert', ',', 'thirteen', 'conversations', 'about'])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import mark_negation, extract_unigram_feats\n",
    "\n",
    "sentim_analyzer = SentimentAnalyzer()\n",
    "all_words_neg = sentim_analyzer.all_words([mark_negation(doc) for doc in training_docs])\n",
    "len(all_words_neg), all_words_neg[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83, ['.', 'the', ',', 'a', 'and', 'of', 'to'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use simple unigram word features, handling negation:\n",
    "unigram_feats = sentim_analyzer.unigram_word_feats(all_words_neg, min_freq=4)\n",
    "sentim_analyzer.add_feat_extractor(extract_unigram_feats, unigrams = unigram_feats)\n",
    "len(unigram_feats), unigram_feats[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier\n",
      "Evaluating NaiveBayesClassifier results...\n",
      "Accuracy: 0.8\n",
      "F-measure [obj]: 0.8\n",
      "F-measure [subj]: 0.8\n",
      "Precision [obj]: 0.8\n",
      "Precision [subj]: 0.8\n",
      "Recall [obj]: 0.8\n",
      "Recall [subj]: 0.8\n"
     ]
    }
   ],
   "source": [
    "# We apply features to obtain a feature-value representation of our datasets:\n",
    "training_set = sentim_analyzer.apply_features(training_docs)\n",
    "test_set = sentim_analyzer.apply_features(testing_docs)\n",
    "\n",
    "# We can now train our classifier on the training set, and subsequently output the evaluation results:\n",
    "trainer = NaiveBayesClassifier.train\n",
    "classifier = sentim_analyzer.train(trainer, training_set)\n",
    "# `Training classifier\n",
    "for key,value in sorted(sentim_analyzer.evaluate(test_set).items()):\n",
    "    print('{0}: {1}'.format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04  nltk.sentiment.sentiment_analyzer  모듈 살펴보기\n",
    "http://www.nltk.org/_modules/nltk/sentiment/sentiment_analyzer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from __future__ import print_function\n",
    "from collections import defaultdict\n",
    "from nltk.classify.util import apply_features, accuracy as eval_accuracy\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import (BigramAssocMeasures, precision as eval_precision, \n",
    "                          recall as eval_recall, f_measure as eval_f_measure)\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.sentiment.util import save_file, timer\n",
    "\n",
    "# 기계학습에 기반한 감정분석도구\n",
    "class SentimentAnalyzer(object):\n",
    "    def __init__(self, classifier=None):\n",
    "        self.feat_extractors = defaultdict(list)\n",
    "        self.classifier = classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # 텍스트에서 모든 (중복)단어를 반환\n",
    "    def all_words(self, documents, labeled=None):\n",
    "        all_words = []\n",
    "        if labeled is None:\n",
    "            labeled = documents and isinstance(documents[0], tuple)\n",
    "        if labeled == True:\n",
    "            for words, sentiment in documents:\n",
    "                all_words.extend(words)\n",
    "        elif labeled == False:\n",
    "            for words in documents:\n",
    "                all_words.extend(words)\n",
    "        return all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # 특징 추출 함수 feature extraction function\n",
    "    def apply_features(self, documents, labeled=None):\n",
    "        return apply_features(self.extract_features, documents,labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # 단어의 특징을 반환하는 코드\n",
    "    def unigram_word_feats(self, words, top_n = None, min_freq = 0):\n",
    "        unigram_feats_freqs = FreqDist(word for word in words)\n",
    "        return [w    for   w, f   in   unigram_feats_freqs.most_common(top_n) \n",
    "                     if   unigram_feats_freqs[w]  >  min_freq ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # bi-gram의 특징을 반환하는 코드\n",
    "    def bigram_collocation_feats(self, documents, top_n=None, min_freq=3, assoc_measure=BigramAssocMeasures.pmi):\n",
    "        finder = BigramCollocationFinder.from_documents(documents)\n",
    "        finder.apply_freq_filter(min_freq)\n",
    "        return finder.nbest(assoc_measure, top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # 사용 가능한 특징세트를 사용하여, 주어진 인스턴스를 분류\n",
    "    def classify(self, instance):\n",
    "        instance_feats = self.apply_features([instance],labeled=False)\n",
    "        return self.classifier.classify(instance_feats[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # 텍스트에서 특징 추출을 위해 사용\n",
    "    def add_feat_extractor(self, function, **kwargs):\n",
    "        self.feat_extractors[function].append(kwargs)\n",
    "\n",
    "    def extract_features(self, document):\n",
    "        all_features = {}\n",
    "        for extractor in self.feat_extractors:\n",
    "            for param_set in self.feat_extractors[extractor]:\n",
    "                feats = extractor(document, **param_set)\n",
    "            all_features.update(feats)\n",
    "        return all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # 훈련데이터를 훈련시키는 함수\n",
    "    def train(self, trainer, training_set, save_classifier = None, **kwargs):\n",
    "        print(\"Training classifier\")\n",
    "        self.classifier = trainer(training_set, **kwargs)\n",
    "        if save_classifier:\n",
    "            save_file(self.classifier, save_classifier)\n",
    "        return self.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # 테스트데이터를 사용한 분류기의 테스트 및 성능평가\n",
    "    def evaluate(self, test_set, classifier = None, accuracy = True, \n",
    "                 f_measure = True, precision = True, recall = True, verbose = False):\n",
    "\n",
    "        if classifier is None:  # 분류기에 아무것도 지정하지 않은 경우\n",
    "            classifier = self.classifier  # __init__의 초깃값을 불러와서 작업을 시작\n",
    "        print(\"Evaluating {0} results...\".format(type(classifier).__name__))\n",
    "        metrics_results = {}              # 출력 report dictionary를 생성\n",
    "\n",
    "        if accuracy == True:   # 정확도 측정옵션에 True를 입력시\n",
    "            accuracy_score = eval_accuracy(classifier, test_set) # 분류기 기준, 데이터를 test한다\n",
    "            metrics_results['Accuracy'] = accuracy_score         # report dictionary에 기록 \n",
    "\n",
    "        # 출처 : https://dongyeopblog.wordpress.com/2016/04/08/python-defaultdict-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/\n",
    "        gold_results = defaultdict(set)   # key값 지정없어도, default로 key를 자동으로 지정한다\n",
    "        test_results = defaultdict(set)   \n",
    "        labels = set()\n",
    "        for i, (feats, label) in enumerate(test_set): # test 상세내용을 기록한다\n",
    "            labels.add(label)\n",
    "            gold_results[label].add(i)\n",
    "            observed = classifier.classify(feats)\n",
    "            test_results[observed].add(i)\n",
    "\n",
    "        for label in labels:  # test 결과 수집된 labels 에 따라, 평가함수로 계산을 한다\n",
    "            if precision == True:  # 정확도 측정\n",
    "                precision_score = eval_precision(gold_results[label], test_results[label])\n",
    "                metrics_results['Precision [{0}]'.format(label)] = precision_score\n",
    "            if recall == True:     # recall 측정\n",
    "                recall_score = eval_recall(gold_results[label], test_results[label])\n",
    "                metrics_results['Recall [{0}]'.format(label)] = recall_score\n",
    "            if f_measure == True:  # f-measure 측정\n",
    "                f_measure_score = eval_f_measure(gold_results[label], test_results[label])\n",
    "                metrics_results['F-measure [{0}]'.format(label)] = f_measure_score\n",
    "            if verbose == True:    # Data를 정렬\n",
    "                for result in sorted(metrics_results):\n",
    "                    print('{0}: {1}'.format(result, metrics_results[result]))\n",
    "        return metrics_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 NER 시스템의 평가\n",
    "Evaluation of the NER system"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
