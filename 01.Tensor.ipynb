{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <strong>Tensor Flow Deep Learning\n",
    "<strong>딥러닝과 텐서플로의 만남</strong>\n",
    "1. <strong>규칙기반 알고리즘</strong> : for/ if/ boolean - 분명한 기준이 존재한 경우 효과적\n",
    "2. <strong>머신러닝 알고리즘</strong> : end-to-end 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "## <strong>1 Jupyter Notebook\n",
    "쥬피터 노트북\n",
    "### <strong> 01 tensor graph 설계\n",
    "Tensor() : graph 구조를 결과로 출력한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_3:0\", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# constant : 상수, 문자형태도 입력가능\n",
    "import tensorflow as tf\n",
    "hello = tf.constant(\"Hello, Tensorflow!\")\n",
    "print(hello)\n",
    "\n",
    "# 'rank'  : Tensor 차원 수\n",
    "# 'shape' : Tensor 구조를 설명\n",
    "# [1., 2., 3.]                    : 'rank' 1차원 tensor, 'shape' [3]     (인덱스 3)\n",
    "# [[1., 2., 3.], [4., 5., 6.]]    : 'rank' 2차원 tensor, 'shape' [2,3]   (2차원 인덱스 3)\n",
    "# [[[1., 2., 3.]],[[7., 8., 9.]]] : 'rank' 3차원 tensor, 'shape' [2,1,3] (3차원 2x1x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(10)\n",
    "b = tf.constant(32)\n",
    "c = tf.add(a,b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <strong> 02 지연실행\n",
    "lazy evaluation : graph 구조를 그린 뒤, Tensor 연산을 실행한다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, Tensorflow!'\n",
      "[10, 32, 42]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(hello))\n",
    "print(sess.run([a,b,c]))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "## <strong>2 PlaceHolder 와 변수\n",
    "parameter 를 설정\n",
    "1. <strong>scalar</strong> : 크기 값  <strong>ex)1</strong>\n",
    "2. <strong>vector</strong> : 화살표 1개 <strong>ex) [1,2,3] list 1개</strong>\n",
    "3. <strong>matrix</strong> : 화살표들의 여러 묶음 <strong>ex) [[1,2],[3,4]]</strong>\n",
    "4. <strong>shape</strong> : 다차원 자료를 x 형태로 표시\n",
    "\n",
    "https://tensorflowkorea.gitbooks.io/tensorflow-kr/content/g3doc/resources/dims_types.html\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*7aXSK5bdSFO9WZMswU5v1w.png\" align=\"left\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_1:0\", shape=(?, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow 의 경직성을 입력 부분에 한해서 \n",
    "# 조금 더 유연한 입력값을 설정가능\n",
    "\n",
    "# None : rank 차원을 범용으로 설정\n",
    "# 3 : feactor 는 3으로 고정하여 모델의 안정성 확보\n",
    "X = tf.placeholder(tf.float32, [None, 3])  \n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf.Variable: 그래프를 계산하면서 자료를 최적화\n",
    "# tf.random_normal: 초기값을 정규분포 랜덤 값으로 초기화\n",
    "W = tf.Variable(tf.random_normal([3, 2]))\n",
    "b = tf.Variable(tf.random_normal([2, 1]))\n",
    "\n",
    "# 가설함수 : 1차원 선형모델을 정의한다\n",
    "expr = tf.matmul(X, W) + b\n",
    "# ------------ graph 설계 완료 --------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://cfile2.uf.tistory.com/image/226F5B3952B78BC7123696\" align='left'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data : [[1, 2, 3], [4, 5, 6]],\n",
      "\n",
      "W(weight) : [[ 0.62197512  0.20127779]\n",
      " [-0.06056291  1.12221813]\n",
      " [ 0.6104278   0.61923862]],\n",
      "\n",
      "b(bias) : [[-0.2599577 ]\n",
      " [-1.26874745]],\n",
      "\n",
      "expr(예측) : [[ 2.07217479  4.04347181]\n",
      " [ 4.57890511  8.86288643]]\n"
     ]
    }
   ],
   "source": [
    "# ------------ lazy evaluation -----------------\n",
    "sess = tf.Session()\n",
    "x_data = [[1, 2, 3], [4, 5, 6]]\n",
    "\n",
    "# Variable 초기화 : tf.global_variables_initializer\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# placeholder 에 입력한 값\n",
    "print(\"x_data : {},\\n\\nW(weight) : {},\\n\\nb(bias) : {},\\n\\nexpr(예측) : {}\".format(\n",
    "    x_data, sess.run(W), sess.run(b), \n",
    "    \n",
    "    # expr 실행\n",
    "    # feed_dict : 'X'매개변수와 입력값 연결 {dict 을 활용}\n",
    "    sess.run(expr, feed_dict={X: x_data})))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "## <strong>3 선형회귀 모델을 구현\n",
    "선형회귀 : x 와 y 의 관계를 파악한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "x_data = [1, 2, 3]\n",
    "y_data = [1, 2, 3]\n",
    "\n",
    "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "b = tf.Variable(tf.random_uniform([1], -1.0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"X:0\", dtype=float32)\n",
      "Tensor(\"Y:0\", dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# name : 값의 추적을 위해 이름을 설정\n",
    "# 변수, 연산함수에도 이름을 지정할 수 있다.\n",
    "X = tf.placeholder(tf.float32, name=\"X\")\n",
    "Y = tf.placeholder(tf.float32, name=\"Y\")\n",
    "print(X)\n",
    "print(Y)   # tensor 에도 이름이 붙여져서 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 가설 수식: y = W * x + b\n",
    "# W 와 X 가 행렬이 아니므로, tf.matmul 아닌 기본 곱셈 기호를 사용\n",
    "hypothesis = W * X + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))  # 예측에서 실제를 뺀, 제곱값들의 평균 (평균제곱오차)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1) # 경사하강법\n",
    "train_op = optimizer.minimize(cost)                              # 비용 최소화 목표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 15.8906 [ 0.883205] [ 0.72400987]\n",
      "20 0.0240177 [ 0.82433146] [ 0.39933595]\n",
      "40 0.00907453 [ 0.8920207] [ 0.24546234]\n",
      "60 0.0034286 [ 0.93362767] [ 0.15087987]\n",
      "80 0.00129542 [ 0.95920247] [ 0.09274228]\n",
      "\n",
      "=== Test ===\n",
      "X: 5, Y:[ 4.92993593] \n",
      "X: 2.5, Y:[ 2.49417329]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())  # 세션을 생성하고 초기화합니다.\n",
    "\n",
    "    for step in range(100): # 최적화를 100번 수행\n",
    "        # sess.run : 1) train_op 와 cost 그래프를 계산, 2) 가설수식 값을 feed_dict 로 전달\n",
    "        _, cost_val = sess.run([train_op, cost], feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 20 == 0: \n",
    "            print(step, cost_val, sess.run(W), sess.run(b))\n",
    "\n",
    "    # 최적화가 완료된 모델에 테스트 값을 넣고 결과가 잘 나오는지 확인해봅니다.\n",
    "    print(\"\\n=== Test ===\\nX: 5, Y:{} \\nX: 2.5, Y:{}\".format(\n",
    "        sess.run(hypothesis, feed_dict={X: 5}),     # X 가 5일때 Y를 예측\n",
    "        sess.run(hypothesis, feed_dict={X: 2.5})))  # X 가 2.5일때 Y를 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "## <strong>4 기본 신경망 구현\n",
    "뉴런 신경망을 연결한 딥러닝 알고리즘 \n",
    "1. ex) $ y = Sigmoid(X * W + b) $\n",
    "1. <strong>인공뉴런</strong> : <strong>weight</strong>(가중치) 와 <strong>활성화 함수</strong>의 연결로 구성\n",
    "1. <strong>activation function</strong> (활성화 함수) : Sigmoid, ReLU, tanh\n",
    "\n",
    "<img src=\"https://ujwlkarn.files.wordpress.com/2016/08/screen-shot-2016-08-08-at-11-53-41-am.png?w=748\" align=\"left\" \n",
    "\\width=\"700\">\n",
    "\n",
    "<img src=\"http://python3.codes/wp-content/uploads/2017/01/XIHOY.jpg\" align=\"left\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RBM (Restricted Boltzmann Machine) : 제한된 볼트만 머신\n",
    "# 역전파 (backpropagation) : 출력층 결과를 입력층까지 역으로 전파하며 계산하여 최적화 과정이 훨씬 유용하다\n",
    "# 털과 날개 여부로, 포유류/조류 분류 신경망모델 생성\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "x_data = np.array([[0, 0], [1, 0], [1, 1], \n",
    "                   [0, 0], [0, 0], [0, 1]])   # 0: 털, 1: 날개 \n",
    "\n",
    "# one-hot-encoding : 기타([1, 0, 0]), 포유류([0, 1, 0]), 조류([0, 0, 1])\n",
    "y_data = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1], \n",
    "                   [1, 0, 0], [1, 0, 0], [0, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. 신경망 모델 구성 graph ------------------------------------------------\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "# 신경망 (2차원) : [Train 데이터 특성, Target 레이블] -> [2, 3]\n",
    "# 자료 x, y 모두 6차원으로 동일해야 한다\n",
    "W = tf.Variable(tf.random_uniform([2, 3], -1., 1.)) # tf.random_uniform : 균등분포 난수출력 -1 ~ 1\n",
    "b = tf.Variable(tf.zeros([3]))  # bias : 각 레이어의 아웃풋 갯수로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L = tf.add(tf.matmul(X, W), b)  # 신경망에 가중치 W과 편향 b을 적용합니다\n",
    "L = tf.nn.relu(L)               # ReLU 함수를 적용\n",
    "model = tf.nn.softmax(L)        # softmax 함수 : 결과 전체 합이 1인 확률로 만들어주는 함수\n",
    "                                # 예) [8.04, 2.76, -6.52] -> [0.53 0.24 0.23]\n",
    "\n",
    "# 신경망을 최적화하기 위한 비용 함수 (Cross-Entropy)\n",
    "# cf) axis 옵션 : 개별 결과를 구한 뒤 평균 계산한다 (axis 이 없으면 -1.09 같은 총합 스칼라로 출력)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(model), axis=1))\n",
    "#        Y         model           Y * tf.log(model)    reduce_sum(axis=1)\n",
    "# 예) [[1 0 0]  [[0.1 0.7 0.2]  -> [[-1.0  0    0]   -> [-1.0, -0.09]\n",
    "#     [0 1 0]]  [0.2 0.8 0.0]]     [ 0   -0.09 0]]\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train_op = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 신경망을 최적화하기 위한 비용 함수를 작성 (Cross-Entropy)\n",
    "# cf) axis 옵션 : 개별 결과를 구한 뒤 평균 계산한다 (axis 이 없으면 -1.09 같은 총합 스칼라로 출력)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(model), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train_op = optimizer.minimize(cost)\n",
    "\n",
    "#        Y         model           Y * tf.log(model)   reduce_sum(axis=1)\n",
    "# 예) [[1 0 0]  [[0.1 0.7 0.2]  -> [[-1.0  0    0]  -> [-1.0, -0.09]\n",
    "#     [0 1 0]]  [0.2 0.8 0.0]]     [ 0   -0.09 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 1.16454\n",
      "40 1.15386\n",
      "60 1.1436\n",
      "80 1.13373\n",
      "100 1.12424\n"
     ]
    }
   ],
   "source": [
    "# 2. 신경망 모델 Train -------------------------------------------------------\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(100):\n",
    "    sess.run(train_op, feed_dict={X: x_data, Y: y_data})\n",
    "    if (step + 1) % 20 == 0:\n",
    "        print(step + 1, sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n",
    "\n",
    "# 결과 확인  0: 기타 1: 포유류, 2: 조류\n",
    "# tf.argmax: 예측값과 실제값의 행렬에서 tf.argmax 를 이용해 가장 큰 값을 가져옵니다.\n",
    "# 예) [[0 1 0] [1 0 0]] -> [1 0]\n",
    "#    [[0.2 0.7 0.1] [0.9 0.1 0.]] -> [1 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측값: [0 1 1 0 0 1]\n",
      "실제값: [0 1 2 0 0 2]\n",
      "정확도: 66.67\n"
     ]
    }
   ],
   "source": [
    "# 3. 신경망 모델 의 검증 -------------------------------------------------------\n",
    "prediction = tf.argmax(model, 1)\n",
    "target = tf.argmax(Y, 1)\n",
    "print('예측값:', sess.run(prediction, feed_dict={X: x_data}))\n",
    "print('실제값:', sess.run(target, feed_dict={Y: y_data}))\n",
    "\n",
    "is_correct = tf.equal(prediction, target)\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('정확도: %.2f' % sess.run(accuracy * 100, feed_dict={X: x_data, Y: y_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
